{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416e388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b600c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # 批量大小\n",
    "label_nums = 26 # 类别数量\n",
    "Data_dir = \"C:/Users/47925/Desktop/Data_sign_language\" # 数据集路径\n",
    "loss = nn.CrossEntropyLoss() # 交叉熵损失\n",
    "lr = 1e-5 # 学习率\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=lr) # 优化器\n",
    "epoch = 1000 # 迭代次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35295886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    # 残差块\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 前馈计算\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725eb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a35bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb306d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet18\n",
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "b5 = nn.Sequential(*resnet_block(256, 512, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b766ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(b1, b2, b3, b4, b5,\n",
    "                    nn.AdaptiveAvgPool2d((1,1)),\n",
    "                    nn.Flatten(), nn.Linear(512, label_nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ba84c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(is_train):\n",
    "    # 预处理数据集\n",
    "    if is_train:\n",
    "        transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.RandomRotation(degrees=(-45,45)),\n",
    "            torchvision.transforms.ColorJitter(brightness=0.4,\n",
    "                                               contrast=0.4,\n",
    "                                               saturation=0.4),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                             [0.229, 0.224, 0.225])])\n",
    "    else:\n",
    "        transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(224),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                             [0.229, 0.224, 0.225])])\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4611389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(is_train):\n",
    "    # 使用torchvision更方便训练\n",
    "    transform = get_transform(is_train)\n",
    "    if is_train:\n",
    "        path = os.path.join(Data_dir,\"Train\")\n",
    "    else:\n",
    "        path=os.path.join(Data_dir,\"Valid\")\n",
    "    dataset = torchvision.datasets.ImageFolder(path,transform=transform)\n",
    "    info = dataset.find_classes(path)\n",
    "    print(info)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30637afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'], {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25})\n",
      "(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'], {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = build_dataset(is_train=True)\n",
    "valid_dataset = build_dataset(is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36a64875",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=True)\n",
    "valid_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                                batch_size,\n",
    "                                                shuffle=False,\n",
    "                                                drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6c6366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f2b867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    # 初始化权重\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daade27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe108f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.load(\"C://Users//47925//Desktop//Data_sign_language//logs//full_model179.pth\") # 继续上次的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5ecbb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1轮训练\n",
      "训练时间：0.10402655601501465\n",
      "第0个批次，loss：0.0005105423042550683，acc：1.0\n",
      "训练时间：13.509186029434204\n",
      "第100个批次，loss：0.00013863760977983475，acc：1.0\n",
      "训练时间：26.682159423828125\n",
      "第200个批次，loss：0.014286128804087639，acc：1.0\n",
      "训练时间：39.85335874557495\n",
      "第300个批次，loss：0.007455478422343731，acc：1.0\n",
      "训练时间：53.05134701728821\n",
      "第400个批次，loss：0.0008073396747931838，acc：1.0\n",
      "训练时间：66.258624792099\n",
      "第500个批次，loss：0.01806616596877575，acc：1.0\n",
      "训练时间：79.48361301422119\n",
      "第600个批次，loss：0.0017764826770871878，acc：1.0\n",
      "训练时间：92.71104979515076\n",
      "第700个批次，loss：0.0012100773165002465，acc：1.0\n",
      "训练时间：105.93252682685852\n",
      "第800个批次，loss：0.0020640932489186525，acc：1.0\n",
      "整体验证集的acc：0.9938461780548096\n",
      "第2轮训练\n",
      "训练时间：115.33464431762695\n",
      "第0个批次，loss：7.82643910497427e-05，acc：1.0\n",
      "训练时间：128.57163405418396\n",
      "第100个批次，loss：0.02616819180548191，acc：0.96875\n",
      "训练时间：141.82293844223022\n",
      "第200个批次，loss：0.0020449631847441196，acc：1.0\n",
      "训练时间：155.09000086784363\n",
      "第300个批次，loss：0.0001863182260422036，acc：1.0\n",
      "训练时间：168.35517024993896\n",
      "第400个批次，loss：8.157407864928246e-05，acc：1.0\n",
      "训练时间：181.63335371017456\n",
      "第500个批次，loss：0.00037091627018526196，acc：1.0\n",
      "训练时间：194.92696142196655\n",
      "第600个批次，loss：0.0006061546155251563，acc：1.0\n",
      "训练时间：208.20803594589233\n",
      "第700个批次，loss：0.051606371998786926，acc：0.96875\n",
      "训练时间：221.4983229637146\n",
      "第800个批次，loss：0.0008909142343327403，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第3轮训练\n",
      "训练时间：230.97686624526978\n",
      "第0个批次，loss：0.006020756438374519，acc：1.0\n",
      "训练时间：244.2688672542572\n",
      "第100个批次，loss：9.845881868386641e-05，acc：1.0\n",
      "训练时间：257.56550550460815\n",
      "第200个批次，loss：0.011943144723773003，acc：1.0\n",
      "训练时间：270.8625109195709\n",
      "第300个批次，loss：0.0001441801869077608，acc：1.0\n",
      "训练时间：284.16399693489075\n",
      "第400个批次，loss：0.0049572899006307125，acc：1.0\n",
      "训练时间：297.46500158309937\n",
      "第500个批次，loss：0.000179359209141694，acc：1.0\n",
      "训练时间：310.79300236701965\n",
      "第600个批次，loss：0.0014528572792187333，acc：1.0\n",
      "训练时间：324.11660599708557\n",
      "第700个批次，loss：0.0004132694157306105，acc：1.0\n",
      "训练时间：337.42661786079407\n",
      "第800个批次，loss：0.0005162708694115281，acc：1.0\n",
      "整体验证集的acc：0.995192289352417\n",
      "第4轮训练\n",
      "训练时间：346.93319964408875\n",
      "第0个批次，loss：0.061572395265102386，acc：0.96875\n",
      "训练时间：360.23920464515686\n",
      "第100个批次，loss：0.00011286493827356026，acc：1.0\n",
      "训练时间：373.57001066207886\n",
      "第200个批次，loss：0.0009342576377093792，acc：1.0\n",
      "训练时间：386.883686542511\n",
      "第300个批次，loss：0.0001697759289527312，acc：1.0\n",
      "训练时间：400.2051134109497\n",
      "第400个批次，loss：0.00022099303896538913，acc：1.0\n",
      "训练时间：413.5251202583313\n",
      "第500个批次，loss：6.578727334272116e-05，acc：1.0\n",
      "训练时间：426.8516275882721\n",
      "第600个批次，loss：0.00010372899123467505，acc：1.0\n",
      "训练时间：440.18606090545654\n",
      "第700个批次，loss：0.004263239912688732，acc：1.0\n",
      "训练时间：453.51216340065\n",
      "第800个批次，loss：0.007262540981173515，acc：1.0\n",
      "整体验证集的acc：0.9938461780548096\n",
      "第5轮训练\n",
      "训练时间：463.0493106842041\n",
      "第0个批次，loss：0.0008885422139428556，acc：1.0\n",
      "训练时间：476.388151884079\n",
      "第100个批次，loss：0.00043133110739290714，acc：1.0\n",
      "训练时间：489.74266290664673\n",
      "第200个批次，loss：0.0003666447300929576，acc：1.0\n",
      "训练时间：503.0856738090515\n",
      "第300个批次，loss：0.014148668386042118，acc：1.0\n",
      "训练时间：516.4368743896484\n",
      "第400个批次，loss：0.0006298775551840663，acc：1.0\n",
      "训练时间：529.770875453949\n",
      "第500个批次，loss：6.317100633168593e-05，acc：1.0\n",
      "训练时间：543.1103553771973\n",
      "第600个批次，loss：0.0007011131383478642，acc：1.0\n",
      "训练时间：556.4786388874054\n",
      "第700个批次，loss：0.0021885426249355078，acc：1.0\n",
      "训练时间：569.8196623325348\n",
      "第800个批次，loss：0.0002135984250344336，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第6轮训练\n",
      "训练时间：579.3314950466156\n",
      "第0个批次，loss：0.013998005539178848，acc：1.0\n",
      "训练时间：592.6725053787231\n",
      "第100个批次，loss：0.00014099868712946773，acc：1.0\n",
      "训练时间：606.0264811515808\n",
      "第200个批次，loss：4.40556432295125e-05，acc：1.0\n",
      "训练时间：619.3895070552826\n",
      "第300个批次，loss：0.040590330958366394，acc：0.96875\n",
      "训练时间：632.7495059967041\n",
      "第400个批次，loss：0.00021222440409474075，acc：1.0\n",
      "训练时间：646.1093056201935\n",
      "第500个批次，loss：0.015146680176258087，acc：1.0\n",
      "训练时间：659.4823248386383\n",
      "第600个批次，loss：0.0012606829404830933，acc：1.0\n",
      "训练时间：672.8703470230103\n",
      "第700个批次，loss：0.0029364898800849915，acc：1.0\n",
      "训练时间：686.2437882423401\n",
      "第800个批次，loss：0.00017667921201791614，acc：1.0\n",
      "整体验证集的acc：0.9938461780548096\n",
      "第7轮训练\n",
      "训练时间：695.785936832428\n",
      "第0个批次，loss：0.0026446038391441107，acc：1.0\n",
      "训练时间：709.1581847667694\n",
      "第100个批次，loss：0.002504008822143078，acc：1.0\n",
      "训练时间：722.532900094986\n",
      "第200个批次，loss：0.028907420113682747，acc：0.96875\n",
      "训练时间：735.922952413559\n",
      "第300个批次，loss：0.00027008395409211516，acc：1.0\n",
      "训练时间：749.309433221817\n",
      "第400个批次，loss：0.00025804858887568116，acc：1.0\n",
      "训练时间：762.7074913978577\n",
      "第500个批次，loss：0.0005756629980169237，acc：1.0\n",
      "训练时间：776.0905134677887\n",
      "第600个批次，loss：0.0008328977273777127，acc：1.0\n",
      "训练时间：789.50048828125\n",
      "第700个批次，loss：0.017062893137335777，acc：1.0\n",
      "训练时间：802.8979408740997\n",
      "第800个批次，loss：0.003940952476114035，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第8轮训练\n",
      "训练时间：812.4818122386932\n",
      "第0个批次，loss：0.005986510775983334，acc：1.0\n",
      "训练时间：825.8783047199249\n",
      "第100个批次，loss：0.0014217455172911286，acc：1.0\n",
      "训练时间：839.2776973247528\n",
      "第200个批次，loss：0.00033457271638326347，acc：1.0\n",
      "训练时间：852.6697132587433\n",
      "第300个批次，loss：0.005866332910954952，acc：1.0\n",
      "训练时间：866.0607273578644\n",
      "第400个批次，loss：0.000288823910523206，acc：1.0\n",
      "训练时间：879.4551560878754\n",
      "第500个批次，loss：0.0007594865746796131，acc：1.0\n",
      "训练时间：892.8526015281677\n",
      "第600个批次，loss：0.005163500085473061，acc：1.0\n",
      "训练时间：906.270877122879\n",
      "第700个批次，loss：0.0002698827884159982，acc：1.0\n",
      "训练时间：919.6679046154022\n",
      "第800个批次，loss：0.0001784543856047094，acc：1.0\n",
      "整体验证集的acc：0.9932692050933838\n",
      "第9轮训练\n",
      "训练时间：929.2479183673859\n",
      "第0个批次，loss：0.0024741042871028185，acc：1.0\n",
      "训练时间：942.6342561244965\n",
      "第100个批次，loss：0.04557328671216965，acc：0.96875\n",
      "训练时间：956.0240008831024\n",
      "第200个批次，loss：0.002115940907970071，acc：1.0\n",
      "训练时间：969.4298279285431\n",
      "第300个批次，loss：0.0004535927146207541，acc：1.0\n",
      "训练时间：982.8422591686249\n",
      "第400个批次，loss：0.0007336001726798713，acc：1.0\n",
      "训练时间：996.2378964424133\n",
      "第500个批次，loss：0.005796162411570549，acc：1.0\n",
      "训练时间：1009.6344499588013\n",
      "第600个批次，loss：0.0003735442296601832，acc：1.0\n",
      "训练时间：1023.049477815628\n",
      "第700个批次，loss：0.0007645572768524289，acc：1.0\n",
      "训练时间：1036.468029975891\n",
      "第800个批次，loss：0.00042721969657577574，acc：1.0\n",
      "整体验证集的acc：0.9932692050933838\n",
      "第10轮训练\n",
      "训练时间：1046.0731132030487\n",
      "第0个批次，loss：0.00036646894295699894，acc：1.0\n",
      "训练时间：1059.472375869751\n",
      "第100个批次，loss：0.00036918645491823554，acc：1.0\n",
      "训练时间：1072.8788261413574\n",
      "第200个批次，loss：0.0005794397438876331，acc：1.0\n",
      "训练时间：1086.2791652679443\n",
      "第300个批次，loss：0.00027675420278683305，acc：1.0\n",
      "训练时间：1099.6941666603088\n",
      "第400个批次，loss：0.0004559445078484714，acc：1.0\n",
      "训练时间：1113.0941967964172\n",
      "第500个批次，loss：0.000262049405137077，acc：1.0\n",
      "训练时间：1126.4934177398682\n",
      "第600个批次，loss：0.11030732840299606，acc：0.96875\n",
      "训练时间：1139.9074881076813\n",
      "第700个批次，loss：0.00017373009177390486，acc：1.0\n",
      "训练时间：1153.3107378482819\n",
      "第800个批次，loss：0.0006802363786846399，acc：1.0\n",
      "整体验证集的acc：0.9909615516662598\n",
      "第11轮训练\n",
      "训练时间：1162.998919725418\n",
      "第0个批次，loss：4.490932042244822e-05，acc：1.0\n",
      "训练时间：1176.4044160842896\n",
      "第100个批次，loss：0.0004491381987463683，acc：1.0\n",
      "训练时间：1189.7876245975494\n",
      "第200个批次，loss：6.048979048500769e-05，acc：1.0\n",
      "训练时间：1203.1929767131805\n",
      "第300个批次，loss：0.055914804339408875，acc：0.96875\n",
      "训练时间：1216.6114919185638\n",
      "第400个批次，loss：0.08828222751617432，acc：0.9375\n",
      "训练时间：1229.997355222702\n",
      "第500个批次，loss：0.00034484348725527525，acc：1.0\n",
      "训练时间：1243.4225211143494\n",
      "第600个批次，loss：0.0013904764782637358，acc：1.0\n",
      "训练时间：1256.9087171554565\n",
      "第700个批次，loss：0.042465005069971085，acc：1.0\n",
      "训练时间：1270.4067766666412\n",
      "第800个批次，loss：0.0033824408892542124，acc：1.0\n",
      "整体验证集的acc：0.992307722568512\n",
      "第12轮训练\n",
      "训练时间：1280.0909328460693\n",
      "第0个批次，loss：0.0002744613739196211，acc：1.0\n",
      "训练时间：1293.9626958370209\n",
      "第100个批次，loss：0.00041425731615163386，acc：1.0\n",
      "训练时间：1307.9414098262787\n",
      "第200个批次，loss：0.0006185941747389734，acc：1.0\n",
      "训练时间：1325.766711473465\n",
      "第300个批次，loss：0.0008553439402021468，acc：1.0\n",
      "训练时间：1343.7963817119598\n",
      "第400个批次，loss：0.01018627267330885，acc：1.0\n",
      "训练时间：1361.5864343643188\n",
      "第500个批次，loss：0.0006652123993262649，acc：1.0\n",
      "训练时间：1379.6700129508972\n",
      "第600个批次，loss：0.0680856704711914，acc：0.96875\n",
      "训练时间：1397.6856198310852\n",
      "第700个批次，loss：6.140334153315052e-05，acc：1.0\n",
      "训练时间：1415.8167569637299\n",
      "第800个批次，loss：0.0004211953782942146，acc：1.0\n",
      "整体验证集的acc：0.9921153783798218\n",
      "第13轮训练\n",
      "训练时间：1428.4175953865051\n",
      "第0个批次，loss：0.0003900667652487755，acc：1.0\n",
      "训练时间：1446.3254663944244\n",
      "第100个批次，loss：0.10494361817836761，acc：0.96875\n",
      "训练时间：1464.6326124668121\n",
      "第200个批次，loss：0.00011761544737964869，acc：1.0\n",
      "训练时间：1482.8382332324982\n",
      "第300个批次，loss：0.003081219969317317，acc：1.0\n",
      "训练时间：1501.0174028873444\n",
      "第400个批次，loss：0.0029354719445109367，acc：1.0\n",
      "训练时间：1519.3585526943207\n",
      "第500个批次，loss：0.0002990144130308181，acc：1.0\n",
      "训练时间：1537.4657287597656\n",
      "第600个批次，loss：6.892452074680477e-05，acc：1.0\n",
      "训练时间：1555.400001525879\n",
      "第700个批次，loss：0.0002361367514822632，acc：1.0\n",
      "训练时间：1573.6428093910217\n",
      "第800个批次，loss：0.0009001249563880265，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第14轮训练\n",
      "训练时间：1586.4296157360077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个批次，loss：7.117289351299405e-05，acc：1.0\n",
      "训练时间：1604.1926488876343\n",
      "第100个批次，loss：0.002512203762307763，acc：1.0\n",
      "训练时间：1622.3907589912415\n",
      "第200个批次，loss：8.328563126269728e-05，acc：1.0\n",
      "训练时间：1640.5152411460876\n",
      "第300个批次，loss：0.00577498646453023，acc：1.0\n",
      "训练时间：1657.9426884651184\n",
      "第400个批次，loss：0.00011476421786937863，acc：1.0\n",
      "训练时间：1671.5336391925812\n",
      "第500个批次，loss：0.000507502700202167，acc：1.0\n",
      "训练时间：1684.9866802692413\n",
      "第600个批次，loss：0.08327274024486542，acc：0.96875\n",
      "训练时间：1698.5476875305176\n",
      "第700个批次，loss：5.886698636459187e-05，acc：1.0\n",
      "训练时间：1712.0007348060608\n",
      "第800个批次，loss：0.00013121584197506309，acc：1.0\n",
      "整体验证集的acc：0.9938461780548096\n",
      "第15轮训练\n",
      "训练时间：1721.7193100452423\n",
      "第0个批次，loss：0.0002736698661465198，acc：1.0\n",
      "训练时间：1735.1936576366425\n",
      "第100个批次，loss：0.00016726850299164653，acc：1.0\n",
      "训练时间：1748.6936230659485\n",
      "第200个批次，loss：0.00012076574057573453，acc：1.0\n",
      "训练时间：1762.1971430778503\n",
      "第300个批次，loss：0.0022612314205616713，acc：1.0\n",
      "训练时间：1775.6272616386414\n",
      "第400个批次，loss：8.486748265568167e-05，acc：1.0\n",
      "训练时间：1789.0607233047485\n",
      "第500个批次，loss：0.016836069524288177，acc：1.0\n",
      "训练时间：1802.4935374259949\n",
      "第600个批次，loss：0.00029231494409032166，acc：1.0\n",
      "训练时间：1815.9253513813019\n",
      "第700个批次，loss：0.0006568522076122463，acc：1.0\n",
      "训练时间：1829.360402584076\n",
      "第800个批次，loss：0.0005184535402804613，acc：1.0\n",
      "整体验证集的acc：0.9938461780548096\n",
      "第16轮训练\n",
      "训练时间：1838.9627361297607\n",
      "第0个批次，loss：0.00037109851837158203，acc：1.0\n",
      "训练时间：1852.4243445396423\n",
      "第100个批次，loss：0.00030450025224126875，acc：1.0\n",
      "训练时间：1865.8704974651337\n",
      "第200个批次，loss：0.0005133622325956821，acc：1.0\n",
      "训练时间：1879.336148738861\n",
      "第300个批次，loss：0.028628339990973473，acc：0.96875\n",
      "训练时间：1892.773365020752\n",
      "第400个批次，loss：0.0010397336445748806，acc：1.0\n",
      "训练时间：1906.222041606903\n",
      "第500个批次，loss：0.0003709777956828475，acc：1.0\n",
      "训练时间：1919.6560809612274\n",
      "第600个批次，loss：0.0009292641188949347，acc：1.0\n",
      "训练时间：1933.0871148109436\n",
      "第700个批次，loss：0.00045200964086689055，acc：1.0\n",
      "训练时间：1946.5047397613525\n",
      "第800个批次，loss：0.0011820611543953419，acc：1.0\n",
      "整体验证集的acc：0.9917307496070862\n",
      "第17轮训练\n",
      "训练时间：1956.129059791565\n",
      "第0个批次，loss：0.0015468448400497437，acc：1.0\n",
      "训练时间：1969.6039004325867\n",
      "第100个批次，loss：7.484047819161788e-05，acc：1.0\n",
      "训练时间：1983.0610482692719\n",
      "第200个批次，loss：0.0005583647289313376，acc：1.0\n",
      "训练时间：1996.5047392845154\n",
      "第300个批次，loss：0.0369027704000473，acc：0.96875\n",
      "训练时间：2009.9357697963715\n",
      "第400个批次，loss：0.00021252159785944968，acc：1.0\n",
      "训练时间：2023.369877576828\n",
      "第500个批次，loss：0.005921805277466774，acc：1.0\n",
      "训练时间：2036.8028943538666\n",
      "第600个批次，loss：0.001553480513393879，acc：1.0\n",
      "训练时间：2050.2348709106445\n",
      "第700个批次，loss：0.0007072361768223345，acc：1.0\n",
      "训练时间：2063.668929576874\n",
      "第800个批次，loss：0.001181062194518745，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第18轮训练\n",
      "训练时间：2073.2745945453644\n",
      "第0个批次，loss：0.0002548524644225836，acc：1.0\n",
      "训练时间：2086.6998748779297\n",
      "第100个批次，loss：0.00033580069430172443，acc：1.0\n",
      "训练时间：2100.133391857147\n",
      "第200个批次，loss：0.0005761445499956608，acc：1.0\n",
      "训练时间：2113.582893848419\n",
      "第300个批次，loss：0.0012815288500860333，acc：1.0\n",
      "训练时间：2127.022937297821\n",
      "第400个批次，loss：0.00047549104783684015，acc：1.0\n",
      "训练时间：2140.4402923583984\n",
      "第500个批次，loss：9.185644739773124e-05，acc：1.0\n",
      "训练时间：2153.864009618759\n",
      "第600个批次，loss：0.0017204696778208017，acc：1.0\n",
      "训练时间：2167.3037548065186\n",
      "第700个批次，loss：0.00018505284970160574，acc：1.0\n",
      "训练时间：2180.747082233429\n",
      "第800个批次，loss：0.00015764558338560164，acc：1.0\n",
      "整体验证集的acc：0.9932692050933838\n",
      "第19轮训练\n",
      "训练时间：2190.4481523036957\n",
      "第0个批次，loss：0.00019397262076381594，acc：1.0\n",
      "训练时间：2203.8796379566193\n",
      "第100个批次，loss：0.01152102928608656，acc：1.0\n",
      "训练时间：2217.294866323471\n",
      "第200个批次，loss：6.209348066477105e-05，acc：1.0\n",
      "训练时间：2230.7283411026\n",
      "第300个批次，loss：0.017289750277996063，acc：1.0\n",
      "训练时间：2244.161781311035\n",
      "第400个批次，loss：0.0018879706040024757，acc：1.0\n",
      "训练时间：2257.592093229294\n",
      "第500个批次，loss：0.0004749812069348991，acc：1.0\n",
      "训练时间：2271.023486852646\n",
      "第600个批次，loss：0.0033464771695435047，acc：1.0\n",
      "训练时间：2284.459814786911\n",
      "第700个批次，loss：0.00029706794884987175，acc：1.0\n",
      "训练时间：2297.8762481212616\n",
      "第800个批次，loss：0.00011288363748462871，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第20轮训练\n",
      "训练时间：2307.446764230728\n",
      "第0个批次，loss：0.00041257977136410773，acc：1.0\n",
      "训练时间：2320.874434232712\n",
      "第100个批次，loss：0.0067833526991307735，acc：1.0\n",
      "训练时间：2334.307571411133\n",
      "第200个批次，loss：0.0034393146634101868，acc：1.0\n",
      "训练时间：2347.743602514267\n",
      "第300个批次，loss：7.586878928123042e-05，acc：1.0\n",
      "训练时间：2361.1560995578766\n",
      "第400个批次，loss：0.0010193726047873497，acc：1.0\n",
      "训练时间：2374.555575609207\n",
      "第500个批次，loss：0.002287648618221283，acc：1.0\n",
      "训练时间：2387.988314151764\n",
      "第600个批次，loss：0.00241749151609838，acc：1.0\n",
      "训练时间：2401.4218759536743\n",
      "第700个批次，loss：0.0004883190267719328，acc：1.0\n",
      "训练时间：2414.8541009426117\n",
      "第800个批次，loss：0.0002856649225577712，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第21轮训练\n",
      "训练时间：2424.51348900795\n",
      "第0个批次，loss：0.00048473142669536173，acc：1.0\n",
      "训练时间：2437.922073364258\n",
      "第100个批次，loss：0.0004880001361016184，acc：1.0\n",
      "训练时间：2451.353274822235\n",
      "第200个批次，loss：0.00029184261802583933，acc：1.0\n",
      "训练时间：2464.7870738506317\n",
      "第300个批次，loss：0.0023313548881560564，acc：1.0\n",
      "训练时间：2478.2127361297607\n",
      "第400个批次，loss：0.0023626419715583324，acc：1.0\n",
      "训练时间：2491.6351606845856\n",
      "第500个批次，loss：0.0021020174026489258，acc：1.0\n",
      "训练时间：2505.0683398246765\n",
      "第600个批次，loss：0.0006216894835233688，acc：1.0\n",
      "训练时间：2518.5013761520386\n",
      "第700个批次，loss：0.0010670782066881657，acc：1.0\n",
      "训练时间：2531.9348559379578\n",
      "第800个批次，loss：0.0004939681384712458，acc：1.0\n",
      "整体验证集的acc：0.9905769228935242\n",
      "第22轮训练\n",
      "训练时间：2541.5260198116302\n",
      "第0个批次，loss：0.00021220261987764388，acc：1.0\n",
      "训练时间：2554.948359489441\n",
      "第100个批次，loss：0.0005750679410994053，acc：1.0\n",
      "训练时间：2568.375397205353\n",
      "第200个批次，loss：0.00010725012543844059，acc：1.0\n",
      "训练时间：2581.8156514167786\n",
      "第300个批次，loss：0.00020928101730532944，acc：1.0\n",
      "训练时间：2595.248004436493\n",
      "第400个批次，loss：0.012629741802811623，acc：1.0\n",
      "训练时间：2608.681766271591\n",
      "第500个批次，loss：0.004651072900742292，acc：1.0\n",
      "训练时间：2622.113480567932\n",
      "第600个批次，loss：0.0024239791091531515，acc：1.0\n",
      "训练时间：2635.5318155288696\n",
      "第700个批次，loss：0.00030161134782247245，acc：1.0\n",
      "训练时间：2648.948124885559\n",
      "第800个批次，loss：0.0003380491107236594，acc：1.0\n",
      "整体验证集的acc：0.9917307496070862\n",
      "第23轮训练\n",
      "训练时间：2658.5597569942474\n",
      "第0个批次，loss：6.762098200852051e-05，acc：1.0\n",
      "训练时间：2671.9787890911102\n",
      "第100个批次，loss：0.0039808605797588825，acc：1.0\n",
      "训练时间：2685.413135290146\n",
      "第200个批次，loss：0.00032261910382658243，acc：1.0\n",
      "训练时间：2698.837171792984\n",
      "第300个批次，loss：0.01518294494599104，acc：1.0\n",
      "训练时间：2712.274707555771\n",
      "第400个批次，loss：0.0022831957321614027，acc：1.0\n",
      "训练时间：2725.694742202759\n",
      "第500个批次，loss：0.01771862991154194，acc：1.0\n",
      "训练时间：2739.1247782707214\n",
      "第600个批次，loss：0.0010718561243265867，acc：1.0\n",
      "训练时间：2752.5510897636414\n",
      "第700个批次，loss：0.0004746604827232659，acc：1.0\n",
      "训练时间：2765.9741327762604\n",
      "第800个批次，loss：0.00029497500509023666，acc：1.0\n",
      "整体验证集的acc：0.994038462638855\n",
      "第24轮训练\n",
      "训练时间：2775.5696873664856\n",
      "第0个批次，loss：0.003966942895203829，acc：1.0\n",
      "训练时间：2788.992692232132\n",
      "第100个批次，loss：0.002818761160597205，acc：1.0\n",
      "训练时间：2802.407148838043\n",
      "第200个批次，loss：0.1207081601023674，acc：0.96875\n",
      "训练时间：2815.84010887146\n",
      "第300个批次，loss：0.0018199264304712415，acc：1.0\n",
      "训练时间：2829.258459329605\n",
      "第400个批次，loss：0.01217709295451641，acc：1.0\n",
      "训练时间：2842.6889860630035\n",
      "第500个批次，loss：8.124529267661273e-05，acc：1.0\n",
      "训练时间：2856.1069111824036\n",
      "第600个批次，loss：0.00013712799409404397，acc：1.0\n",
      "训练时间：2869.5228667259216\n",
      "第700个批次，loss：0.000593737349845469，acc：1.0\n",
      "训练时间：2882.9401953220367\n",
      "第800个批次，loss：0.002649867907166481，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第25轮训练\n",
      "训练时间：2892.5343539714813\n",
      "第0个批次，loss：0.0013283112784847617，acc：1.0\n",
      "训练时间：2905.953984975815\n",
      "第100个批次，loss：0.0006557831657119095，acc：1.0\n",
      "训练时间：2919.3886399269104\n",
      "第200个批次，loss：0.05612300708889961，acc：0.96875\n",
      "训练时间：2932.8196692466736\n",
      "第300个批次，loss：0.0002403830731054768，acc：1.0\n",
      "训练时间：2946.254392385483\n",
      "第400个批次，loss：0.00011105470912298188，acc：1.0\n",
      "训练时间：2959.6868023872375\n",
      "第500个批次，loss：0.0001871984568424523，acc：1.0\n",
      "训练时间：2973.1208367347717\n",
      "第600个批次，loss：0.001370815560221672，acc：1.0\n",
      "训练时间：2986.5528666973114\n",
      "第700个批次，loss：0.00012038365821354091，acc：1.0\n",
      "训练时间：2999.9759860038757\n",
      "第800个批次，loss：0.0007116611232049763，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第26轮训练\n",
      "训练时间：3009.564146757126\n",
      "第0个批次，loss：0.0001518854551250115，acc：1.0\n",
      "训练时间：3022.984180688858\n",
      "第100个批次，loss：0.0005598384304903448，acc：1.0\n",
      "训练时间：3036.3988468647003\n",
      "第200个批次，loss：9.723383845994249e-05，acc：1.0\n",
      "训练时间：3049.8328371047974\n",
      "第300个批次，loss：9.628092811908573e-05，acc：1.0\n",
      "训练时间：3063.2668812274933\n",
      "第400个批次，loss：0.00017872918397188187，acc：1.0\n",
      "训练时间：3076.7009193897247\n",
      "第500个批次，loss：0.03483855351805687，acc：0.96875\n",
      "训练时间：3090.150192975998\n",
      "第600个批次，loss：0.011631972156465054，acc：1.0\n",
      "训练时间：3103.5813941955566\n",
      "第700个批次，loss：0.0018150897230952978，acc：1.0\n",
      "训练时间：3116.9954273700714\n",
      "第800个批次，loss：0.0001098611974157393，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第27轮训练\n",
      "训练时间：3126.587961912155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个批次，loss：0.0012874589301645756，acc：1.0\n",
      "训练时间：3140.0152881145477\n",
      "第100个批次，loss：0.0007043716032058001，acc：1.0\n",
      "训练时间：3153.4479537010193\n",
      "第200个批次，loss：0.00043669104343280196，acc：1.0\n",
      "训练时间：3166.880141019821\n",
      "第300个批次，loss：0.0007705349125899374，acc：1.0\n",
      "训练时间：3180.310334920883\n",
      "第400个批次，loss：0.0004682278377003968，acc：1.0\n",
      "训练时间：3193.727536201477\n",
      "第500个批次，loss：0.0004606911388691515，acc：1.0\n",
      "训练时间：3207.178811311722\n",
      "第600个批次，loss：0.03947019949555397，acc：0.96875\n",
      "训练时间：3220.6102130413055\n",
      "第700个批次，loss：0.01546352356672287，acc：1.0\n",
      "训练时间：3234.0268471240997\n",
      "第800个批次，loss：0.14786408841609955，acc：0.96875\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第28轮训练\n",
      "训练时间：3243.6520924568176\n",
      "第0个批次，loss：0.0018960575107485056，acc：1.0\n",
      "训练时间：3257.076639175415\n",
      "第100个批次，loss：0.011735886335372925，acc：1.0\n",
      "训练时间：3270.510722398758\n",
      "第200个批次，loss：0.0030698170885443687，acc：1.0\n",
      "训练时间：3283.959208726883\n",
      "第300个批次，loss：0.0006078804144635797，acc：1.0\n",
      "训练时间：3297.3933296203613\n",
      "第400个批次，loss：2.651077556947712e-05，acc：1.0\n",
      "训练时间：3310.825042247772\n",
      "第500个批次，loss：0.0013035973533988，acc：1.0\n",
      "训练时间：3324.2559666633606\n",
      "第600个批次，loss：9.20007296372205e-05，acc：1.0\n",
      "训练时间：3337.6899003982544\n",
      "第700个批次，loss：0.00043707151780836284，acc：1.0\n",
      "训练时间：3351.1049196720123\n",
      "第800个批次，loss：0.01540439948439598，acc：1.0\n",
      "整体验证集的acc：0.9915384650230408\n",
      "第29轮训练\n",
      "训练时间：3360.6874389648438\n",
      "第0个批次，loss：0.013069749809801579，acc：1.0\n",
      "训练时间：3374.1064908504486\n",
      "第100个批次，loss：0.0010056106839329004，acc：1.0\n",
      "训练时间：3387.533523082733\n",
      "第200个批次，loss：0.00021207579993642867，acc：1.0\n",
      "训练时间：3400.9551289081573\n",
      "第300个批次，loss：0.0008154890965670347，acc：1.0\n",
      "训练时间：3414.3891406059265\n",
      "第400个批次，loss：0.0001270074862986803，acc：1.0\n",
      "训练时间：3427.8198294639587\n",
      "第500个批次，loss：0.0006318163359537721，acc：1.0\n",
      "训练时间：3441.2528586387634\n",
      "第600个批次，loss：0.00046202613157220185，acc：1.0\n",
      "训练时间：3454.6865422725677\n",
      "第700个批次，loss：0.008965622633695602，acc：1.0\n",
      "训练时间：3468.119484424591\n",
      "第800个批次，loss：0.0002867444127332419，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第30轮训练\n",
      "训练时间：3477.705612897873\n",
      "第0个批次，loss：0.00015866136527620256，acc：1.0\n",
      "训练时间：3491.134527683258\n",
      "第100个批次，loss：0.003441825043410063，acc：1.0\n",
      "训练时间：3504.568766593933\n",
      "第200个批次，loss：0.042242784053087234，acc：1.0\n",
      "训练时间：3518.0188024044037\n",
      "第300个批次，loss：0.1068306565284729，acc：0.96875\n",
      "训练时间：3531.451255083084\n",
      "第400个批次，loss：7.95050582382828e-05，acc：1.0\n",
      "训练时间：3544.883181810379\n",
      "第500个批次，loss：0.09332282841205597，acc：0.96875\n",
      "训练时间：3558.315488100052\n",
      "第600个批次，loss：0.0001386104995617643，acc：1.0\n",
      "训练时间：3571.748986005783\n",
      "第700个批次，loss：0.01957918517291546，acc：1.0\n",
      "训练时间：3585.1587042808533\n",
      "第800个批次，loss：0.00476892339065671，acc：1.0\n",
      "整体验证集的acc：0.9936538338661194\n",
      "第31轮训练\n",
      "训练时间：3594.816009759903\n",
      "第0个批次，loss：0.0002614410186652094，acc：1.0\n",
      "训练时间：3608.250053167343\n",
      "第100个批次，loss：0.022784071043133736，acc：0.96875\n",
      "训练时间：3621.664882183075\n",
      "第200个批次，loss：0.00046094582648947835，acc：1.0\n",
      "训练时间：3635.081063270569\n",
      "第300个批次，loss：0.000385307299438864，acc：1.0\n",
      "训练时间：3648.5103557109833\n",
      "第400个批次，loss：0.0016260381089523435，acc：1.0\n",
      "训练时间：3661.9453892707825\n",
      "第500个批次，loss：0.0008853395702317357，acc：1.0\n",
      "训练时间：3675.3801963329315\n",
      "第600个批次，loss：0.00015162114868871868，acc：1.0\n",
      "训练时间：3688.8135035037994\n",
      "第700个批次，loss：0.0016466542147099972，acc：1.0\n",
      "训练时间：3702.2440207004547\n",
      "第800个批次，loss：0.004772847052663565，acc：1.0\n",
      "整体验证集的acc：0.993461549282074\n",
      "第32轮训练\n",
      "训练时间：3711.848202943802\n",
      "第0个批次，loss：0.010756977833807468，acc：1.0\n",
      "训练时间：3725.4804055690765\n",
      "第100个批次，loss：0.00023048449656926095，acc：1.0\n",
      "训练时间：3738.910433769226\n",
      "第200个批次，loss：0.0028460947796702385，acc：1.0\n",
      "训练时间：3752.3397345542908\n",
      "第300个批次，loss：0.0003121721383649856，acc：1.0\n",
      "训练时间：3765.775717496872\n",
      "第400个批次，loss：0.00034376830444671214，acc：1.0\n",
      "训练时间：3779.194177389145\n",
      "第500个批次，loss：0.0025574401952326298，acc：1.0\n",
      "训练时间：3792.605213880539\n",
      "第600个批次，loss：0.0017481744289398193，acc：1.0\n",
      "训练时间：3806.0245394706726\n",
      "第700个批次，loss：0.004317454993724823，acc：1.0\n",
      "训练时间：3819.4558503627777\n",
      "第800个批次，loss：0.00019812247774098068，acc：1.0\n",
      "整体验证集的acc：0.993461549282074\n",
      "第33轮训练\n",
      "训练时间：3829.0403089523315\n",
      "第0个批次，loss：0.014112054370343685，acc：1.0\n",
      "训练时间：3842.4709043502808\n",
      "第100个批次，loss：0.008417216129601002，acc：1.0\n",
      "训练时间：3855.90717625618\n",
      "第200个批次，loss：0.008377863094210625，acc：1.0\n",
      "训练时间：3869.335173368454\n",
      "第300个批次，loss：0.04050181061029434，acc：1.0\n",
      "训练时间：3882.771214723587\n",
      "第400个批次，loss：5.169197902432643e-05，acc：1.0\n",
      "训练时间：3896.1872787475586\n",
      "第500个批次，loss：0.0011499414686113596，acc：1.0\n",
      "训练时间：3909.6286594867706\n",
      "第600个批次，loss：0.08772594481706619，acc：0.96875\n",
      "训练时间：3923.054237127304\n",
      "第700个批次，loss：3.6786423152079806e-05，acc：1.0\n",
      "训练时间：3936.4705226421356\n",
      "第800个批次，loss：0.0004802252515219152，acc：1.0\n",
      "整体验证集的acc：0.9944230914115906\n",
      "第34轮训练\n",
      "训练时间：3946.058680295944\n",
      "第0个批次，loss：0.002168022794649005，acc：1.0\n",
      "训练时间：3959.483633041382\n",
      "第100个批次，loss：0.00012530024105217308，acc：1.0\n",
      "训练时间：3972.9041340351105\n",
      "第200个批次，loss：0.00010677098907763138，acc：1.0\n",
      "训练时间：3986.346248626709\n",
      "第300个批次，loss：0.00029915617778897285，acc：1.0\n",
      "训练时间：3999.7650566101074\n",
      "第400个批次，loss：0.0012617389438673854，acc：1.0\n",
      "训练时间：4013.181704759598\n",
      "第500个批次，loss：0.0007340681622736156，acc：1.0\n",
      "训练时间：4026.618158340454\n",
      "第600个批次，loss：0.0010138091165572405，acc：1.0\n",
      "训练时间：4040.0491902828217\n",
      "第700个批次，loss：0.0010592967737466097，acc：1.0\n",
      "训练时间：4053.4662268161774\n",
      "第800个批次，loss：0.03849094733595848，acc：0.96875\n",
      "整体验证集的acc：0.992884635925293\n",
      "第35轮训练\n",
      "训练时间：4063.067390203476\n",
      "第0个批次，loss：6.557484448421746e-05，acc：1.0\n",
      "训练时间：4076.493423938751\n",
      "第100个批次，loss：0.0001351799292024225，acc：1.0\n",
      "训练时间：4089.914289712906\n",
      "第200个批次，loss：0.011315404437482357，acc：1.0\n",
      "训练时间：4103.344307899475\n",
      "第300个批次，loss：0.004198750946670771，acc：1.0\n",
      "训练时间：4116.764308214188\n",
      "第400个批次，loss：9.122648043558002e-05，acc：1.0\n",
      "训练时间：4130.195336818695\n",
      "第500个批次，loss：0.0012885219184681773，acc：1.0\n",
      "训练时间：4143.617926120758\n",
      "第600个批次，loss：0.004516481887549162，acc：1.0\n",
      "训练时间：4157.059882640839\n",
      "第700个批次，loss：0.0004611499316524714，acc：1.0\n",
      "训练时间：4170.496555805206\n",
      "第800个批次，loss：0.0009506039787083864，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第36轮训练\n",
      "训练时间：4180.062709093094\n",
      "第0个批次，loss：0.02669215388596058，acc：0.96875\n",
      "训练时间：4193.49302482605\n",
      "第100个批次，loss：0.012900631874799728，acc：1.0\n",
      "训练时间：4206.9284336566925\n",
      "第200个批次，loss：0.000625002256128937，acc：1.0\n",
      "训练时间：4220.361018896103\n",
      "第300个批次，loss：0.03606647253036499，acc：0.96875\n",
      "训练时间：4233.795234680176\n",
      "第400个批次，loss：0.004509351681917906，acc：1.0\n",
      "训练时间：4247.234746456146\n",
      "第500个批次，loss：0.00018092204118147492，acc：1.0\n",
      "训练时间：4260.660091638565\n",
      "第600个批次，loss：0.0011931322515010834，acc：1.0\n",
      "训练时间：4274.108511209488\n",
      "第700个批次，loss：0.000574026140384376，acc：1.0\n",
      "训练时间：4287.542546987534\n",
      "第800个批次，loss：0.0015890623908489943，acc：1.0\n",
      "整体验证集的acc：0.9930769205093384\n",
      "第37轮训练\n",
      "训练时间：4297.1456706523895\n",
      "第0个批次，loss：0.00023000284272711724，acc：1.0\n",
      "训练时间：4310.587500095367\n",
      "第100个批次，loss：0.00026859587524086237，acc：1.0\n",
      "训练时间：4324.008727788925\n",
      "第200个批次，loss：0.00015074864495545626，acc：1.0\n",
      "训练时间：4337.431770324707\n",
      "第300个批次，loss：8.027727744774893e-05，acc：1.0\n",
      "训练时间：4350.857286930084\n",
      "第400个批次，loss：0.00756949745118618，acc：1.0\n",
      "训练时间：4364.2727663517\n",
      "第500个批次，loss：0.00020074049825780094，acc：1.0\n",
      "训练时间：4377.705317974091\n",
      "第600个批次，loss：0.010308122262358665，acc：1.0\n",
      "训练时间：4391.154353618622\n",
      "第700个批次，loss：0.0005505058798007667，acc：1.0\n",
      "训练时间：4404.604158163071\n",
      "第800个批次，loss：0.0012323303380981088，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第38轮训练\n",
      "训练时间：4414.19433760643\n",
      "第0个批次，loss：0.0004678610130213201，acc：1.0\n",
      "训练时间：4427.635751008987\n",
      "第100个批次，loss：0.005070497747510672，acc：1.0\n",
      "训练时间：4441.0707750320435\n",
      "第200个批次，loss：0.021803075447678566，acc：1.0\n",
      "训练时间：4454.504277467728\n",
      "第300个批次，loss：0.00046297669177874923，acc：1.0\n",
      "训练时间：4467.919315099716\n",
      "第400个批次，loss：0.003451022319495678，acc：1.0\n",
      "训练时间：4481.350782394409\n",
      "第500个批次，loss：0.004782794509083033，acc：1.0\n",
      "训练时间：4494.782100439072\n",
      "第600个批次，loss：0.0007371443207375705，acc：1.0\n",
      "训练时间：4508.233282089233\n",
      "第700个批次，loss：0.0007737044943496585，acc：1.0\n",
      "训练时间：4521.681039571762\n",
      "第800个批次，loss：0.0019524390809237957，acc：1.0\n",
      "整体验证集的acc：0.9913461804389954\n",
      "第39轮训练\n",
      "训练时间：4531.262206792831\n",
      "第0个批次，loss：0.00046935532009229064，acc：1.0\n",
      "训练时间：4544.700237751007\n",
      "第100个批次，loss：0.11918178200721741，acc：0.96875\n",
      "训练时间：4558.114510297775\n",
      "第200个批次，loss：0.006785502657294273，acc：1.0\n",
      "训练时间：4571.533628463745\n",
      "第300个批次，loss：0.0002340312348678708，acc：1.0\n",
      "训练时间：4585.090860128403\n",
      "第400个批次，loss：0.001327883335761726，acc：1.0\n",
      "训练时间：4598.531103372574\n",
      "第500个批次，loss：0.0003263754188083112，acc：1.0\n",
      "训练时间：4611.981065988541\n",
      "第600个批次，loss：0.00036949425702914596，acc：1.0\n",
      "训练时间：4625.420358657837\n",
      "第700个批次，loss：0.1733541339635849，acc：0.96875\n",
      "训练时间：4638.845432758331\n",
      "第800个批次，loss：0.0002699824399314821，acc：1.0\n",
      "整体验证集的acc：0.9913461804389954\n",
      "第40轮训练\n",
      "训练时间：4648.443699598312\n",
      "第0个批次，loss：0.001930768834426999，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：4661.862091302872\n",
      "第100个批次，loss：0.0004893938312307，acc：1.0\n",
      "训练时间：4675.2942016124725\n",
      "第200个批次，loss：0.0022194876801222563，acc：1.0\n",
      "训练时间：4688.7111649513245\n",
      "第300个批次，loss：0.00027400217368267477，acc：1.0\n",
      "训练时间：4702.178187608719\n",
      "第400个批次，loss：0.00015193417493719608，acc：1.0\n",
      "训练时间：4715.611217260361\n",
      "第500个批次，loss：0.0011453562183305621，acc：1.0\n",
      "训练时间：4729.0442481040955\n",
      "第600个批次，loss：0.0014125378802418709，acc：1.0\n",
      "训练时间：4742.4623737335205\n",
      "第700个批次，loss：0.0031774877570569515，acc：1.0\n",
      "训练时间：4755.927410840988\n",
      "第800个批次，loss：0.04578113928437233，acc：0.96875\n",
      "整体验证集的acc：0.992307722568512\n",
      "第41轮训练\n",
      "训练时间：4765.600052595139\n",
      "第0个批次，loss：0.0002033763303188607，acc：1.0\n",
      "训练时间：4779.042776823044\n",
      "第100个批次，loss：0.00589069165289402，acc：1.0\n",
      "训练时间：4792.4610340595245\n",
      "第200个批次，loss：0.00014652185200247914，acc：1.0\n",
      "训练时间：4805.8924741744995\n",
      "第300个批次，loss：0.000479242269648239，acc：1.0\n",
      "训练时间：4819.325898170471\n",
      "第400个批次，loss：0.0017009201692417264，acc：1.0\n",
      "训练时间：4832.772933959961\n",
      "第500个批次，loss：0.0014120076084509492，acc：1.0\n",
      "训练时间：4846.224929094315\n",
      "第600个批次，loss：0.001516479765996337，acc：1.0\n",
      "训练时间：4859.656154870987\n",
      "第700个批次，loss：0.0322568453848362，acc：0.96875\n",
      "训练时间：4873.104523420334\n",
      "第800个批次，loss：0.03284028172492981，acc：1.0\n",
      "整体验证集的acc：0.9907692074775696\n",
      "第42轮训练\n",
      "训练时间：4882.69868183136\n",
      "第0个批次，loss：0.00015355669893324375，acc：1.0\n",
      "训练时间：4896.136711359024\n",
      "第100个批次，loss：0.001501375576481223，acc：1.0\n",
      "训练时间：4909.573776006699\n",
      "第200个批次，loss：0.059487827122211456，acc：1.0\n",
      "训练时间：4923.006949663162\n",
      "第300个批次，loss：0.0003109244571533054，acc：1.0\n",
      "训练时间：4936.4389617443085\n",
      "第400个批次，loss：0.00015792528574820608，acc：1.0\n",
      "训练时间：4949.888757228851\n",
      "第500个批次，loss：0.011758263222873211，acc：1.0\n",
      "训练时间：4963.338307142258\n",
      "第600个批次，loss：0.0003101998590864241，acc：1.0\n",
      "训练时间：4976.786025047302\n",
      "第700个批次，loss：0.000350230373442173，acc：1.0\n",
      "训练时间：4990.252080202103\n",
      "第800个批次，loss：0.002148378873243928，acc：1.0\n",
      "整体验证集的acc：0.9930769205093384\n",
      "第43轮训练\n",
      "训练时间：4999.950397491455\n",
      "第0个批次，loss：0.00028304880834184587，acc：1.0\n",
      "训练时间：5013.400844573975\n",
      "第100个批次，loss：0.007265165448188782，acc：1.0\n",
      "训练时间：5026.851474523544\n",
      "第200个批次，loss：0.007219737395644188，acc：1.0\n",
      "训练时间：5040.334832191467\n",
      "第300个批次，loss：8.753712609177455e-05，acc：1.0\n",
      "训练时间：5053.785090446472\n",
      "第400个批次，loss：0.0033194185234606266，acc：1.0\n",
      "训练时间：5067.217119932175\n",
      "第500个批次，loss：0.0005487255984917283，acc：1.0\n",
      "训练时间：5080.649347782135\n",
      "第600个批次，loss：9.127302473643795e-05，acc：1.0\n",
      "训练时间：5094.1013786792755\n",
      "第700个批次，loss：0.049041446298360825，acc：0.96875\n",
      "训练时间：5107.573642253876\n",
      "第800个批次，loss：0.00010333989484934136，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第44轮训练\n",
      "训练时间：5117.200575351715\n",
      "第0个批次，loss：7.396764704026282e-05，acc：1.0\n",
      "训练时间：5130.636757612228\n",
      "第100个批次，loss：0.0001988980220630765，acc：1.0\n",
      "训练时间：5144.0712740421295\n",
      "第200个批次，loss：0.0038093600887805223，acc：1.0\n",
      "训练时间：5157.525405406952\n",
      "第300个批次，loss：0.041601844131946564，acc：0.96875\n",
      "训练时间：5170.9814331531525\n",
      "第400个批次，loss：7.793930126354098e-05，acc：1.0\n",
      "训练时间：5184.418626070023\n",
      "第500个批次，loss：0.0018855863017961383，acc：1.0\n",
      "训练时间：5197.872961521149\n",
      "第600个批次，loss：0.0010468818945810199，acc：1.0\n",
      "训练时间：5211.311995983124\n",
      "第700个批次，loss：0.00020396684703882784，acc：1.0\n",
      "训练时间：5224.779530286789\n",
      "第800个批次，loss：0.00010164934064960107，acc：1.0\n",
      "整体验证集的acc：0.9932692050933838\n",
      "第45轮训练\n",
      "训练时间：5234.411987066269\n",
      "第0个批次，loss：0.0003182442451361567，acc：1.0\n",
      "训练时间：5247.859654426575\n",
      "第100个批次，loss：0.011340825818479061，acc：1.0\n",
      "训练时间：5261.32884311676\n",
      "第200个批次，loss：0.000374477676814422，acc：1.0\n",
      "训练时间：5274.793230056763\n",
      "第300个批次，loss：0.06585314124822617，acc：0.96875\n",
      "训练时间：5288.242596626282\n",
      "第400个批次，loss：0.0016468706307932734，acc：1.0\n",
      "训练时间：5301.744384288788\n",
      "第500个批次，loss：0.00026196619728580117，acc：1.0\n",
      "训练时间：5315.239401102066\n",
      "第600个批次，loss：0.000602686544880271，acc：1.0\n",
      "训练时间：5328.710779428482\n",
      "第700个批次，loss：0.0005019692471250892，acc：1.0\n",
      "训练时间：5342.159273862839\n",
      "第800个批次，loss：0.07829833030700684，acc：0.96875\n",
      "整体验证集的acc：0.992307722568512\n",
      "第46轮训练\n",
      "训练时间：5351.801923036575\n",
      "第0个批次，loss：0.0007965413969941437，acc：1.0\n",
      "训练时间：5365.256340742111\n",
      "第100个批次，loss：0.0002257237647427246，acc：1.0\n",
      "训练时间：5378.714271306992\n",
      "第200个批次，loss：0.008289379999041557，acc：1.0\n",
      "训练时间：5392.155308008194\n",
      "第300个批次，loss：0.0038235883694142103，acc：1.0\n",
      "训练时间：5405.605565071106\n",
      "第400个批次，loss：0.006443573161959648，acc：1.0\n",
      "训练时间：5419.056205749512\n",
      "第500个批次，loss：7.822929183021188e-05，acc：1.0\n",
      "训练时间：5432.5072457790375\n",
      "第600个批次，loss：0.00024158232554327697，acc：1.0\n",
      "训练时间：5445.95729470253\n",
      "第700个批次，loss：5.9679037804016843e-05，acc：1.0\n",
      "训练时间：5459.393744945526\n",
      "第800个批次，loss：0.000278354185866192，acc：1.0\n",
      "整体验证集的acc：0.992307722568512\n",
      "第47轮训练\n",
      "训练时间：5469.031224727631\n",
      "第0个批次，loss：0.0007103047100827098，acc：1.0\n",
      "训练时间：5482.487263679504\n",
      "第100个批次，loss：0.0011211063247174025，acc：1.0\n",
      "训练时间：5495.9351189136505\n",
      "第200个批次，loss：0.02367016300559044，acc：1.0\n",
      "训练时间：5509.368644237518\n",
      "第300个批次，loss：0.0052551161497831345，acc：1.0\n",
      "训练时间：5522.841651201248\n",
      "第400个批次，loss：6.207244587130845e-05，acc：1.0\n",
      "训练时间：5536.268986463547\n",
      "第500个批次，loss：0.00010289361671311781，acc：1.0\n",
      "训练时间：5549.701933860779\n",
      "第600个批次，loss：0.0028037813026458025，acc：1.0\n",
      "训练时间：5563.1994688510895\n",
      "第700个批次，loss：0.00027205038350075483，acc：1.0\n",
      "训练时间：5576.66730761528\n",
      "第800个批次，loss：0.002868032781407237，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第48轮训练\n",
      "训练时间：5586.287996768951\n",
      "第0个批次，loss：0.0010194244096055627，acc：1.0\n",
      "训练时间：5599.731083393097\n",
      "第100个批次，loss：0.00011497820378281176，acc：1.0\n",
      "训练时间：5613.1636209487915\n",
      "第200个批次，loss：0.02132737822830677，acc：1.0\n",
      "训练时间：5626.596652507782\n",
      "第300个批次，loss：0.00036712040309794247，acc：1.0\n",
      "训练时间：5640.0306849479675\n",
      "第400个批次，loss：0.0001524671824881807，acc：1.0\n",
      "训练时间：5653.463339567184\n",
      "第500个批次，loss：0.0001116320418077521，acc：1.0\n",
      "训练时间：5666.89470243454\n",
      "第600个批次，loss：0.0007461551576852798，acc：1.0\n",
      "训练时间：5680.361674547195\n",
      "第700个批次，loss：0.059197209775447845，acc：0.96875\n",
      "训练时间：5693.794965028763\n",
      "第800个批次，loss：0.0005963795119896531，acc：1.0\n",
      "整体验证集的acc：0.9917307496070862\n",
      "第49轮训练\n",
      "训练时间：5703.4231469631195\n",
      "第0个批次，loss：0.0008741361671127379，acc：1.0\n",
      "训练时间：5716.860626220703\n",
      "第100个批次，loss：0.0010352743556722999，acc：1.0\n",
      "训练时间：5730.294662237167\n",
      "第200个批次，loss：0.00021376977383624762，acc：1.0\n",
      "训练时间：5743.729690074921\n",
      "第300个批次，loss：0.00014793078298680484，acc：1.0\n",
      "训练时间：5757.17685675621\n",
      "第400个批次，loss：0.0075120809487998486，acc：1.0\n",
      "训练时间：5770.640379667282\n",
      "第500个批次，loss：0.0013715128879994154，acc：1.0\n",
      "训练时间：5784.095490932465\n",
      "第600个批次，loss：0.0008386304252780974，acc：1.0\n",
      "训练时间：5797.523803472519\n",
      "第700个批次，loss：0.0003881125303450972，acc：1.0\n",
      "训练时间：5810.9898381233215\n",
      "第800个批次，loss：0.0001441853673895821，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第50轮训练\n",
      "训练时间：5820.6160135269165\n",
      "第0个批次，loss：0.0002308493567397818，acc：1.0\n",
      "训练时间：5834.073225021362\n",
      "第100个批次，loss：0.0021157709416002035，acc：1.0\n",
      "训练时间：5847.507263422012\n",
      "第200个批次，loss：0.0003638724738266319，acc：1.0\n",
      "训练时间：5860.938326120377\n",
      "第300个批次，loss：0.0002981804427690804，acc：1.0\n",
      "训练时间：5874.371812105179\n",
      "第400个批次，loss：0.00028371234657242894，acc：1.0\n",
      "训练时间：5887.837974309921\n",
      "第500个批次，loss：0.009344538673758507，acc：1.0\n",
      "训练时间：5901.290434122086\n",
      "第600个批次，loss：0.004470333456993103，acc：1.0\n",
      "训练时间：5914.721461057663\n",
      "第700个批次，loss：6.746050348738208e-05，acc：1.0\n",
      "训练时间：5928.154541492462\n",
      "第800个批次，loss：0.00030430208425968885，acc：1.0\n",
      "整体验证集的acc：0.993461549282074\n",
      "第51轮训练\n",
      "训练时间：5937.823208332062\n",
      "第0个批次，loss：8.98124126251787e-05，acc：1.0\n",
      "训练时间：5951.256261348724\n",
      "第100个批次，loss：0.0007875940063968301，acc：1.0\n",
      "训练时间：5964.686516046524\n",
      "第200个批次，loss：0.00022438319865614176，acc：1.0\n",
      "训练时间：5978.131553888321\n",
      "第300个批次，loss：0.0007289783679880202，acc：1.0\n",
      "训练时间：5991.571594953537\n",
      "第400个批次，loss：0.0001472426811233163，acc：1.0\n",
      "训练时间：6005.01044344902\n",
      "第500个批次，loss：0.00015870532661210746，acc：1.0\n",
      "训练时间：6018.434480905533\n",
      "第600个批次，loss：0.048754848539829254，acc：0.96875\n",
      "训练时间：6031.866671800613\n",
      "第700个批次，loss：0.0015603838255628943，acc：1.0\n",
      "训练时间：6045.300227880478\n",
      "第800个批次，loss：9.771389159141108e-05，acc：1.0\n",
      "整体验证集的acc：0.9921153783798218\n",
      "第52轮训练\n",
      "训练时间：6054.919516086578\n",
      "第0个批次，loss：0.007314165588468313，acc：1.0\n",
      "训练时间：6068.3667578697205\n",
      "第100个批次，loss：0.0009723399998620152，acc：1.0\n",
      "训练时间：6081.802023410797\n",
      "第200个批次，loss：0.0004996739444322884，acc：1.0\n",
      "训练时间：6095.264036417007\n",
      "第300个批次，loss：0.004661232698708773，acc：1.0\n",
      "训练时间：6108.717622041702\n",
      "第400个批次，loss：0.0006128911045379937，acc：1.0\n",
      "训练时间：6122.160049200058\n",
      "第500个批次，loss：0.00043272311449982226，acc：1.0\n",
      "训练时间：6135.614992141724\n",
      "第600个批次，loss：0.00025774785899557173，acc：1.0\n",
      "训练时间：6149.047296047211\n",
      "第700个批次，loss：0.0033746915869414806，acc：1.0\n",
      "训练时间：6162.50962638855\n",
      "第800个批次，loss：0.002319403924047947，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第53轮训练\n",
      "训练时间：6172.110791444778\n",
      "第0个批次，loss：0.0004702586156781763，acc：1.0\n",
      "训练时间：6185.579056978226\n",
      "第100个批次，loss：0.00025196681963279843，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：6199.046786308289\n",
      "第200个批次，loss：0.0020281870383769274，acc：1.0\n",
      "训练时间：6212.506072759628\n",
      "第300个批次，loss：0.0006919255829416215，acc：1.0\n",
      "训练时间：6225.956276416779\n",
      "第400个批次，loss：0.0004077463527210057，acc：1.0\n",
      "训练时间：6239.39754986763\n",
      "第500个批次，loss：0.023928433656692505，acc：1.0\n",
      "训练时间：6252.843821048737\n",
      "第600个批次，loss：0.00047784161870367825，acc：1.0\n",
      "训练时间：6266.483976840973\n",
      "第700个批次，loss：0.0006291915779002011，acc：1.0\n",
      "训练时间：6280.023343324661\n",
      "第800个批次，loss：0.0006281792302615941，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第54轮训练\n",
      "训练时间：6289.844787836075\n",
      "第0个批次，loss：0.014324424788355827，acc：1.0\n",
      "训练时间：6303.354083538055\n",
      "第100个批次，loss：0.002022204454988241，acc：1.0\n",
      "训练时间：6317.037308931351\n",
      "第200个批次，loss：0.0007515703910030425，acc：1.0\n",
      "训练时间：6330.536913871765\n",
      "第300个批次，loss：0.0003848181222565472，acc：1.0\n",
      "训练时间：6344.092864990234\n",
      "第400个批次，loss：0.027662673965096474，acc：0.96875\n",
      "训练时间：6357.574856519699\n",
      "第500个批次，loss：0.00046578014735132456，acc：1.0\n",
      "训练时间：6371.09867978096\n",
      "第600个批次，loss：0.00065270671620965，acc：1.0\n",
      "训练时间：6384.571023464203\n",
      "第700个批次，loss：0.00012454473471734673，acc：1.0\n",
      "训练时间：6398.08394575119\n",
      "第800个批次，loss：0.0014523993013426661，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第55轮训练\n",
      "训练时间：6407.7496082782745\n",
      "第0个批次，loss：0.00014677387662231922，acc：1.0\n",
      "训练时间：6421.254424333572\n",
      "第100个批次，loss：0.00022721714049112052，acc：1.0\n",
      "训练时间：6434.846944570541\n",
      "第200个批次，loss：0.003929829690605402，acc：1.0\n",
      "训练时间：6449.061192274094\n",
      "第300个批次，loss：0.0005213639815337956，acc：1.0\n",
      "训练时间：6462.620655298233\n",
      "第400个批次，loss：0.0002585689362604171，acc：1.0\n",
      "训练时间：6476.153235912323\n",
      "第500个批次，loss：7.084514072630554e-05，acc：1.0\n",
      "训练时间：6490.075480699539\n",
      "第600个批次，loss：0.00012650477583520114，acc：1.0\n",
      "训练时间：6503.847431898117\n",
      "第700个批次，loss：7.828571688150987e-05，acc：1.0\n",
      "训练时间：6517.765098333359\n",
      "第800个批次，loss：0.010424206964671612，acc：1.0\n",
      "整体验证集的acc：0.994038462638855\n",
      "第56轮训练\n",
      "训练时间：6527.46128153801\n",
      "第0个批次，loss：0.007270112633705139，acc：1.0\n",
      "训练时间：6540.974333763123\n",
      "第100个批次，loss：0.002549459459260106，acc：1.0\n",
      "训练时间：6554.6110100746155\n",
      "第200个批次，loss：0.046625323593616486，acc：0.96875\n",
      "训练时间：6568.051412343979\n",
      "第300个批次，loss：8.559045090805739e-05，acc：1.0\n",
      "训练时间：6581.614057540894\n",
      "第400个批次，loss：0.003039595438167453，acc：1.0\n",
      "训练时间：6595.158584117889\n",
      "第500个批次，loss：0.0010365362977609038，acc：1.0\n",
      "训练时间：6608.6773228645325\n",
      "第600个批次，loss：0.0005584164755418897，acc：1.0\n",
      "训练时间：6622.144695281982\n",
      "第700个批次，loss：0.00011805199756054208，acc：1.0\n",
      "训练时间：6635.680759191513\n",
      "第800个批次，loss：0.00041929312283173203，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第57轮训练\n",
      "训练时间：6645.3759479522705\n",
      "第0个批次，loss：0.00015606751549057662，acc：1.0\n",
      "训练时间：6658.848616838455\n",
      "第100个批次，loss：0.0004990968736819923，acc：1.0\n",
      "训练时间：6672.420682430267\n",
      "第200个批次，loss：0.001283641206100583，acc：1.0\n",
      "训练时间：6686.280458211899\n",
      "第300个批次，loss：0.00045002621482126415，acc：1.0\n",
      "训练时间：6700.259889602661\n",
      "第400个批次，loss：4.8308211262337863e-05，acc：1.0\n",
      "训练时间：6713.837929964066\n",
      "第500个批次，loss：0.0029226511251181364，acc：1.0\n",
      "训练时间：6727.2940130233765\n",
      "第600个批次，loss：0.005907183047384024，acc：1.0\n",
      "训练时间：6740.746123075485\n",
      "第700个批次，loss：0.004308077972382307，acc：1.0\n",
      "训练时间：6754.210556030273\n",
      "第800个批次，loss：0.000591884134337306，acc：1.0\n",
      "整体验证集的acc：0.994038462638855\n",
      "第58轮训练\n",
      "训练时间：6763.968034029007\n",
      "第0个批次，loss：0.00023627429618500173，acc：1.0\n",
      "训练时间：6777.409056901932\n",
      "第100个批次，loss：0.0011239064624533057，acc：1.0\n",
      "训练时间：6790.8745703697205\n",
      "第200个批次，loss：0.030212391167879105，acc：0.96875\n",
      "训练时间：6804.326608181\n",
      "第300个批次，loss：0.0008618463180027902，acc：1.0\n",
      "训练时间：6817.811950922012\n",
      "第400个批次，loss：0.00022966130927670747，acc：1.0\n",
      "训练时间：6831.246304273605\n",
      "第500个批次，loss：0.001783761428669095，acc：1.0\n",
      "训练时间：6844.690286159515\n",
      "第600个批次，loss：0.00016443747153971344，acc：1.0\n",
      "训练时间：6858.139709472656\n",
      "第700个批次，loss：0.0005963023286312819，acc：1.0\n",
      "训练时间：6871.589945793152\n",
      "第800个批次，loss：0.0017679538577795029，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第59轮训练\n",
      "训练时间：6881.280136346817\n",
      "第0个批次，loss：0.0024277938064187765，acc：1.0\n",
      "训练时间：6894.705169916153\n",
      "第100个批次，loss：0.0004315944679547101，acc：1.0\n",
      "训练时间：6908.185221672058\n",
      "第200个批次，loss：0.0002463521377649158，acc：1.0\n",
      "训练时间：6921.637368679047\n",
      "第300个批次，loss：0.0004632528289221227，acc：1.0\n",
      "训练时间：6935.092401504517\n",
      "第400个批次，loss：0.0029748487286269665，acc：1.0\n",
      "训练时间：6948.57099199295\n",
      "第500个批次，loss：0.0009541974286548793，acc：1.0\n",
      "训练时间：6962.051275730133\n",
      "第600个批次，loss：0.0001035437744576484，acc：1.0\n",
      "训练时间：6975.505865097046\n",
      "第700个批次，loss：0.00017131549248006195，acc：1.0\n",
      "训练时间：6988.971319675446\n",
      "第800个批次，loss：3.1445353670278564e-05，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第60轮训练\n",
      "训练时间：6998.592485666275\n",
      "第0个批次，loss：0.002111562294885516，acc：1.0\n",
      "训练时间：7012.021542787552\n",
      "第100个批次，loss：0.003945318050682545，acc：1.0\n",
      "训练时间：7025.491681814194\n",
      "第200个批次，loss：0.007714113220572472，acc：1.0\n",
      "训练时间：7038.9509036540985\n",
      "第300个批次，loss：0.00043121245107613504，acc：1.0\n",
      "训练时间：7052.400255680084\n",
      "第400个批次，loss：0.0012208025436848402，acc：1.0\n",
      "训练时间：7065.8496832847595\n",
      "第500个批次，loss：0.0007876630406826735，acc：1.0\n",
      "训练时间：7079.2986698150635\n",
      "第600个批次，loss：0.0004370773967821151，acc：1.0\n",
      "训练时间：7092.779689788818\n",
      "第700个批次，loss：0.0056292093358933926，acc：1.0\n",
      "训练时间：7106.272180318832\n",
      "第800个批次，loss：0.029753226786851883，acc：1.0\n",
      "整体验证集的acc：0.994038462638855\n",
      "第61轮训练\n",
      "训练时间：7116.347453594208\n",
      "第0个批次，loss：0.02176412008702755，acc：1.0\n",
      "训练时间：7130.269596815109\n",
      "第100个批次，loss：0.0021983354818075895，acc：1.0\n",
      "训练时间：7143.982403993607\n",
      "第200个批次，loss：8.00283596618101e-05，acc：1.0\n",
      "训练时间：7157.8701338768005\n",
      "第300个批次，loss：0.002965871710330248，acc：1.0\n",
      "训练时间：7171.599803924561\n",
      "第400个批次，loss：0.08946659415960312，acc：0.96875\n",
      "训练时间：7185.4463222026825\n",
      "第500个批次，loss：0.00727829709649086，acc：1.0\n",
      "训练时间：7198.934545040131\n",
      "第600个批次，loss：0.00010255038796458393，acc：1.0\n",
      "训练时间：7212.478079557419\n",
      "第700个批次，loss：0.002688540378585458，acc：1.0\n",
      "训练时间：7226.1595277786255\n",
      "第800个批次，loss：0.0011470643803477287，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第62轮训练\n",
      "训练时间：7236.250238418579\n",
      "第0个批次，loss：0.00018169041140936315，acc：1.0\n",
      "训练时间：7249.722533941269\n",
      "第100个批次，loss：0.0043445066548883915，acc：1.0\n",
      "训练时间：7263.159081935883\n",
      "第200个批次，loss：7.723075395915657e-05，acc：1.0\n",
      "训练时间：7276.6942183971405\n",
      "第300个批次，loss：0.0007356663118116558，acc：1.0\n",
      "训练时间：7290.304695606232\n",
      "第400个批次，loss：0.00014839245704934，acc：1.0\n",
      "训练时间：7303.802970647812\n",
      "第500个批次，loss：0.0007244559237733483，acc：1.0\n",
      "训练时间：7317.280768632889\n",
      "第600个批次，loss：0.0002713721478357911，acc：1.0\n",
      "训练时间：7330.758703947067\n",
      "第700个批次，loss：0.003626246238127351，acc：1.0\n",
      "训练时间：7344.220179796219\n",
      "第800个批次，loss：0.00034888219670392573，acc：1.0\n",
      "整体验证集的acc：0.994038462638855\n",
      "第63轮训练\n",
      "训练时间：7353.840520143509\n",
      "第0个批次，loss：0.026891930028796196，acc：0.96875\n",
      "训练时间：7367.28781914711\n",
      "第100个批次，loss：0.000271451921435073，acc：1.0\n",
      "训练时间：7380.783925294876\n",
      "第200个批次，loss：0.02722793072462082，acc：1.0\n",
      "训练时间：7394.220402479172\n",
      "第300个批次，loss：0.0003530677640810609，acc：1.0\n",
      "训练时间：7407.652441978455\n",
      "第400个批次，loss：6.0816917539341375e-05，acc：1.0\n",
      "训练时间：7421.17098236084\n",
      "第500个批次，loss：0.0026094878558069468，acc：1.0\n",
      "训练时间：7434.7691287994385\n",
      "第600个批次，loss：0.009940704330801964，acc：1.0\n",
      "训练时间：7448.21817111969\n",
      "第700个批次，loss：0.0008379584760405123，acc：1.0\n",
      "训练时间：7461.652490377426\n",
      "第800个批次，loss：0.00031176686752587557，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第64轮训练\n",
      "训练时间：7471.249845266342\n",
      "第0个批次，loss：5.1213213737355545e-05，acc：1.0\n",
      "训练时间：7484.8266615867615\n",
      "第100个批次，loss：0.00030772382160648704，acc：1.0\n",
      "训练时间：7498.40172958374\n",
      "第200个批次，loss：0.00047791769611649215，acc：1.0\n",
      "训练时间：7511.892724752426\n",
      "第300个批次，loss：0.003065224504098296，acc：1.0\n",
      "训练时间：7525.427800416946\n",
      "第400个批次，loss：0.007321550976485014，acc：1.0\n",
      "训练时间：7539.166686534882\n",
      "第500个批次，loss：0.00879605207592249，acc：1.0\n",
      "训练时间：7552.8291347026825\n",
      "第600个批次，loss：0.001471870462410152，acc：1.0\n",
      "训练时间：7566.357411623001\n",
      "第700个批次，loss：0.0034987148828804493，acc：1.0\n",
      "训练时间：7580.084558010101\n",
      "第800个批次，loss：0.00048270676052197814，acc：1.0\n",
      "整体验证集的acc：0.9921153783798218\n",
      "第65轮训练\n",
      "训练时间：7590.507323741913\n",
      "第0个批次，loss：0.00013182131806388497，acc：1.0\n",
      "训练时间：7605.548029661179\n",
      "第100个批次，loss：0.00013197057705838233，acc：1.0\n",
      "训练时间：7621.160576343536\n",
      "第200个批次，loss：0.00025515639572404325，acc：1.0\n",
      "训练时间：7635.87827706337\n",
      "第300个批次，loss：0.004632566124200821，acc：1.0\n",
      "训练时间：7649.314426183701\n",
      "第400个批次，loss：0.0020559029653668404，acc：1.0\n",
      "训练时间：7662.747474431992\n",
      "第500个批次，loss：0.0034765072632580996，acc：1.0\n",
      "训练时间：7676.177543878555\n",
      "第600个批次，loss：0.002915559336543083，acc：1.0\n",
      "训练时间：7689.609574079514\n",
      "第700个批次，loss：0.0007875125156715512，acc：1.0\n",
      "训练时间：7703.044100046158\n",
      "第800个批次，loss：0.0008317864267155528，acc：1.0\n",
      "整体验证集的acc：0.9936538338661194\n",
      "第66轮训练\n",
      "训练时间：7712.661268949509\n",
      "第0个批次，loss：0.0009646707912907004，acc：1.0\n",
      "训练时间：7726.0934517383575\n",
      "第100个批次，loss：0.0003377114189788699，acc：1.0\n",
      "训练时间：7739.5402455329895\n",
      "第200个批次，loss：0.0012115929275751114，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：7752.97447180748\n",
      "第300个批次，loss：0.0011157627450302243，acc：1.0\n",
      "训练时间：7766.407970190048\n",
      "第400个批次，loss：0.08561155945062637，acc：0.96875\n",
      "训练时间：7779.852427482605\n",
      "第500个批次，loss：0.00023706222418695688，acc：1.0\n",
      "训练时间：7793.290344953537\n",
      "第600个批次，loss：0.0007218254613690078，acc：1.0\n",
      "训练时间：7806.739880800247\n",
      "第700个批次，loss：0.0013430756516754627，acc：1.0\n",
      "训练时间：7820.172261714935\n",
      "第800个批次，loss：0.00020793025032617152，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第67轮训练\n",
      "训练时间：7829.772423028946\n",
      "第0个批次，loss：0.0004382900951895863，acc：1.0\n",
      "训练时间：7843.204753160477\n",
      "第100个批次，loss：0.0004643244610633701，acc：1.0\n",
      "训练时间：7856.638437271118\n",
      "第200个批次，loss：0.00032242905581369996，acc：1.0\n",
      "训练时间：7870.072722434998\n",
      "第300个批次，loss：0.00040069958777166903，acc：1.0\n",
      "训练时间：7883.519718647003\n",
      "第400个批次，loss：0.0004239189438521862，acc：1.0\n",
      "训练时间：7896.9708507061005\n",
      "第500个批次，loss：0.00012060261360602453，acc：1.0\n",
      "训练时间：7910.401895999908\n",
      "第600个批次，loss：0.0005832907045260072，acc：1.0\n",
      "训练时间：7923.8184270858765\n",
      "第700个批次，loss：0.0005514937220141292，acc：1.0\n",
      "训练时间：7937.252457618713\n",
      "第800个批次，loss：0.00023907078139018267，acc：1.0\n",
      "整体验证集的acc：0.9930769205093384\n",
      "第68轮训练\n",
      "训练时间：7946.846613168716\n",
      "第0个批次，loss：0.040775980800390244，acc：0.96875\n",
      "训练时间：7960.283637046814\n",
      "第100个批次，loss：6.193466106196865e-05，acc：1.0\n",
      "训练时间：7973.727030038834\n",
      "第200个批次，loss：0.0017082885606214404，acc：1.0\n",
      "训练时间：7987.14962387085\n",
      "第300个批次，loss：0.0012025362811982632，acc：1.0\n",
      "训练时间：8000.584671020508\n",
      "第400个批次，loss：0.00032033014576882124，acc：1.0\n",
      "训练时间：8014.03172492981\n",
      "第500个批次，loss：0.0006553265266120434，acc：1.0\n",
      "训练时间：8027.465763092041\n",
      "第600个批次，loss：0.000531611090991646，acc：1.0\n",
      "训练时间：8040.899809360504\n",
      "第700个批次，loss：0.003349756123498082，acc：1.0\n",
      "训练时间：8054.326059103012\n",
      "第800个批次，loss：0.00026714312843978405，acc：1.0\n",
      "整体验证集的acc：0.994038462638855\n",
      "第69轮训练\n",
      "训练时间：8063.944243192673\n",
      "第0个批次，loss：0.003620441537350416，acc：1.0\n",
      "训练时间：8077.364297628403\n",
      "第100个批次，loss：0.0038036613259464502，acc：1.0\n",
      "训练时间：8090.81675696373\n",
      "第200个批次，loss：0.00013049347035121173，acc：1.0\n",
      "训练时间：8104.24499130249\n",
      "第300个批次，loss：0.0001864076330093667，acc：1.0\n",
      "训练时间：8117.671588420868\n",
      "第400个批次，loss：6.990733527345583e-05，acc：1.0\n",
      "训练时间：8131.106116056442\n",
      "第500个批次，loss：0.00026303596678189933，acc：1.0\n",
      "训练时间：8144.542071342468\n",
      "第600个批次，loss：0.03960685059428215，acc：0.96875\n",
      "训练时间：8157.976920843124\n",
      "第700个批次，loss：0.0007763513713143766，acc：1.0\n",
      "训练时间：8171.417961597443\n",
      "第800个批次，loss：0.010532496497035027，acc：1.0\n",
      "整体验证集的acc：0.9936538338661194\n",
      "第70轮训练\n",
      "训练时间：8181.002121686935\n",
      "第0个批次，loss：0.0013484800001606345，acc：1.0\n",
      "训练时间：8194.427571296692\n",
      "第100个批次，loss：0.0009793315548449755，acc：1.0\n",
      "训练时间：8207.852616786957\n",
      "第200个批次，loss：0.00023839191999286413，acc：1.0\n",
      "训练时间：8221.291870832443\n",
      "第300个批次，loss：0.00029617821564897895，acc：1.0\n",
      "训练时间：8234.724319934845\n",
      "第400个批次，loss：0.004863621201366186，acc：1.0\n",
      "训练时间：8248.15769982338\n",
      "第500个批次，loss：7.159421511460096e-05，acc：1.0\n",
      "训练时间：8261.58879852295\n",
      "第600个批次，loss：0.0013979158829897642，acc：1.0\n",
      "训练时间：8275.024804830551\n",
      "第700个批次，loss：4.596901635522954e-05，acc：1.0\n",
      "训练时间：8288.45728468895\n",
      "第800个批次，loss：0.00015699466166552156，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第71轮训练\n",
      "训练时间：8298.132429599762\n",
      "第0个批次，loss：0.00012692085874732584，acc：1.0\n",
      "训练时间：8311.55546283722\n",
      "第100个批次，loss：0.00014504350838251412，acc：1.0\n",
      "训练时间：8324.988041877747\n",
      "第200个批次，loss：0.0032214224338531494，acc：1.0\n",
      "训练时间：8338.422107458115\n",
      "第300个批次，loss：0.004347038455307484，acc：1.0\n",
      "训练时间：8351.85316824913\n",
      "第400个批次，loss：0.0004132349567953497，acc：1.0\n",
      "训练时间：8365.288205862045\n",
      "第500个批次，loss：0.0010645331349223852，acc：1.0\n",
      "训练时间：8378.720618247986\n",
      "第600个批次，loss：0.00043796165846288204，acc：1.0\n",
      "训练时间：8392.136986255646\n",
      "第700个批次，loss：0.00032915733754634857，acc：1.0\n",
      "训练时间：8405.568419456482\n",
      "第800个批次，loss：0.00023113403585739434，acc：1.0\n",
      "整体验证集的acc：0.992307722568512\n",
      "第72轮训练\n",
      "训练时间：8415.21304321289\n",
      "第0个批次，loss：0.0002747773833107203，acc：1.0\n",
      "训练时间：8428.632165431976\n",
      "第100个批次，loss：0.03570481389760971，acc：1.0\n",
      "训练时间：8442.066618680954\n",
      "第200个批次，loss：0.000151934233144857，acc：1.0\n",
      "训练时间：8455.499717235565\n",
      "第300个批次，loss：0.00029960621031932533，acc：1.0\n",
      "训练时间：8468.933948040009\n",
      "第400个批次，loss：0.0011386132100597024，acc：1.0\n",
      "训练时间：8482.36624622345\n",
      "第500个批次，loss：0.00010873909923247993，acc：1.0\n",
      "训练时间：8495.781502723694\n",
      "第600个批次，loss：0.00079388078302145，acc：1.0\n",
      "训练时间：8509.214654684067\n",
      "第700个批次，loss：0.00013697627582587302，acc：1.0\n",
      "训练时间：8522.629677295685\n",
      "第800个批次，loss：0.0002381557715125382，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第73轮训练\n",
      "训练时间：8532.247042179108\n",
      "第0个批次，loss：0.0005390035803429782，acc：1.0\n",
      "训练时间：8545.698083639145\n",
      "第100个批次，loss：0.0016472095157951117，acc：1.0\n",
      "训练时间：8559.113270044327\n",
      "第200个批次，loss：0.00012553880515042692，acc：1.0\n",
      "训练时间：8572.547776460648\n",
      "第300个批次，loss：5.3895506425760686e-05，acc：1.0\n",
      "训练时间：8585.972809314728\n",
      "第400个批次，loss：0.08493362367153168，acc：0.96875\n",
      "训练时间：8599.395180225372\n",
      "第500个批次，loss：0.016134878620505333，acc：1.0\n",
      "训练时间：8612.827549219131\n",
      "第600个批次，loss：0.035678695887327194，acc：1.0\n",
      "训练时间：8626.25758767128\n",
      "第700个批次，loss：0.0012549037346616387，acc：1.0\n",
      "训练时间：8639.677652835846\n",
      "第800个批次，loss：0.00036266830284148455，acc：1.0\n",
      "整体验证集的acc：0.9909615516662598\n",
      "第74轮训练\n",
      "训练时间：8649.279776334763\n",
      "第0个批次，loss：0.00016693075303919613，acc：1.0\n",
      "训练时间：8662.71081995964\n",
      "第100个批次，loss：0.0010426947847008705，acc：1.0\n",
      "训练时间：8676.144117116928\n",
      "第200个批次，loss：0.003937183413654566，acc：1.0\n",
      "训练时间：8689.577159166336\n",
      "第300个批次，loss：0.0006707594147883356，acc：1.0\n",
      "训练时间：8703.008484363556\n",
      "第400个批次，loss：0.00025972098228521645，acc：1.0\n",
      "训练时间：8716.442346572876\n",
      "第500个批次，loss：0.00030614028219133615，acc：1.0\n",
      "训练时间：8729.858346939087\n",
      "第600个批次，loss：0.000816781772300601，acc：1.0\n",
      "训练时间：8743.261471271515\n",
      "第700个批次，loss：0.0011924350401386619，acc：1.0\n",
      "训练时间：8756.69051027298\n",
      "第800个批次，loss：0.02474409155547619，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第75轮训练\n",
      "训练时间：8766.274673223495\n",
      "第0个批次，loss：0.005772942211478949，acc：1.0\n",
      "训练时间：8779.708273172379\n",
      "第100个批次，loss：0.044927582144737244，acc：0.96875\n",
      "训练时间：8793.139480113983\n",
      "第200个批次，loss：6.272933387663215e-05，acc：1.0\n",
      "训练时间：8806.57383441925\n",
      "第300个批次，loss：0.00021303139510564506，acc：1.0\n",
      "训练时间：8820.011512517929\n",
      "第400个批次，loss：0.0005349792772904038，acc：1.0\n",
      "训练时间：8833.438631772995\n",
      "第500个批次，loss：0.04736723750829697，acc：0.96875\n",
      "训练时间：8846.870033025742\n",
      "第600个批次，loss：0.0007591058383695781，acc：1.0\n",
      "训练时间：8860.303634166718\n",
      "第700个批次，loss：0.00041122030233964324，acc：1.0\n",
      "训练时间：8873.721280574799\n",
      "第800个批次，loss：0.03073718771338463，acc：0.96875\n",
      "整体验证集的acc：0.992884635925293\n",
      "第76轮训练\n",
      "训练时间：8883.328622817993\n",
      "第0个批次，loss：0.0056462399661540985，acc：1.0\n",
      "训练时间：8896.754665851593\n",
      "第100个批次，loss：0.00020326426601968706，acc：1.0\n",
      "训练时间：8910.190084457397\n",
      "第200个批次，loss：0.0002657882578205317，acc：1.0\n",
      "训练时间：8923.632742404938\n",
      "第300个批次，loss：0.003058483824133873，acc：1.0\n",
      "训练时间：8937.067011356354\n",
      "第400个批次，loss：0.00012982670159544796，acc：1.0\n",
      "训练时间：8950.502242803574\n",
      "第500个批次，loss：0.0016917921602725983，acc：1.0\n",
      "训练时间：8963.93396115303\n",
      "第600个批次，loss：0.00019461980264168233，acc：1.0\n",
      "训练时间：8977.369363307953\n",
      "第700个批次，loss：0.00046470214147120714，acc：1.0\n",
      "训练时间：8990.799841403961\n",
      "第800个批次，loss：0.009087142534554005，acc：1.0\n",
      "整体验证集的acc：0.9921153783798218\n",
      "第77轮训练\n",
      "训练时间：9000.385006666183\n",
      "第0个批次，loss：0.016994738951325417，acc：1.0\n",
      "训练时间：9013.816262245178\n",
      "第100个批次，loss：0.001382019487209618，acc：1.0\n",
      "训练时间：9027.248423576355\n",
      "第200个批次，loss：0.063579261302948，acc：0.96875\n",
      "训练时间：9040.67873096466\n",
      "第300个批次，loss：4.103203536942601e-05，acc：1.0\n",
      "训练时间：9054.113137960434\n",
      "第400个批次，loss：0.0018907628254964948，acc：1.0\n",
      "训练时间：9067.547092437744\n",
      "第500个批次，loss：5.9671929193427786e-05，acc：1.0\n",
      "训练时间：9080.979405641556\n",
      "第600个批次，loss：2.6298648663214408e-05，acc：1.0\n",
      "训练时间：9094.41336965561\n",
      "第700个批次，loss：0.0002957145916298032，acc：1.0\n",
      "训练时间：9107.860758543015\n",
      "第800个批次，loss：0.02948303334414959，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第78轮训练\n",
      "训练时间：9117.430181980133\n",
      "第0个批次，loss：0.0008438277291134，acc：1.0\n",
      "训练时间：9130.845662593842\n",
      "第100个批次，loss：0.003070217790082097，acc：1.0\n",
      "训练时间：9144.277693271637\n",
      "第200个批次，loss：2.9135908334865235e-05，acc：1.0\n",
      "训练时间：9157.71272611618\n",
      "第300个批次，loss：0.0005993259837850928，acc：1.0\n",
      "训练时间：9171.242252349854\n",
      "第400个批次，loss：0.10139066725969315，acc：0.96875\n",
      "训练时间：9184.679300069809\n",
      "第500个批次，loss：0.00011210818774998188，acc：1.0\n",
      "训练时间：9198.110330343246\n",
      "第600个批次，loss：0.0019024892244488，acc：1.0\n",
      "训练时间：9211.540863275528\n",
      "第700个批次，loss：0.00010011457197833806，acc：1.0\n",
      "训练时间：9224.986908435822\n",
      "第800个批次，loss：8.615769911557436e-05，acc：1.0\n",
      "整体验证集的acc：0.9942307472229004\n",
      "第79轮训练\n",
      "训练时间：9234.592218399048\n",
      "第0个批次，loss：0.00016902679635677487，acc：1.0\n",
      "训练时间：9248.005551099777\n",
      "第100个批次，loss：0.00016693158249836415，acc：1.0\n",
      "训练时间：9261.422582864761\n",
      "第200个批次，loss：0.008678369224071503，acc：1.0\n",
      "训练时间：9274.853606462479\n",
      "第300个批次，loss：0.003915025852620602，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：9288.286129951477\n",
      "第400个批次，loss：0.00289808283559978，acc：1.0\n",
      "训练时间：9301.70594739914\n",
      "第500个批次，loss：0.0023000764194875956，acc：1.0\n",
      "训练时间：9315.136984586716\n",
      "第600个批次，loss：0.0012109668459743261，acc：1.0\n",
      "训练时间：9328.570038557053\n",
      "第700个批次，loss：0.0022885738871991634，acc：1.0\n",
      "训练时间：9342.018562078476\n",
      "第800个批次，loss：0.004037754610180855，acc：1.0\n",
      "整体验证集的acc：0.9913461804389954\n",
      "第80轮训练\n",
      "训练时间：9351.650815963745\n",
      "第0个批次，loss：0.00985777284950018，acc：1.0\n",
      "训练时间：9365.088629961014\n",
      "第100个批次，loss：0.004984894301742315，acc：1.0\n",
      "训练时间：9378.544836044312\n",
      "第200个批次，loss：0.00506769260391593，acc：1.0\n",
      "训练时间：9391.985583305359\n",
      "第300个批次，loss：0.012589626014232635，acc：1.0\n",
      "训练时间：9405.418629407883\n",
      "第400个批次，loss：0.0001278221170650795，acc：1.0\n",
      "训练时间：9418.83466887474\n",
      "第500个批次，loss：0.002022534841671586，acc：1.0\n",
      "训练时间：9432.26670718193\n",
      "第600个批次，loss：0.0008376341429539025，acc：1.0\n",
      "训练时间：9445.684764623642\n",
      "第700个批次，loss：0.06329572200775146，acc：0.96875\n",
      "训练时间：9459.11787199974\n",
      "第800个批次，loss：0.0009511313983239233，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第81轮训练\n",
      "训练时间：9468.785267829895\n",
      "第0个批次，loss：0.0004613001365214586，acc：1.0\n",
      "训练时间：9482.216270208359\n",
      "第100个批次，loss：0.0005034143687225878，acc：1.0\n",
      "训练时间：9495.634160518646\n",
      "第200个批次，loss：0.0005673186969943345，acc：1.0\n",
      "训练时间：9509.06185054779\n",
      "第300个批次，loss：0.013636902906000614，acc：1.0\n",
      "训练时间：9522.500522375107\n",
      "第400个批次，loss：0.000438081071479246，acc：1.0\n",
      "训练时间：9535.931004524231\n",
      "第500个批次，loss：0.0002307253162143752，acc：1.0\n",
      "训练时间：9549.364932537079\n",
      "第600个批次，loss：0.001203553518280387，acc：1.0\n",
      "训练时间：9562.799804449081\n",
      "第700个批次，loss：0.00013391870015766472，acc：1.0\n",
      "训练时间：9576.246373176575\n",
      "第800个批次，loss：0.0006395885138772428，acc：1.0\n",
      "整体验证集的acc：0.9938461780548096\n",
      "第82轮训练\n",
      "训练时间：9585.803653478622\n",
      "第0个批次，loss：7.382971671177074e-05，acc：1.0\n",
      "训练时间：9599.226867198944\n",
      "第100个批次，loss：0.0026257873978465796，acc：1.0\n",
      "训练时间：9612.66178035736\n",
      "第200个批次，loss：0.005526195280253887，acc：1.0\n",
      "训练时间：9626.076064109802\n",
      "第300个批次，loss：0.004238154273480177，acc：1.0\n",
      "训练时间：9639.49731707573\n",
      "第400个批次，loss：0.002682045102119446，acc：1.0\n",
      "训练时间：9652.922479629517\n",
      "第500个批次，loss：0.07101742178201675，acc：0.9375\n",
      "训练时间：9666.342810153961\n",
      "第600个批次，loss：0.0003543556376826018，acc：1.0\n",
      "训练时间：9679.792151927948\n",
      "第700个批次，loss：0.0014851356390863657，acc：1.0\n",
      "训练时间：9693.228744029999\n",
      "第800个批次，loss：0.0021995387505739927，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第83轮训练\n",
      "训练时间：9702.839919567108\n",
      "第0个批次，loss：0.0006372909410856664，acc：1.0\n",
      "训练时间：9716.276328325272\n",
      "第100个批次，loss：9.986571967601776e-05，acc：1.0\n",
      "训练时间：9729.706758260727\n",
      "第200个批次，loss：0.02463863044977188，acc：0.96875\n",
      "训练时间：9743.141045570374\n",
      "第300个批次，loss：0.00048526469618082047，acc：1.0\n",
      "训练时间：9756.573281049728\n",
      "第400个批次，loss：0.014929825440049171，acc：1.0\n",
      "训练时间：9770.007306337357\n",
      "第500个批次，loss：0.0021300276275724173，acc：1.0\n",
      "训练时间：9783.439178228378\n",
      "第600个批次，loss：0.0007014141883701086，acc：1.0\n",
      "训练时间：9796.88521695137\n",
      "第700个批次，loss：0.009172920137643814，acc：1.0\n",
      "训练时间：9810.32225060463\n",
      "第800个批次，loss：0.0002277416060678661，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第84轮训练\n",
      "训练时间：9819.931422710419\n",
      "第0个批次，loss：0.00030334762413986027，acc：1.0\n",
      "训练时间：9833.354637384415\n",
      "第100个批次，loss：0.0001195386576000601，acc：1.0\n",
      "训练时间：9846.788039445877\n",
      "第200个批次，loss：0.00022151891607791185，acc：1.0\n",
      "训练时间：9860.222224712372\n",
      "第300个批次，loss：0.00011645259655779228，acc：1.0\n",
      "训练时间：9873.63563299179\n",
      "第400个批次，loss：0.026728371158242226，acc：1.0\n",
      "训练时间：9887.06866645813\n",
      "第500个批次，loss：0.0023943453561514616，acc：1.0\n",
      "训练时间：9900.502776145935\n",
      "第600个批次，loss：0.0006417713593691587，acc：1.0\n",
      "训练时间：9913.935142755508\n",
      "第700个批次，loss：0.0008972734794951975，acc：1.0\n",
      "训练时间：9927.353180408478\n",
      "第800个批次，loss：0.04899825528264046，acc：0.96875\n",
      "整体验证集的acc：0.9921153783798218\n",
      "第85轮训练\n",
      "训练时间：9936.978358507156\n",
      "第0个批次，loss：0.0009610737324692309，acc：1.0\n",
      "训练时间：9950.399840593338\n",
      "第100个批次，loss：0.00016086136747617275，acc：1.0\n",
      "训练时间：9963.833844184875\n",
      "第200个批次，loss：0.0007175807259045541，acc：1.0\n",
      "训练时间：9977.26747584343\n",
      "第300个批次，loss：0.0018086713971570134，acc：1.0\n",
      "训练时间：9990.69976758957\n",
      "第400个批次，loss：0.0003874430258292705，acc：1.0\n",
      "训练时间：10004.128035783768\n",
      "第500个批次，loss：8.06031166575849e-05，acc：1.0\n",
      "训练时间：10017.567105770111\n",
      "第600个批次，loss：0.0005292618880048394，acc：1.0\n",
      "训练时间：10030.998781204224\n",
      "第700个批次，loss：0.0004266058385837823，acc：1.0\n",
      "训练时间：10044.432218313217\n",
      "第800个批次，loss：0.04377363249659538，acc：0.96875\n",
      "整体验证集的acc：0.9936538338661194\n",
      "第86轮训练\n",
      "训练时间：10054.054811954498\n",
      "第0个批次，loss：0.0046789622865617275，acc：1.0\n",
      "训练时间：10067.479853153229\n",
      "第100个批次，loss：0.0005385820404626429，acc：1.0\n",
      "训练时间：10080.912124633789\n",
      "第200个批次，loss：0.007219934836030006，acc：1.0\n",
      "训练时间：10094.345858812332\n",
      "第300个批次，loss：0.021597174927592278，acc：1.0\n",
      "训练时间：10107.801266431808\n",
      "第400个批次，loss：0.05834231525659561，acc：0.96875\n",
      "训练时间：10121.228607177734\n",
      "第500个批次，loss：0.0011196061968803406，acc：1.0\n",
      "训练时间：10134.663658618927\n",
      "第600个批次，loss：0.00023438737844116986，acc：1.0\n",
      "训练时间：10148.093692779541\n",
      "第700个批次，loss：0.039311353117227554，acc：1.0\n",
      "训练时间：10161.528029680252\n",
      "第800个批次，loss：0.0005212110700085759，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第87轮训练\n",
      "训练时间：10171.1541223526\n",
      "第0个批次，loss：0.0045089744962751865，acc：1.0\n",
      "训练时间：10184.576155900955\n",
      "第100个批次，loss：0.00023538482491858304，acc：1.0\n",
      "训练时间：10198.009203195572\n",
      "第200个批次，loss：0.014868521131575108，acc：1.0\n",
      "训练时间：10211.443741559982\n",
      "第300个批次，loss：0.007022921461611986，acc：1.0\n",
      "训练时间：10224.890053272247\n",
      "第400个批次，loss：0.0016612979816272855，acc：1.0\n",
      "训练时间：10238.326091051102\n",
      "第500个批次，loss：0.0007524113170802593，acc：1.0\n",
      "训练时间：10251.75730061531\n",
      "第600个批次，loss：0.00011822212400147691，acc：1.0\n",
      "训练时间：10265.189983844757\n",
      "第700个批次，loss：0.0005078907706774771，acc：1.0\n",
      "训练时间：10278.624611139297\n",
      "第800个批次，loss：0.0006487421924248338，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第88轮训练\n",
      "训练时间：10288.23780965805\n",
      "第0个批次，loss：0.0002502513525541872，acc：1.0\n",
      "训练时间：10301.672506093979\n",
      "第100个批次，loss：0.00013471714919432998，acc：1.0\n",
      "训练时间：10315.088968753815\n",
      "第200个批次，loss：0.0005371562438085675，acc：1.0\n",
      "训练时间：10328.520859003067\n",
      "第300个批次，loss：6.886468327138573e-05，acc：1.0\n",
      "训练时间：10341.93722653389\n",
      "第400个批次，loss：0.0006743295816704631，acc：1.0\n",
      "训练时间：10355.38898897171\n",
      "第500个批次，loss：6.524378841277212e-05，acc：1.0\n",
      "训练时间：10368.817118167877\n",
      "第600个批次，loss：0.00036460315459407866，acc：1.0\n",
      "训练时间：10382.253160953522\n",
      "第700个批次，loss：0.001842853962443769，acc：1.0\n",
      "训练时间：10395.68678855896\n",
      "第800个批次，loss：0.017048679292201996，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第89轮训练\n",
      "训练时间：10405.285951852798\n",
      "第0个批次，loss：0.00040807444020174444，acc：1.0\n",
      "训练时间：10418.719221115112\n",
      "第100个批次，loss：0.0006982941413298249，acc：1.0\n",
      "训练时间：10432.164430618286\n",
      "第200个批次，loss：0.008253680542111397，acc：1.0\n",
      "训练时间：10445.601462602615\n",
      "第300个批次，loss：0.003817934775725007，acc：1.0\n",
      "训练时间：10459.05185842514\n",
      "第400个批次，loss：0.001622903160750866，acc：1.0\n",
      "训练时间：10472.48433971405\n",
      "第500个批次，loss：0.09118736535310745，acc：0.96875\n",
      "训练时间：10485.935380935669\n",
      "第600个批次，loss：0.001315397908911109，acc：1.0\n",
      "训练时间：10499.377039670944\n",
      "第700个批次，loss：0.0004489145940169692，acc：1.0\n",
      "训练时间：10512.816465854645\n",
      "第800个批次，loss：6.514519918709993e-05，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第90轮训练\n",
      "训练时间：10522.391020536423\n",
      "第0个批次，loss：6.7140870669391e-05，acc：1.0\n",
      "训练时间：10535.813764810562\n",
      "第100个批次，loss：0.0002520264242775738，acc：1.0\n",
      "训练时间：10549.245650529861\n",
      "第200个批次，loss：0.0032359682954847813，acc：1.0\n",
      "训练时间：10562.683210134506\n",
      "第300个批次，loss：0.0007496500038541853，acc：1.0\n",
      "训练时间：10576.113460302353\n",
      "第400个批次，loss：0.0024560762103646994，acc：1.0\n",
      "训练时间：10589.544509887695\n",
      "第500个批次，loss：0.0007320436998270452，acc：1.0\n",
      "训练时间：10602.977797269821\n",
      "第600个批次，loss：0.0001289016508962959，acc：1.0\n",
      "训练时间：10616.41184926033\n",
      "第700个批次，loss：0.005173211917281151，acc：1.0\n",
      "训练时间：10629.844535112381\n",
      "第800个批次，loss：0.005511470139026642，acc：1.0\n",
      "整体验证集的acc：0.9930769205093384\n",
      "第91轮训练\n",
      "训练时间：10639.55073261261\n",
      "第0个批次，loss：6.83279795339331e-05，acc：1.0\n",
      "训练时间：10652.977321624756\n",
      "第100个批次，loss：0.006158039905130863，acc：1.0\n",
      "训练时间：10666.392405748367\n",
      "第200个批次，loss：0.0020003998652100563，acc：1.0\n",
      "训练时间：10679.82744216919\n",
      "第300个批次，loss：0.0006889694486744702，acc：1.0\n",
      "训练时间：10693.263179779053\n",
      "第400个批次，loss：0.0003453734389040619，acc：1.0\n",
      "训练时间：10706.690281629562\n",
      "第500个批次，loss：0.0005611138767562807，acc：1.0\n",
      "训练时间：10720.10835981369\n",
      "第600个批次，loss：0.00030517420964315534，acc：1.0\n",
      "训练时间：10733.540880680084\n",
      "第700个批次，loss：0.0002692344132810831，acc：1.0\n",
      "训练时间：10746.973179340363\n",
      "第800个批次，loss：0.00017785180534701794，acc：1.0\n",
      "整体验证集的acc：0.9942307472229004\n",
      "第92轮训练\n",
      "训练时间：10756.563349485397\n",
      "第0个批次，loss：0.0009237361955456436，acc：1.0\n",
      "训练时间：10769.990014791489\n",
      "第100个批次，loss：0.0004712791123893112，acc：1.0\n",
      "训练时间：10783.43877696991\n",
      "第200个批次，loss：0.00019232260819990188，acc：1.0\n",
      "训练时间：10796.869571685791\n",
      "第300个批次，loss：0.0010708930203691125，acc：1.0\n",
      "训练时间：10810.304713249207\n",
      "第400个批次，loss：0.003870677202939987，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：10823.739190101624\n",
      "第500个批次，loss：0.0008832932799123228，acc：1.0\n",
      "训练时间：10837.154417991638\n",
      "第600个批次，loss：0.000815895851701498，acc：1.0\n",
      "训练时间：10850.569714069366\n",
      "第700个批次，loss：0.007825849577784538，acc：1.0\n",
      "训练时间：10864.00480556488\n",
      "第800个批次，loss：0.00010143523832084611，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第93轮训练\n",
      "训练时间：10873.654196500778\n",
      "第0个批次，loss：0.0009075442794710398，acc：1.0\n",
      "训练时间：10887.068949699402\n",
      "第100个批次，loss：0.0021671634167432785，acc：1.0\n",
      "训练时间：10900.49336051941\n",
      "第200个批次，loss：0.0010158040095120668，acc：1.0\n",
      "训练时间：10913.918022632599\n",
      "第300个批次，loss：0.0010144697735086083，acc：1.0\n",
      "训练时间：10927.350566864014\n",
      "第400个批次，loss：0.00016338107525371015，acc：1.0\n",
      "训练时间：10940.78309583664\n",
      "第500个批次，loss：0.018301913514733315，acc：1.0\n",
      "训练时间：10954.199895143509\n",
      "第600个批次，loss：0.0006337444065138698，acc：1.0\n",
      "训练时间：10967.632589817047\n",
      "第700个批次，loss：0.00017140209092758596，acc：1.0\n",
      "训练时间：10981.065644741058\n",
      "第800个批次，loss：0.0003673142346087843，acc：1.0\n",
      "整体验证集的acc：0.992307722568512\n",
      "第94轮训练\n",
      "训练时间：10990.652391910553\n",
      "第0个批次，loss：0.0013500801287591457，acc：1.0\n",
      "训练时间：11004.066016435623\n",
      "第100个批次，loss：0.014908612705767155，acc：1.0\n",
      "训练时间：11017.497825145721\n",
      "第200个批次，loss：0.004891680087894201，acc：1.0\n",
      "训练时间：11030.93087720871\n",
      "第300个批次，loss：0.0008006207644939423，acc：1.0\n",
      "训练时间：11044.362553834915\n",
      "第400个批次，loss：0.0014629714423790574，acc：1.0\n",
      "训练时间：11057.797162532806\n",
      "第500个批次，loss：0.00012287776917219162，acc：1.0\n",
      "训练时间：11071.230602502823\n",
      "第600个批次，loss：0.007967093959450722，acc：1.0\n",
      "训练时间：11084.66220498085\n",
      "第700个批次，loss：0.0028230776078999043，acc：1.0\n",
      "训练时间：11098.095010995865\n",
      "第800个批次，loss：0.0017776358872652054，acc：1.0\n",
      "整体验证集的acc：0.993461549282074\n",
      "第95轮训练\n",
      "训练时间：11107.671173810959\n",
      "第0个批次，loss：0.0006699721561744809，acc：1.0\n",
      "训练时间：11121.09431552887\n",
      "第100个批次，loss：0.0004702155420091003，acc：1.0\n",
      "训练时间：11134.527494430542\n",
      "第200个批次，loss：0.0034988296683877707，acc：1.0\n",
      "训练时间：11147.961010932922\n",
      "第300个批次，loss：0.001386826392263174，acc：1.0\n",
      "训练时间：11161.392862796783\n",
      "第400个批次，loss：0.0002286853559780866，acc：1.0\n",
      "训练时间：11174.826120853424\n",
      "第500个批次，loss：0.0002499270485714078，acc：1.0\n",
      "训练时间：11188.240852355957\n",
      "第600个批次，loss：0.0018820568220689893，acc：1.0\n",
      "训练时间：11201.675075054169\n",
      "第700个批次，loss：0.12257843464612961，acc：0.96875\n",
      "训练时间：11215.10735464096\n",
      "第800个批次，loss：0.0007344069890677929，acc：1.0\n",
      "整体验证集的acc：0.9909615516662598\n",
      "第96轮训练\n",
      "训练时间：11224.734423875809\n",
      "第0个批次，loss：0.005659994203597307，acc：1.0\n",
      "训练时间：11238.173925638199\n",
      "第100个批次，loss：0.000362865423085168，acc：1.0\n",
      "训练时间：11251.624523162842\n",
      "第200个批次，loss：0.03747386485338211，acc：0.96875\n",
      "训练时间：11265.057078838348\n",
      "第300个批次，loss：0.001339367008768022，acc：1.0\n",
      "训练时间：11278.50754070282\n",
      "第400个批次，loss：0.0006397122051566839，acc：1.0\n",
      "训练时间：11291.939260959625\n",
      "第500个批次，loss：0.0004442399076651782，acc：1.0\n",
      "训练时间：11305.3702917099\n",
      "第600个批次，loss：0.00018537700816523284，acc：1.0\n",
      "训练时间：11318.803758621216\n",
      "第700个批次，loss：0.000780389818828553，acc：1.0\n",
      "训练时间：11332.2369389534\n",
      "第800个批次，loss：0.001094434061087668，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第97轮训练\n",
      "训练时间：11341.826119422913\n",
      "第0个批次，loss：0.0007745167822577059，acc：1.0\n",
      "训练时间：11355.254138231277\n",
      "第100个批次，loss：0.0029906753916293383，acc：1.0\n",
      "训练时间：11368.686294078827\n",
      "第200个批次，loss：0.0023766392841935158，acc：1.0\n",
      "训练时间：11382.130404233932\n",
      "第300个批次，loss：0.004667942877858877，acc：1.0\n",
      "训练时间：11395.569818973541\n",
      "第400个批次，loss：0.00025816052220761776，acc：1.0\n",
      "训练时间：11409.003133773804\n",
      "第500个批次，loss：0.0007757125422358513，acc：1.0\n",
      "训练时间：11422.434608697891\n",
      "第600个批次，loss：0.00010050377750303596，acc：1.0\n",
      "训练时间：11435.868674755096\n",
      "第700个批次，loss：0.0002232455153716728，acc：1.0\n",
      "训练时间：11449.287354707718\n",
      "第800个批次，loss：0.02401811070740223，acc：1.0\n",
      "整体验证集的acc：0.992307722568512\n",
      "第98轮训练\n",
      "训练时间：11458.891114473343\n",
      "第0个批次，loss：0.0005471391486935318，acc：1.0\n",
      "训练时间：11472.31655216217\n",
      "第100个批次，loss：0.002317458391189575，acc：1.0\n",
      "训练时间：11485.765478372574\n",
      "第200个批次，loss：0.0007743368623778224，acc：1.0\n",
      "训练时间：11499.214459180832\n",
      "第300个批次，loss：9.927854989655316e-05，acc：1.0\n",
      "训练时间：11512.64781332016\n",
      "第400个批次，loss：0.00010449226101627573，acc：1.0\n",
      "训练时间：11526.080862760544\n",
      "第500个批次，loss：0.0008029767777770758，acc：1.0\n",
      "训练时间：11539.514892578125\n",
      "第600个批次，loss：0.010729179717600346，acc：1.0\n",
      "训练时间：11552.947128295898\n",
      "第700个批次，loss：0.022939210757613182，acc：1.0\n",
      "训练时间：11566.36982536316\n",
      "第800个批次，loss：7.46191872167401e-05，acc：1.0\n",
      "整体验证集的acc：0.9921153783798218\n",
      "第99轮训练\n",
      "训练时间：11575.98300075531\n",
      "第0个批次，loss：0.0002494497748557478，acc：1.0\n",
      "训练时间：11589.429044008255\n",
      "第100个批次，loss：0.00022006704239174724，acc：1.0\n",
      "训练时间：11602.878564596176\n",
      "第200个批次，loss：0.0005283778882585466，acc：1.0\n",
      "训练时间：11616.295105457306\n",
      "第300个批次，loss：0.0009975292487069964，acc：1.0\n",
      "训练时间：11629.731144666672\n",
      "第400个批次，loss：0.0005379500798881054，acc：1.0\n",
      "训练时间：11643.177675008774\n",
      "第500个批次，loss：0.0005180748412385583，acc：1.0\n",
      "训练时间：11656.608719110489\n",
      "第600个批次，loss：0.00042698049219325185，acc：1.0\n",
      "训练时间：11670.059997081757\n",
      "第700个批次，loss：0.00010589649900794029，acc：1.0\n",
      "训练时间：11683.493016242981\n",
      "第800个批次，loss：0.0006848202901892364，acc：1.0\n",
      "整体验证集的acc：0.992307722568512\n",
      "第100轮训练\n",
      "训练时间：11693.08917427063\n",
      "第0个批次，loss：0.0005509572220034897，acc：1.0\n",
      "训练时间：11706.524703979492\n",
      "第100个批次，loss：0.00047729091602377594，acc：1.0\n",
      "训练时间：11719.974890232086\n",
      "第200个批次，loss：0.0004960997030138969，acc：1.0\n",
      "训练时间：11733.391421079636\n",
      "第300个批次，loss：0.0001409265969414264，acc：1.0\n",
      "训练时间：11746.825380086899\n",
      "第400个批次，loss：0.0030220875050872564，acc：1.0\n",
      "训练时间：11760.256272792816\n",
      "第500个批次，loss：0.00014152482617646456，acc：1.0\n",
      "训练时间：11773.689495325089\n",
      "第600个批次，loss：0.000223145165364258，acc：1.0\n",
      "训练时间：11787.122893333435\n",
      "第700个批次，loss：0.0013336183037608862，acc：1.0\n",
      "训练时间：11800.554141283035\n",
      "第800个批次，loss：3.558316529961303e-05，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第101轮训练\n",
      "训练时间：11810.211544036865\n",
      "第0个批次，loss：0.008735922165215015，acc：1.0\n",
      "训练时间：11823.65542459488\n",
      "第100个批次，loss：0.00028297543758526444，acc：1.0\n",
      "训练时间：11837.086768388748\n",
      "第200个批次，loss：0.0003836429968941957，acc：1.0\n",
      "训练时间：11850.519805431366\n",
      "第300个批次，loss：0.002190115861594677，acc：1.0\n",
      "训练时间：11863.954160690308\n",
      "第400个批次，loss：0.0476689450442791，acc：0.96875\n",
      "训练时间：11877.386367321014\n",
      "第500个批次，loss：0.00031731632770970464，acc：1.0\n",
      "训练时间：11890.800855398178\n",
      "第600个批次，loss：0.0006632774602621794，acc：1.0\n",
      "训练时间：11904.235140323639\n",
      "第700个批次，loss：0.02625013329088688，acc：1.0\n",
      "训练时间：11917.66563796997\n",
      "第800个批次，loss：0.012999379076063633，acc：1.0\n",
      "整体验证集的acc：0.992307722568512\n",
      "第102轮训练\n",
      "训练时间：11927.278802156448\n",
      "第0个批次，loss：0.0029566227458417416，acc：1.0\n",
      "训练时间：11940.698828935623\n",
      "第100个批次，loss：0.026938507333397865，acc：0.96875\n",
      "训练时间：11954.134043455124\n",
      "第200个批次，loss：0.027441363781690598，acc：1.0\n",
      "训练时间：11967.56543803215\n",
      "第300个批次，loss：0.015740782022476196，acc：1.0\n",
      "训练时间：11980.999409675598\n",
      "第400个批次，loss：0.00038784107891842723，acc：1.0\n",
      "训练时间：11994.430091381073\n",
      "第500个批次，loss：5.094918378745206e-05，acc：1.0\n",
      "训练时间：12007.846556901932\n",
      "第600个批次，loss：0.0005037214141339064，acc：1.0\n",
      "训练时间：12021.262640237808\n",
      "第700个批次，loss：0.001045321929268539，acc：1.0\n",
      "训练时间：12034.688601732254\n",
      "第800个批次，loss：0.006743024569004774，acc：1.0\n",
      "整体验证集的acc：0.9921153783798218\n",
      "第103轮训练\n",
      "训练时间：12044.273762702942\n",
      "第0个批次，loss：0.0009555798606015742，acc：1.0\n",
      "训练时间：12057.69671678543\n",
      "第100个批次，loss：0.0006557896267622709，acc：1.0\n",
      "训练时间：12071.129568099976\n",
      "第200个批次，loss：0.0005151110817678273，acc：1.0\n",
      "训练时间：12084.56224322319\n",
      "第300个批次，loss：0.00016993441386148334，acc：1.0\n",
      "训练时间：12097.976332426071\n",
      "第400个批次，loss：6.574644066859037e-05，acc：1.0\n",
      "训练时间：12111.408601045609\n",
      "第500个批次，loss：0.0006996420561335981，acc：1.0\n",
      "训练时间：12124.82761478424\n",
      "第600个批次，loss：0.12605522572994232，acc：0.96875\n",
      "训练时间：12138.25809764862\n",
      "第700个批次，loss：0.0021329186856746674，acc：1.0\n",
      "训练时间：12151.691103935242\n",
      "第800个批次，loss：0.00013595800555776805，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第104轮训练\n",
      "训练时间：12161.29553937912\n",
      "第0个批次，loss：0.00017556392413098365，acc：1.0\n",
      "训练时间：12174.721608400345\n",
      "第100个批次，loss：0.03091287426650524，acc：0.96875\n",
      "训练时间：12188.141999959946\n",
      "第200个批次，loss：0.00039933924563229084，acc：1.0\n",
      "训练时间：12201.574435472488\n",
      "第300个批次，loss：0.007970103994011879，acc：1.0\n",
      "训练时间：12215.005935668945\n",
      "第400个批次，loss：0.0005041529075242579，acc：1.0\n",
      "训练时间：12228.422346115112\n",
      "第500个批次，loss：0.00022744711895938963，acc：1.0\n",
      "训练时间：12241.873744726181\n",
      "第600个批次，loss：0.017721999436616898，acc：1.0\n",
      "训练时间：12255.306609153748\n",
      "第700个批次，loss：0.0018489789217710495，acc：1.0\n",
      "训练时间：12268.736567020416\n",
      "第800个批次，loss：0.03850182145833969，acc：0.96875\n",
      "整体验证集的acc：0.9932692050933838\n",
      "第105轮训练\n",
      "训练时间：12278.331006765366\n",
      "第0个批次，loss：8.126959437504411e-05，acc：1.0\n",
      "训练时间：12291.754010677338\n",
      "第100个批次，loss：0.0027252992149442434，acc：1.0\n",
      "训练时间：12305.170623779297\n",
      "第200个批次，loss：0.0004805467324331403，acc：1.0\n",
      "训练时间：12318.60267829895\n",
      "第300个批次，loss：0.0002716454036999494，acc：1.0\n",
      "训练时间：12332.034874916077\n",
      "第400个批次，loss：0.00016955127648543566，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：12345.470487356186\n",
      "第500个批次，loss：0.006014086771756411，acc：1.0\n",
      "训练时间：12358.887315750122\n",
      "第600个批次，loss：0.003100540256127715，acc：1.0\n",
      "训练时间：12372.318264961243\n",
      "第700个批次，loss：0.0025574415922164917，acc：1.0\n",
      "训练时间：12385.750852823257\n",
      "第800个批次，loss：0.0019624808337539434，acc：1.0\n",
      "整体验证集的acc：0.994038462638855\n",
      "第106轮训练\n",
      "训练时间：12395.351517677307\n",
      "第0个批次，loss：0.00023533856438007206，acc：1.0\n",
      "训练时间：12408.783647298813\n",
      "第100个批次，loss：0.013386400416493416，acc：1.0\n",
      "训练时间：12422.21697974205\n",
      "第200个批次，loss：0.0002020303363678977，acc：1.0\n",
      "训练时间：12435.650016784668\n",
      "第300个批次，loss：0.0005982039147056639，acc：1.0\n",
      "训练时间：12449.083059549332\n",
      "第400个批次，loss：0.0003502734180074185，acc：1.0\n",
      "训练时间：12462.51562833786\n",
      "第500个批次，loss：0.00017998153634835035，acc：1.0\n",
      "训练时间：12475.948851823807\n",
      "第600个批次，loss：0.0008492690976709127，acc：1.0\n",
      "训练时间：12489.380192279816\n",
      "第700个批次，loss：0.00012798127136193216，acc：1.0\n",
      "训练时间：12502.83253645897\n",
      "第800个批次，loss：0.00015492996317334473，acc：1.0\n",
      "整体验证集的acc：0.9915384650230408\n",
      "第107轮训练\n",
      "训练时间：12512.447642564774\n",
      "第0个批次，loss：0.0003182170039508492，acc：1.0\n",
      "训练时间：12525.882160663605\n",
      "第100个批次，loss：0.00037888812948949635，acc：1.0\n",
      "训练时间：12539.329459667206\n",
      "第200个批次，loss：0.045368742197752，acc：0.96875\n",
      "训练时间：12552.766901731491\n",
      "第300个批次，loss：0.0006907735951244831，acc：1.0\n",
      "训练时间：12566.194930315018\n",
      "第400个批次，loss：0.0003564356593415141，acc：1.0\n",
      "训练时间：12579.628521680832\n",
      "第500个批次，loss：3.326642399770208e-05，acc：1.0\n",
      "训练时间：12593.06231212616\n",
      "第600个批次，loss：0.00010169520828640088，acc：1.0\n",
      "训练时间：12606.504647016525\n",
      "第700个批次，loss：0.0007374447886832058，acc：1.0\n",
      "训练时间：12619.945181369781\n",
      "第800个批次，loss：0.004200296476483345，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第108轮训练\n",
      "训练时间：12629.547349452972\n",
      "第0个批次，loss：0.0005585930193774402，acc：1.0\n",
      "训练时间：12642.976366519928\n",
      "第100个批次，loss：0.0006610641139559448，acc：1.0\n",
      "训练时间：12656.41087603569\n",
      "第200个批次，loss：0.00163162627723068，acc：1.0\n",
      "训练时间：12669.840162038803\n",
      "第300个批次，loss：0.0005950973718427122，acc：1.0\n",
      "训练时间：12683.276238679886\n",
      "第400个批次，loss：0.0004900119383819401，acc：1.0\n",
      "训练时间：12696.725272417068\n",
      "第500个批次，loss：0.04547091946005821，acc：0.96875\n",
      "训练时间：12710.158220529556\n",
      "第600个批次，loss：7.441935304086655e-05，acc：1.0\n",
      "训练时间：12723.573482751846\n",
      "第700个批次，loss：0.04830757901072502，acc：0.96875\n",
      "训练时间：12737.023696422577\n",
      "第800个批次，loss：0.003226432017982006，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第109轮训练\n",
      "训练时间：12746.615090370178\n",
      "第0个批次，loss：4.320744119468145e-05，acc：1.0\n",
      "训练时间：12760.093116521835\n",
      "第100个批次，loss：0.0002227586810477078，acc：1.0\n",
      "训练时间：12773.537763834\n",
      "第200个批次，loss：0.0021304041147232056，acc：1.0\n",
      "训练时间：12786.97088098526\n",
      "第300个批次，loss：8.243247430073097e-05，acc：1.0\n",
      "训练时间：12800.405641317368\n",
      "第400个批次，loss：0.00018620293121784925，acc：1.0\n",
      "训练时间：12813.821159362793\n",
      "第500个批次，loss：0.0009207943803630769，acc：1.0\n",
      "训练时间：12827.25300860405\n",
      "第600个批次，loss：2.370325273659546e-05，acc：1.0\n",
      "训练时间：12840.690945386887\n",
      "第700个批次，loss：0.00039290834683924913，acc：1.0\n",
      "训练时间：12854.120256185532\n",
      "第800个批次，loss：0.0013503178488463163，acc：1.0\n",
      "整体验证集的acc：0.993461549282074\n",
      "第110轮训练\n",
      "训练时间：12863.727978229523\n",
      "第0个批次，loss：0.00016167195281013846，acc：1.0\n",
      "训练时间：12877.151046991348\n",
      "第100个批次，loss：0.0008091136696748435，acc：1.0\n",
      "训练时间：12890.584517240524\n",
      "第200个批次，loss：0.0056024533696472645，acc：1.0\n",
      "训练时间：12904.019557237625\n",
      "第300个批次，loss：0.00030960829462856054，acc：1.0\n",
      "训练时间：12917.468002796173\n",
      "第400个批次，loss：0.04322291165590286，acc：0.96875\n",
      "训练时间：12930.899727106094\n",
      "第500个批次，loss：0.004581934306770563，acc：1.0\n",
      "训练时间：12944.349175453186\n",
      "第600个批次，loss：0.0005456905346363783，acc：1.0\n",
      "训练时间：12957.781628608704\n",
      "第700个批次，loss：6.736739305779338e-05，acc：1.0\n",
      "训练时间：12971.214899301529\n",
      "第800个批次，loss：0.009266025386750698，acc：1.0\n",
      "整体验证集的acc：0.9938461780548096\n",
      "第111轮训练\n",
      "训练时间：12980.889641284943\n",
      "第0个批次，loss：0.008679600432515144，acc：1.0\n",
      "训练时间：12994.317476272583\n",
      "第100个批次，loss：0.00045293880975805223，acc：1.0\n",
      "训练时间：13007.76565003395\n",
      "第200个批次，loss：0.012275401502847672，acc：1.0\n",
      "训练时间：13021.195754289627\n",
      "第300个批次，loss：0.004140871576964855，acc：1.0\n",
      "训练时间：13034.64641880989\n",
      "第400个批次，loss：4.388756860862486e-05，acc：1.0\n",
      "训练时间：13048.077465057373\n",
      "第500个批次，loss：0.016911739483475685，acc：1.0\n",
      "训练时间：13061.529597043991\n",
      "第600个批次，loss：6.838636909378693e-05，acc：1.0\n",
      "训练时间：13074.962171792984\n",
      "第700个批次，loss：0.00011422421084716916，acc：1.0\n",
      "训练时间：13088.412829875946\n",
      "第800个批次，loss：0.030173489823937416，acc：1.0\n",
      "整体验证集的acc：0.9921153783798218\n",
      "第112轮训练\n",
      "训练时间：13098.049308300018\n",
      "第0个批次，loss：0.00012962707842234522，acc：1.0\n",
      "训练时间：13111.489269733429\n",
      "第100个批次，loss：0.00030976050766184926，acc：1.0\n",
      "训练时间：13124.911544084549\n",
      "第200个批次，loss：0.06565393507480621，acc：0.96875\n",
      "训练时间：13138.32677102089\n",
      "第300个批次，loss：0.0004382511251606047，acc：1.0\n",
      "训练时间：13151.777148008347\n",
      "第400个批次，loss：0.004623531363904476，acc：1.0\n",
      "训练时间：13165.20958852768\n",
      "第500个批次，loss：7.650163024663925e-05，acc：1.0\n",
      "训练时间：13178.641966342926\n",
      "第600个批次，loss：0.0010679274564608932，acc：1.0\n",
      "训练时间：13192.075006961823\n",
      "第700个批次，loss：0.0013083890080451965，acc：1.0\n",
      "训练时间：13205.542156934738\n",
      "第800个批次，loss：0.00277083832770586，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第113轮训练\n",
      "训练时间：13215.138128519058\n",
      "第0个批次，loss：0.0666043609380722，acc：0.96875\n",
      "训练时间：13228.574558258057\n",
      "第100个批次，loss：0.00048151161172427237，acc：1.0\n",
      "训练时间：13241.99551987648\n",
      "第200个批次，loss：0.00030395592330023646，acc：1.0\n",
      "训练时间：13255.425078630447\n",
      "第300个批次，loss：0.006762244738638401，acc：1.0\n",
      "训练时间：13268.85526394844\n",
      "第400个批次，loss：7.792127871653065e-05，acc：1.0\n",
      "训练时间：13282.287310361862\n",
      "第500个批次，loss：0.00036698573967441916，acc：1.0\n",
      "训练时间：13295.704683542252\n",
      "第600个批次，loss：0.00014577739057131112，acc：1.0\n",
      "训练时间：13309.153806447983\n",
      "第700个批次，loss：0.00154928641859442，acc：1.0\n",
      "训练时间：13322.586575508118\n",
      "第800个批次，loss：0.018155120313167572，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第114轮训练\n",
      "训练时间：13332.165748596191\n",
      "第0个批次，loss：0.0010405916254967451，acc：1.0\n",
      "训练时间：13345.599793195724\n",
      "第100个批次，loss：0.0021580029278993607，acc：1.0\n",
      "训练时间：13359.019175291061\n",
      "第200个批次，loss：0.003183405613526702，acc：1.0\n",
      "训练时间：13372.43438410759\n",
      "第300个批次，loss：0.0001312947424594313，acc：1.0\n",
      "训练时间：13385.880176067352\n",
      "第400个批次，loss：0.013552303425967693，acc：1.0\n",
      "训练时间：13399.320605754852\n",
      "第500个批次，loss：0.0027821885887533426，acc：1.0\n",
      "训练时间：13412.751456975937\n",
      "第600个批次，loss：0.052435968071222305，acc：0.96875\n",
      "训练时间：13426.168951272964\n",
      "第700个批次，loss：0.019241835922002792，acc：1.0\n",
      "训练时间：13439.599228858948\n",
      "第800个批次，loss：0.0012356408406049013，acc：1.0\n",
      "整体验证集的acc：0.993461549282074\n",
      "第115轮训练\n",
      "训练时间：13449.205738306046\n",
      "第0个批次，loss：0.00021023130102548748，acc：1.0\n",
      "训练时间：13462.630847930908\n",
      "第100个批次，loss：0.00018885180179495364，acc：1.0\n",
      "训练时间：13476.066958904266\n",
      "第200个批次，loss：0.0008208773215301335，acc：1.0\n",
      "训练时间：13489.498287916183\n",
      "第300个批次，loss：0.0013671035412698984，acc：1.0\n",
      "训练时间：13502.932302236557\n",
      "第400个批次，loss：0.0008552095387130976，acc：1.0\n",
      "训练时间：13516.365405797958\n",
      "第500个批次，loss：0.0009296314674429595，acc：1.0\n",
      "训练时间：13529.780275821686\n",
      "第600个批次，loss：0.0017568257171660662，acc：1.0\n",
      "训练时间：13543.212376356125\n",
      "第700个批次，loss：0.0001683411974227056，acc：1.0\n",
      "训练时间：13556.645419359207\n",
      "第800个批次，loss：0.0006527882651425898，acc：1.0\n",
      "整体验证集的acc：0.9936538338661194\n",
      "第116轮训练\n",
      "训练时间：13566.226585626602\n",
      "第0个批次，loss：0.00043261199607513845，acc：1.0\n",
      "训练时间：13579.644913434982\n",
      "第100个批次，loss：0.0002581094449851662，acc：1.0\n",
      "训练时间：13593.061441898346\n",
      "第200个批次，loss：0.0064680082723498344，acc：1.0\n",
      "训练时间：13606.477790355682\n",
      "第300个批次，loss：8.00999696366489e-05，acc：1.0\n",
      "训练时间：13619.89435505867\n",
      "第400个批次，loss：0.00014204622129909694，acc：1.0\n",
      "训练时间：13633.327400684357\n",
      "第500个批次，loss：0.0001264806487597525，acc：1.0\n",
      "训练时间：13646.77544426918\n",
      "第600个批次，loss：0.00014730503608006984，acc：1.0\n",
      "训练时间：13660.209483861923\n",
      "第700个批次，loss：0.0001402587367920205，acc：1.0\n",
      "训练时间：13673.642034769058\n",
      "第800个批次，loss：0.00029989040922373533，acc：1.0\n",
      "整体验证集的acc：0.9936538338661194\n",
      "第117轮训练\n",
      "训练时间：13683.23560667038\n",
      "第0个批次，loss：0.0037967858370393515，acc：1.0\n",
      "训练时间：13696.674070119858\n",
      "第100个批次，loss：0.0019935802556574345，acc：1.0\n",
      "训练时间：13710.106382846832\n",
      "第200个批次，loss：0.0996277928352356，acc：0.96875\n",
      "训练时间：13723.542887449265\n",
      "第300个批次，loss：0.0032377534080296755，acc：1.0\n",
      "训练时间：13737.005134344101\n",
      "第400个批次，loss：0.0014509247848764062，acc：1.0\n",
      "训练时间：13750.438170194626\n",
      "第500个批次，loss：0.0011637343559414148，acc：1.0\n",
      "训练时间：13763.87225317955\n",
      "第600个批次，loss：0.00032130334875546396，acc：1.0\n",
      "训练时间：13777.301812171936\n",
      "第700个批次，loss：0.0005323439254425466，acc：1.0\n",
      "训练时间：13790.739085674286\n",
      "第800个批次，loss：0.000280031148577109，acc：1.0\n",
      "整体验证集的acc：0.994038462638855\n",
      "第118轮训练\n",
      "训练时间：13800.343255758286\n",
      "第0个批次，loss：0.00045803128159604967，acc：1.0\n",
      "训练时间：13813.77063035965\n",
      "第100个批次，loss：0.006304798182100058，acc：1.0\n",
      "训练时间：13827.20265841484\n",
      "第200个批次，loss：0.0001567456783959642，acc：1.0\n",
      "训练时间：13840.65322470665\n",
      "第300个批次，loss：0.0007034532027319074，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：13854.086211919785\n",
      "第400个批次，loss：0.0037861433811485767，acc：1.0\n",
      "训练时间：13867.520242452621\n",
      "第500个批次，loss：0.010293570347130299，acc：1.0\n",
      "训练时间：13880.952474117279\n",
      "第600个批次，loss：0.0012473141541704535，acc：1.0\n",
      "训练时间：13894.40066075325\n",
      "第700个批次，loss：0.008597617968916893，acc：1.0\n",
      "训练时间：13907.8371155262\n",
      "第800个批次，loss：0.001962101785466075，acc：1.0\n",
      "整体验证集的acc：0.9936538338661194\n",
      "第119轮训练\n",
      "训练时间：13917.460504770279\n",
      "第0个批次，loss：0.0014495879877358675，acc：1.0\n",
      "训练时间：13930.88287973404\n",
      "第100个批次，loss：0.0003127531090285629，acc：1.0\n",
      "训练时间：13944.315923213959\n",
      "第200个批次，loss：0.027711335569620132，acc：1.0\n",
      "训练时间：13957.749396800995\n",
      "第300个批次，loss：0.0006389259360730648，acc：1.0\n",
      "训练时间：13971.183725833893\n",
      "第400个批次，loss：0.0652640089392662，acc：0.96875\n",
      "训练时间：13984.631978273392\n",
      "第500个批次，loss：0.0005135352839715779，acc：1.0\n",
      "训练时间：13998.082042694092\n",
      "第600个批次，loss：0.0013891503913328052，acc：1.0\n",
      "训练时间：14011.515143871307\n",
      "第700个批次，loss：0.002892520511522889，acc：1.0\n",
      "训练时间：14024.94718003273\n",
      "第800个批次，loss：0.0010706024477258325，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第120轮训练\n",
      "训练时间：14034.560772657394\n",
      "第0个批次，loss：0.0014582669828087091，acc：1.0\n",
      "训练时间：14047.996421813965\n",
      "第100个批次，loss：0.00048166781198233366，acc：1.0\n",
      "训练时间：14061.430804014206\n",
      "第200个批次，loss：0.00042280321940779686，acc：1.0\n",
      "训练时间：14074.862835645676\n",
      "第300个批次，loss：0.00012126530054956675，acc：1.0\n",
      "训练时间：14088.279863834381\n",
      "第400个批次，loss：0.0003612581640481949，acc：1.0\n",
      "训练时间：14101.71032500267\n",
      "第500个批次，loss：0.00039550772635266185，acc：1.0\n",
      "训练时间：14115.142864704132\n",
      "第600个批次，loss：0.0008344591478817165，acc：1.0\n",
      "训练时间：14128.594903707504\n",
      "第700个批次，loss：0.0010717186378315091，acc：1.0\n",
      "训练时间：14142.043944120407\n",
      "第800个批次，loss：0.0015341842081397772，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第121轮训练\n",
      "训练时间：14151.730161428452\n",
      "第0个批次，loss：0.0006334743229672313，acc：1.0\n",
      "训练时间：14165.168208122253\n",
      "第100个批次，loss：0.00010382562322774902，acc：1.0\n",
      "训练时间：14178.591719150543\n",
      "第200个批次，loss：0.001226183376275003，acc：1.0\n",
      "训练时间：14192.024157524109\n",
      "第300个批次，loss：7.870311674196273e-05，acc：1.0\n",
      "训练时间：14205.45698261261\n",
      "第400个批次，loss：0.0006968661327846348，acc：1.0\n",
      "训练时间：14218.924502849579\n",
      "第500个批次，loss：0.0015031129587441683，acc：1.0\n",
      "训练时间：14232.356989622116\n",
      "第600个批次，loss：0.000683070975355804，acc：1.0\n",
      "训练时间：14245.806077480316\n",
      "第700个批次，loss：0.002453904366120696，acc：1.0\n",
      "训练时间：14259.23919558525\n",
      "第800个批次，loss：0.0020668955985456705，acc：1.0\n",
      "整体验证集的acc：0.9917307496070862\n",
      "第122轮训练\n",
      "训练时间：14268.849735736847\n",
      "第0个批次，loss：0.002276051789522171，acc：1.0\n",
      "训练时间：14282.289279937744\n",
      "第100个批次，loss：0.000646411266643554，acc：1.0\n",
      "训练时间：14295.736406564713\n",
      "第200个批次，loss：0.001585807534866035，acc：1.0\n",
      "训练时间：14309.15444946289\n",
      "第300个批次，loss：9.02573301573284e-05，acc：1.0\n",
      "训练时间：14322.608822107315\n",
      "第400个批次，loss：0.0009885795880109072，acc：1.0\n",
      "训练时间：14336.038457393646\n",
      "第500个批次，loss：0.0009801097912713885，acc：1.0\n",
      "训练时间：14349.481922864914\n",
      "第600个批次，loss：0.007008980959653854，acc：1.0\n",
      "训练时间：14362.918956518173\n",
      "第700个批次，loss：0.00034677822259254754，acc：1.0\n",
      "训练时间：14376.36987042427\n",
      "第800个批次，loss：0.0001749302464304492，acc：1.0\n",
      "整体验证集的acc：0.9930769205093384\n",
      "第123轮训练\n",
      "训练时间：14385.99137544632\n",
      "第0个批次，loss：0.0002442630648147315，acc：1.0\n",
      "训练时间：14399.43472647667\n",
      "第100个批次，loss：0.00519441906362772，acc：1.0\n",
      "训练时间：14412.865921258926\n",
      "第200个批次，loss：0.00019361518207006156，acc：1.0\n",
      "训练时间：14426.31646823883\n",
      "第300个批次，loss：0.00010883380309678614，acc：1.0\n",
      "训练时间：14439.750715494156\n",
      "第400个批次，loss：0.00015538177103735507，acc：1.0\n",
      "训练时间：14453.181942462921\n",
      "第500个批次，loss：0.0017184598837047815，acc：1.0\n",
      "训练时间：14466.597064256668\n",
      "第600个批次，loss：0.0005812590243294835，acc：1.0\n",
      "训练时间：14480.032358646393\n",
      "第700个批次，loss：0.00022842097678221762，acc：1.0\n",
      "训练时间：14493.464346408844\n",
      "第800个批次，loss：0.002537352964282036，acc：1.0\n",
      "整体验证集的acc：0.9942307472229004\n",
      "第124轮训练\n",
      "训练时间：14503.100749015808\n",
      "第0个批次，loss：0.00016155614866875112，acc：1.0\n",
      "训练时间：14516.53522515297\n",
      "第100个批次，loss：0.0008817508351057768，acc：1.0\n",
      "训练时间：14529.979521989822\n",
      "第200个批次，loss：0.0001917196495924145，acc：1.0\n",
      "训练时间：14543.44657278061\n",
      "第300个批次，loss：5.400285590440035e-05，acc：1.0\n",
      "训练时间：14556.895341396332\n",
      "第400个批次，loss：5.620347292278893e-05，acc：1.0\n",
      "训练时间：14570.345785856247\n",
      "第500个批次，loss：0.00043476952123455703，acc：1.0\n",
      "训练时间：14583.778898000717\n",
      "第600个批次，loss：0.004311177413910627，acc：1.0\n",
      "训练时间：14597.21122097969\n",
      "第700个批次，loss：0.0861332044005394，acc：0.96875\n",
      "训练时间：14610.643961668015\n",
      "第800个批次，loss：0.0001930409052874893，acc：1.0\n",
      "整体验证集的acc：0.992307722568512\n",
      "第125轮训练\n",
      "训练时间：14620.262937545776\n",
      "第0个批次，loss：0.0009180324850603938，acc：1.0\n",
      "训练时间：14633.692948818207\n",
      "第100个批次，loss：0.00014178574201650918，acc：1.0\n",
      "训练时间：14647.135415554047\n",
      "第200个批次，loss：0.0002674997958820313，acc：1.0\n",
      "训练时间：14660.57454419136\n",
      "第300个批次，loss：0.00010497756011318415，acc：1.0\n",
      "训练时间：14674.006145238876\n",
      "第400个批次，loss：9.625958045944571e-05，acc：1.0\n",
      "训练时间：14687.441136360168\n",
      "第500个批次，loss：0.00022452513803727925，acc：1.0\n",
      "训练时间：14700.92584991455\n",
      "第600个批次，loss：0.0007987745339050889，acc：1.0\n",
      "训练时间：14714.575002193451\n",
      "第700个批次，loss：0.0010966859990730882，acc：1.0\n",
      "训练时间：14728.257517576218\n",
      "第800个批次，loss：0.00029767549131065607，acc：1.0\n",
      "整体验证集的acc：0.9917307496070862\n",
      "第126轮训练\n",
      "训练时间：14738.108743429184\n",
      "第0个批次，loss：0.09609262645244598，acc：0.96875\n",
      "训练时间：14751.982815980911\n",
      "第100个批次，loss：0.03243900462985039，acc：0.96875\n",
      "训练时间：14767.902063131332\n",
      "第200个批次，loss：0.000791507656686008，acc：1.0\n",
      "训练时间：14785.819338321686\n",
      "第300个批次，loss：0.0001150381431216374，acc：1.0\n",
      "训练时间：14803.78037238121\n",
      "第400个批次，loss：0.0018022686708718538，acc：1.0\n",
      "训练时间：14821.935215711594\n",
      "第500个批次，loss：9.29005618672818e-05，acc：1.0\n",
      "训练时间：14836.787564754486\n",
      "第600个批次，loss：0.026680894196033478，acc：0.96875\n",
      "训练时间：14850.452795743942\n",
      "第700个批次，loss：0.1456797569990158，acc：0.9375\n",
      "训练时间：14864.61747598648\n",
      "第800个批次，loss：0.06745810061693192，acc：0.96875\n",
      "整体验证集的acc：0.994038462638855\n",
      "第127轮训练\n",
      "训练时间：14877.777877092361\n",
      "第0个批次，loss：0.0020981295965611935，acc：1.0\n",
      "训练时间：14892.279021501541\n",
      "第100个批次，loss：7.120491500245407e-05，acc：1.0\n",
      "训练时间：14906.626191139221\n",
      "第200个批次，loss：0.0005891977925784886，acc：1.0\n",
      "训练时间：14922.777391672134\n",
      "第300个批次，loss：0.00026694568805396557，acc：1.0\n",
      "训练时间：14936.692859172821\n",
      "第400个批次，loss：0.020618291571736336，acc：1.0\n",
      "训练时间：14950.340188026428\n",
      "第500个批次，loss：0.00023629273346159607，acc：1.0\n",
      "训练时间：14963.905479192734\n",
      "第600个批次，loss：0.000512080208864063，acc：1.0\n",
      "训练时间：14977.568150997162\n",
      "第700个批次，loss：0.00011437392822699621，acc：1.0\n",
      "训练时间：14991.42743396759\n",
      "第800个批次，loss：0.005326530430465937，acc：1.0\n",
      "整体验证集的acc：0.9942307472229004\n",
      "第128轮训练\n",
      "训练时间：15001.30772948265\n",
      "第0个批次，loss：0.009898986667394638，acc：1.0\n",
      "训练时间：15014.788714647293\n",
      "第100个批次，loss：0.0043958439491689205，acc：1.0\n",
      "训练时间：15028.238554477692\n",
      "第200个批次，loss：0.0004028337716590613，acc：1.0\n",
      "训练时间：15041.796795368195\n",
      "第300个批次，loss：0.0026442150119692087，acc：1.0\n",
      "训练时间：15054.963822364807\n",
      "第400个批次，loss：0.0001869325351435691，acc：1.0\n",
      "训练时间：15068.122757673264\n",
      "第500个批次，loss：8.280380279757082e-05，acc：1.0\n",
      "训练时间：15081.264742136002\n",
      "第600个批次，loss：0.017774801701307297，acc：1.0\n",
      "训练时间：15094.451726436615\n",
      "第700个批次，loss：0.000734522647690028，acc：1.0\n",
      "训练时间：15107.644738912582\n",
      "第800个批次，loss：9.557314479025081e-05，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第129轮训练\n",
      "训练时间：15117.142407417297\n",
      "第0个批次，loss：0.0009326571598649025，acc：1.0\n",
      "训练时间：15130.296126365662\n",
      "第100个批次，loss：0.017401203513145447，acc：1.0\n",
      "训练时间：15143.469417572021\n",
      "第200个批次，loss：0.0022961501963436604，acc：1.0\n",
      "训练时间：15156.622385501862\n",
      "第300个批次，loss：0.001776049379259348，acc：1.0\n",
      "训练时间：15169.773359537125\n",
      "第400个批次，loss：0.002754095708951354，acc：1.0\n",
      "训练时间：15182.902829885483\n",
      "第500个批次，loss：0.0032750065438449383，acc：1.0\n",
      "训练时间：15196.110901594162\n",
      "第600个批次，loss：0.0004093079187441617，acc：1.0\n",
      "训练时间：15209.25785779953\n",
      "第700个批次，loss：0.0016392661491408944，acc：1.0\n",
      "训练时间：15222.406319379807\n",
      "第800个批次，loss：0.0022435772698372602，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第130轮训练\n",
      "训练时间：15231.820447921753\n",
      "第0个批次，loss：8.475372305838391e-05，acc：1.0\n",
      "训练时间：15244.95940542221\n",
      "第100个批次，loss：0.00024482878507114947，acc：1.0\n",
      "训练时间：15258.116707801819\n",
      "第200个批次，loss：0.0032381725031882524，acc：1.0\n",
      "训练时间：15271.24167919159\n",
      "第300个批次，loss：0.0014215140836313367，acc：1.0\n",
      "训练时间：15284.381878137589\n",
      "第400个批次，loss：0.0013739541172981262，acc：1.0\n",
      "训练时间：15297.65586900711\n",
      "第500个批次，loss：0.0010400025639683008，acc：1.0\n",
      "训练时间：15310.824547290802\n",
      "第600个批次，loss：0.0055643171072006226，acc：1.0\n",
      "训练时间：15323.966801404953\n",
      "第700个批次，loss：0.007697161287069321，acc：1.0\n",
      "训练时间：15337.114588975906\n",
      "第800个批次，loss：6.620044587180018e-05，acc：1.0\n",
      "整体验证集的acc：0.9915384650230408\n",
      "第131轮训练\n",
      "训练时间：15346.60172700882\n",
      "第0个批次，loss：0.00043816142715513706，acc：1.0\n",
      "训练时间：15359.727024316788\n",
      "第100个批次，loss：0.00023757923918310553，acc：1.0\n",
      "训练时间：15372.860460996628\n",
      "第200个批次，loss：0.0031584021635353565，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：15385.993904590607\n",
      "第300个批次，loss：0.00022610364248976111，acc：1.0\n",
      "训练时间：15399.12237739563\n",
      "第400个批次，loss：0.0020112197380512953，acc：1.0\n",
      "训练时间：15412.266336917877\n",
      "第500个批次，loss：0.0003174423472955823，acc：1.0\n",
      "训练时间：15425.434317827225\n",
      "第600个批次，loss：8.271000115200877e-05，acc：1.0\n",
      "训练时间：15438.581283807755\n",
      "第700个批次，loss：0.007346080616116524，acc：1.0\n",
      "训练时间：15451.714254617691\n",
      "第800个批次，loss：4.962738967151381e-05，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第132轮训练\n",
      "训练时间：15461.147690534592\n",
      "第0个批次，loss：0.0001117411520681344，acc：1.0\n",
      "训练时间：15474.27665734291\n",
      "第100个批次，loss：0.0003853213565889746，acc：1.0\n",
      "训练时间：15487.42102599144\n",
      "第200个批次，loss：0.0004131582099944353，acc：1.0\n",
      "训练时间：15500.548997879028\n",
      "第300个批次，loss：0.0020938224624842405，acc：1.0\n",
      "训练时间：15513.68432855606\n",
      "第400个批次，loss：0.0006534627755172551，acc：1.0\n",
      "训练时间：15526.826629400253\n",
      "第500个批次，loss：0.0015640964265912771，acc：1.0\n",
      "训练时间：15539.984750270844\n",
      "第600个批次，loss：0.00040995384915731847，acc：1.0\n",
      "训练时间：15553.143057584763\n",
      "第700个批次，loss：0.00014883936091791838，acc：1.0\n",
      "训练时间：15566.283027648926\n",
      "第800个批次，loss：0.020250381901860237，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第133轮训练\n",
      "训练时间：15575.71316242218\n",
      "第0个批次，loss：0.00026693090330809355，acc：1.0\n",
      "训练时间：15588.8471159935\n",
      "第100个批次，loss：0.004026705399155617，acc：1.0\n",
      "训练时间：15601.981073617935\n",
      "第200个批次，loss：0.00036230223486199975，acc：1.0\n",
      "训练时间：15615.100039482117\n",
      "第300个批次，loss：0.00027456917450763285，acc：1.0\n",
      "训练时间：15628.23880648613\n",
      "第400个批次，loss：0.004563446622341871，acc：1.0\n",
      "训练时间：15641.361399888992\n",
      "第500个批次，loss：0.00029662903398275375，acc：1.0\n",
      "训练时间：15654.499738454819\n",
      "第600个批次，loss：0.005106386728584766，acc：1.0\n",
      "训练时间：15667.653721094131\n",
      "第700个批次，loss：0.11760356277227402，acc：0.96875\n",
      "训练时间：15680.78295135498\n",
      "第800个批次，loss：0.0001255528040928766，acc：1.0\n",
      "整体验证集的acc：0.994038462638855\n",
      "第134轮训练\n",
      "训练时间：15690.21330690384\n",
      "第0个批次，loss：3.842648584395647e-05，acc：1.0\n",
      "训练时间：15703.325669765472\n",
      "第100个批次，loss：0.025455206632614136，acc：0.96875\n",
      "训练时间：15716.445630788803\n",
      "第200个批次，loss：0.0008280811598524451，acc：1.0\n",
      "训练时间：15729.573560476303\n",
      "第300个批次，loss：0.00030076110851950943，acc：1.0\n",
      "训练时间：15742.70869898796\n",
      "第400个批次，loss：0.00046786892926320434，acc：1.0\n",
      "训练时间：15755.84405374527\n",
      "第500个批次，loss：0.00027492319350130856，acc：1.0\n",
      "训练时间：15768.96495103836\n",
      "第600个批次，loss：0.02352142333984375，acc：1.0\n",
      "训练时间：15782.099598646164\n",
      "第700个批次，loss：0.007349254563450813，acc：1.0\n",
      "训练时间：15795.253576755524\n",
      "第800个批次，loss：0.00021558260777965188，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第135轮训练\n",
      "训练时间：15804.642987966537\n",
      "第0个批次，loss：0.02837994694709778，acc：1.0\n",
      "训练时间：15817.772950410843\n",
      "第100个批次，loss：0.0025218429509550333，acc：1.0\n",
      "训练时间：15830.9029109478\n",
      "第200个批次，loss：0.0017559921834617853，acc：1.0\n",
      "训练时间：15844.031127929688\n",
      "第300个批次，loss：0.0004503399250097573，acc：1.0\n",
      "训练时间：15857.160522699356\n",
      "第400个批次，loss：0.00054351327707991，acc：1.0\n",
      "训练时间：15870.290745019913\n",
      "第500个批次，loss：0.0035874443128705025，acc：1.0\n",
      "训练时间：15883.418954133987\n",
      "第600个批次，loss：0.0006471448577940464，acc：1.0\n",
      "训练时间：15896.551339626312\n",
      "第700个批次，loss：0.0022408715449273586，acc：1.0\n",
      "训练时间：15909.705305576324\n",
      "第800个批次，loss：0.06363167613744736，acc：0.96875\n",
      "整体验证集的acc：0.992307722568512\n",
      "第136轮训练\n",
      "训练时间：15919.152445793152\n",
      "第0个批次，loss：0.0002912216878030449，acc：1.0\n",
      "训练时间：15932.27461051941\n",
      "第100个批次，loss：0.0015056622214615345，acc：1.0\n",
      "训练时间：15945.424571275711\n",
      "第200个批次，loss：0.0027306952979415655，acc：1.0\n",
      "训练时间：15958.536566972733\n",
      "第300个批次，loss：0.0009455081890337169，acc：1.0\n",
      "训练时间：15971.684533596039\n",
      "第400个批次，loss：0.0006312637706287205，acc：1.0\n",
      "训练时间：15984.823324918747\n",
      "第500个批次，loss：0.002687206258997321，acc：1.0\n",
      "训练时间：15997.953689813614\n",
      "第600个批次，loss：0.0007908898405730724，acc：1.0\n",
      "训练时间：16011.107587575912\n",
      "第700个批次，loss：0.00011434130283305421，acc：1.0\n",
      "训练时间：16024.256562948227\n",
      "第800个批次，loss：0.0036018253304064274，acc：1.0\n",
      "整体验证集的acc：0.993461549282074\n",
      "第137轮训练\n",
      "训练时间：16033.664696455002\n",
      "第0个批次，loss：0.0020729464013129473，acc：1.0\n",
      "训练时间：16046.796455144882\n",
      "第100个批次，loss：0.028629133477807045，acc：1.0\n",
      "训练时间：16059.930428266525\n",
      "第200个批次，loss：0.001582973636686802，acc：1.0\n",
      "训练时间：16073.06962108612\n",
      "第300个批次，loss：8.293379505630583e-05，acc：1.0\n",
      "训练时间：16086.201792240143\n",
      "第400个批次，loss：0.020811520516872406，acc：1.0\n",
      "训练时间：16099.365147829056\n",
      "第500个批次，loss：0.00025688702589832246，acc：1.0\n",
      "训练时间：16112.493686199188\n",
      "第600个批次，loss：0.030073855072259903，acc：0.96875\n",
      "训练时间：16125.65275478363\n",
      "第700个批次，loss：0.000714142166543752，acc：1.0\n",
      "训练时间：16138.788717269897\n",
      "第800个批次，loss：0.0006911515956744552，acc：1.0\n",
      "整体验证集的acc：0.9942307472229004\n",
      "第138轮训练\n",
      "训练时间：16148.284856319427\n",
      "第0个批次，loss：0.0006150616682134569，acc：1.0\n",
      "训练时间：16161.428039550781\n",
      "第100个批次，loss：0.00031894806306809187，acc：1.0\n",
      "训练时间：16174.575269460678\n",
      "第200个批次，loss：0.00037520495243370533，acc：1.0\n",
      "训练时间：16187.70931982994\n",
      "第300个批次，loss：0.0016018287278711796，acc：1.0\n",
      "训练时间：16200.862281799316\n",
      "第400个批次，loss：0.004012860357761383，acc：1.0\n",
      "训练时间：16213.996242523193\n",
      "第500个批次，loss：0.09874952584505081，acc：0.96875\n",
      "训练时间：16227.129261493683\n",
      "第600个批次，loss：0.00010536623449297622，acc：1.0\n",
      "训练时间：16240.266149044037\n",
      "第700个批次，loss：0.0008810863364487886，acc：1.0\n",
      "训练时间：16253.402297496796\n",
      "第800个批次，loss：0.00030242878710851073，acc：1.0\n",
      "整体验证集的acc：0.9948077201843262\n",
      "第139轮训练\n",
      "训练时间：16262.817893981934\n",
      "第0个批次，loss：0.00023205600155051798，acc：1.0\n",
      "训练时间：16275.979256391525\n",
      "第100个批次，loss：0.001612070482224226，acc：1.0\n",
      "训练时间：16289.121233701706\n",
      "第200个批次，loss：0.0006741309771314263，acc：1.0\n",
      "训练时间：16302.249244689941\n",
      "第300个批次，loss：0.0005029903841204941，acc：1.0\n",
      "训练时间：16315.387567281723\n",
      "第400个批次，loss：0.00013636302901431918，acc：1.0\n",
      "训练时间：16328.524271965027\n",
      "第500个批次，loss：0.00021328828006517142，acc：1.0\n",
      "训练时间：16341.671631336212\n",
      "第600个批次，loss：0.00022777626872994006，acc：1.0\n",
      "训练时间：16354.807958602905\n",
      "第700个批次，loss：0.0007311709923669696，acc：1.0\n",
      "训练时间：16368.010026693344\n",
      "第800个批次，loss：0.00039391726022586226，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第140轮训练\n",
      "训练时间：16377.445388317108\n",
      "第0个批次，loss：0.0002085272135445848，acc：1.0\n",
      "训练时间：16390.601921081543\n",
      "第100个批次，loss：0.0011106188176199794，acc：1.0\n",
      "训练时间：16403.73498749733\n",
      "第200个批次，loss：0.004493629094213247，acc：1.0\n",
      "训练时间：16416.86294579506\n",
      "第300个批次，loss：0.0002738708280958235，acc：1.0\n",
      "训练时间：16429.99890112877\n",
      "第400个批次，loss：0.0009402434225194156，acc：1.0\n",
      "训练时间：16443.147369623184\n",
      "第500个批次，loss：0.0025809546932578087，acc：1.0\n",
      "训练时间：16456.275448322296\n",
      "第600个批次，loss：0.0007071481086313725，acc：1.0\n",
      "训练时间：16469.41288781166\n",
      "第700个批次，loss：0.00016557796334382147，acc：1.0\n",
      "训练时间：16482.535872220993\n",
      "第800个批次，loss：0.00020881861564703286，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第141轮训练\n",
      "训练时间：16492.028013944626\n",
      "第0个批次，loss：0.0076425811275839806，acc：1.0\n",
      "训练时间：16505.182990074158\n",
      "第100个批次，loss：0.002955873729661107，acc：1.0\n",
      "训练时间：16518.33136153221\n",
      "第200个批次，loss：0.00012879462155979127，acc：1.0\n",
      "训练时间：16531.46209049225\n",
      "第300个批次，loss：0.00048525171587243676，acc：1.0\n",
      "训练时间：16544.584716320038\n",
      "第400个批次，loss：0.0002611981763038784，acc：1.0\n",
      "训练时间：16557.727038145065\n",
      "第500个批次，loss：0.00025291898055002093，acc：1.0\n",
      "训练时间：16570.867911577225\n",
      "第600个批次，loss：0.00015592460113111883，acc：1.0\n",
      "训练时间：16584.007883548737\n",
      "第700个批次，loss：0.0029367224778980017，acc：1.0\n",
      "训练时间：16597.13921189308\n",
      "第800个批次，loss：0.020006835460662842，acc：1.0\n",
      "整体验证集的acc：0.9921153783798218\n",
      "第142轮训练\n",
      "训练时间：16606.62335371971\n",
      "第0个批次，loss：0.0001755211123963818，acc：1.0\n",
      "训练时间：16619.748391866684\n",
      "第100个批次，loss：0.0005572087247855961，acc：1.0\n",
      "训练时间：16632.91036272049\n",
      "第200个批次，loss：0.0004089827125426382，acc：1.0\n",
      "训练时间：16646.036620378494\n",
      "第300个批次，loss：0.0001615579385543242，acc：1.0\n",
      "训练时间：16659.164578676224\n",
      "第400个批次，loss：5.3224324801703915e-05，acc：1.0\n",
      "训练时间：16672.291945695877\n",
      "第500个批次，loss：0.0006029388168826699，acc：1.0\n",
      "训练时间：16685.428900957108\n",
      "第600个批次，loss：0.0053698476403951645，acc：1.0\n",
      "训练时间：16698.564302444458\n",
      "第700个批次，loss：0.017814408987760544，acc：1.0\n",
      "训练时间：16711.695381879807\n",
      "第800个批次，loss：0.00042289277189411223，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第143轮训练\n",
      "训练时间：16721.14952993393\n",
      "第0个批次，loss：0.00016275999951176345，acc：1.0\n",
      "训练时间：16734.279485464096\n",
      "第100个批次，loss：0.00040599072235636413，acc：1.0\n",
      "训练时间：16747.439393520355\n",
      "第200个批次，loss：0.0035234950482845306，acc：1.0\n",
      "训练时间：16760.56821990013\n",
      "第300个批次，loss：8.569820784032345e-05，acc：1.0\n",
      "训练时间：16773.717406749725\n",
      "第400个批次，loss：0.00035360659239813685，acc：1.0\n",
      "训练时间：16786.85338449478\n",
      "第500个批次，loss：0.08448183536529541，acc：0.96875\n",
      "训练时间：16799.984344244003\n",
      "第600个批次，loss：0.004812304396182299，acc：1.0\n",
      "训练时间：16813.109071731567\n",
      "第700个批次，loss：0.000300596613669768，acc：1.0\n",
      "训练时间：16826.256596326828\n",
      "第800个批次，loss：0.004488080739974976，acc：1.0\n",
      "整体验证集的acc：0.9930769205093384\n",
      "第144轮训练\n",
      "训练时间：16835.680972337723\n",
      "第0个批次，loss：7.835305586922914e-05，acc：1.0\n",
      "训练时间：16848.807942390442\n",
      "第100个批次，loss：6.57271666568704e-05，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：16861.947907686234\n",
      "第200个批次，loss：7.351637032115832e-05，acc：1.0\n",
      "训练时间：16875.10406756401\n",
      "第300个批次，loss：0.0004455203306861222，acc：1.0\n",
      "训练时间：16888.25551724434\n",
      "第400个批次，loss：0.001636430504731834，acc：1.0\n",
      "训练时间：16901.38592338562\n",
      "第500个批次，loss：0.00033015600638464093，acc：1.0\n",
      "训练时间：16914.536200761795\n",
      "第600个批次，loss：0.0002864800044335425，acc：1.0\n",
      "训练时间：16927.6531624794\n",
      "第700个批次，loss：0.018115201964974403，acc：1.0\n",
      "训练时间：16940.78324818611\n",
      "第800个批次，loss：6.979898171266541e-05，acc：1.0\n",
      "整体验证集的acc：0.9917307496070862\n",
      "第145轮训练\n",
      "训练时间：16950.270691633224\n",
      "第0个批次，loss：5.838021752424538e-05，acc：1.0\n",
      "训练时间：16963.390060424805\n",
      "第100个批次，loss：0.00020481631509028375，acc：1.0\n",
      "训练时间：16976.509389162064\n",
      "第200个批次，loss：0.000521933485288173，acc：1.0\n",
      "训练时间：16989.667354106903\n",
      "第300个批次，loss：0.027743864804506302，acc：0.96875\n",
      "训练时间：17002.84441637993\n",
      "第400个批次，loss：0.00015714121400378644，acc：1.0\n",
      "训练时间：17015.966389894485\n",
      "第500个批次，loss：0.0037871270906180143，acc：1.0\n",
      "训练时间：17029.09389424324\n",
      "第600个批次，loss：0.00036878019454889，acc：1.0\n",
      "训练时间：17042.2393989563\n",
      "第700个批次，loss：0.00010770953667815775，acc：1.0\n",
      "训练时间：17055.374925136566\n",
      "第800个批次，loss：4.919474304188043e-05，acc：1.0\n",
      "整体验证集的acc：0.9936538338661194\n",
      "第146轮训练\n",
      "训练时间：17064.805359363556\n",
      "第0个批次，loss：0.0002324490633327514，acc：1.0\n",
      "训练时间：17077.930356025696\n",
      "第100个批次，loss：0.0699022188782692，acc：0.96875\n",
      "训练时间：17091.05262875557\n",
      "第200个批次，loss：0.0012437248369678855，acc：1.0\n",
      "训练时间：17104.22993516922\n",
      "第300个批次，loss：0.020475352182984352，acc：1.0\n",
      "训练时间：17117.394904136658\n",
      "第400个批次，loss：0.014432995580136776，acc：1.0\n",
      "训练时间：17130.547877311707\n",
      "第500个批次，loss：0.0021773292683064938，acc：1.0\n",
      "训练时间：17143.70303273201\n",
      "第600个批次，loss：0.007342624478042126，acc：1.0\n",
      "训练时间：17156.864005565643\n",
      "第700个批次，loss：0.0006001305882818997，acc：1.0\n",
      "训练时间：17170.008980989456\n",
      "第800个批次，loss：0.02213313616812229，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第147轮训练\n",
      "训练时间：17179.46211528778\n",
      "第0个批次，loss：0.00020991932251490653，acc：1.0\n",
      "训练时间：17192.617245435715\n",
      "第100个批次，loss：0.0002766005345620215，acc：1.0\n",
      "训练时间：17205.775999069214\n",
      "第200个批次，loss：0.00038120915996842086，acc：1.0\n",
      "训练时间：17218.9239654541\n",
      "第300个批次，loss：0.00011691437975969166，acc：1.0\n",
      "训练时间：17232.121956825256\n",
      "第400个批次，loss：0.004307812545448542，acc：1.0\n",
      "训练时间：17245.276888370514\n",
      "第500个批次，loss：9.52883783611469e-05，acc：1.0\n",
      "训练时间：17258.45054745674\n",
      "第600个批次，loss：0.0004164499696344137，acc：1.0\n",
      "训练时间：17271.61252117157\n",
      "第700个批次，loss：0.00020918947120662779，acc：1.0\n",
      "训练时间：17284.78266453743\n",
      "第800个批次，loss：0.0004109506553504616，acc：1.0\n",
      "整体验证集的acc：0.9907692074775696\n",
      "第148轮训练\n",
      "训练时间：17294.280807495117\n",
      "第0个批次，loss：0.0026414443273097277，acc：1.0\n",
      "训练时间：17307.43978047371\n",
      "第100个批次，loss：0.0004980004741810262，acc：1.0\n",
      "训练时间：17320.604757785797\n",
      "第200个批次，loss：0.005640613846480846，acc：1.0\n",
      "训练时间：17333.761219978333\n",
      "第300个批次，loss：0.06753275543451309，acc：0.96875\n",
      "训练时间：17346.9552025795\n",
      "第400个批次，loss：0.002424737671390176，acc：1.0\n",
      "训练时间：17360.107170820236\n",
      "第500个批次，loss：0.00028681897674687207，acc：1.0\n",
      "训练时间：17373.249228954315\n",
      "第600个批次，loss：0.0007084925309754908，acc：1.0\n",
      "训练时间：17386.386159181595\n",
      "第700个批次，loss：0.09081480652093887，acc：0.96875\n",
      "训练时间：17399.529056549072\n",
      "第800个批次，loss：0.00010339682921767235，acc：1.0\n",
      "整体验证集的acc：0.9938461780548096\n",
      "第149轮训练\n",
      "训练时间：17408.957256555557\n",
      "第0个批次，loss：0.00012957246508449316，acc：1.0\n",
      "训练时间：17422.095462322235\n",
      "第100个批次，loss：0.01487945020198822，acc：1.0\n",
      "训练时间：17435.484617233276\n",
      "第200个批次，loss：0.0002141200820915401，acc：1.0\n",
      "训练时间：17448.68761229515\n",
      "第300个批次，loss：0.001780455349944532，acc：1.0\n",
      "训练时间：17461.83806014061\n",
      "第400个批次，loss：0.0002359995705774054，acc：1.0\n",
      "训练时间：17474.99934911728\n",
      "第500个批次，loss：0.0004342455940786749，acc：1.0\n",
      "训练时间：17488.144372224808\n",
      "第600个批次，loss：7.980037480592728e-05，acc：1.0\n",
      "训练时间：17501.2761425972\n",
      "第700个批次，loss：0.00047003792133182287，acc：1.0\n",
      "训练时间：17514.413782596588\n",
      "第800个批次，loss：0.00011912187619600445，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第150轮训练\n",
      "训练时间：17523.887843847275\n",
      "第0个批次，loss：9.983537893276662e-05，acc：1.0\n",
      "训练时间：17537.03518462181\n",
      "第100个批次，loss：0.0024903917219489813，acc：1.0\n",
      "训练时间：17550.167883634567\n",
      "第200个批次，loss：0.014724746346473694，acc：1.0\n",
      "训练时间：17563.316960811615\n",
      "第300个批次，loss：0.00559672387316823，acc：1.0\n",
      "训练时间：17576.460207939148\n",
      "第400个批次，loss：0.0003287135623395443，acc：1.0\n",
      "训练时间：17589.61952471733\n",
      "第500个批次，loss：0.00012739469821099192，acc：1.0\n",
      "训练时间：17602.774491786957\n",
      "第600个批次，loss：5.870333916391246e-05，acc：1.0\n",
      "训练时间：17615.914414405823\n",
      "第700个批次，loss：0.05729256570339203，acc：0.96875\n",
      "训练时间：17629.055114507675\n",
      "第800个批次，loss：9.818865510169417e-05，acc：1.0\n",
      "整体验证集的acc：0.994038462638855\n",
      "第151轮训练\n",
      "训练时间：17638.571262598038\n",
      "第0个批次，loss：0.00013474878505803645，acc：1.0\n",
      "训练时间：17651.70724415779\n",
      "第100个批次，loss：0.0002726854872889817，acc：1.0\n",
      "训练时间：17664.85840153694\n",
      "第200个批次，loss：0.0017685608472675085，acc：1.0\n",
      "训练时间：17677.995665073395\n",
      "第300个批次，loss：0.001654503052122891，acc：1.0\n",
      "训练时间：17691.137631177902\n",
      "第400个批次，loss：0.0038653917144984007，acc：1.0\n",
      "训练时间：17704.285774946213\n",
      "第500个批次，loss：0.00022161391098052263，acc：1.0\n",
      "训练时间：17717.434839248657\n",
      "第600个批次，loss：0.0009509054943919182，acc：1.0\n",
      "训练时间：17730.57689356804\n",
      "第700个批次，loss：0.001249097753316164，acc：1.0\n",
      "训练时间：17743.709995031357\n",
      "第800个批次，loss：8.088877802947536e-05，acc：1.0\n",
      "整体验证集的acc：0.9938461780548096\n",
      "第152轮训练\n",
      "训练时间：17753.155129909515\n",
      "第0个批次，loss：0.0007267208420671523，acc：1.0\n",
      "训练时间：17766.29714488983\n",
      "第100个批次，loss：0.00029250147053971887，acc：1.0\n",
      "训练时间：17779.42111182213\n",
      "第200个批次，loss：0.0002017524093389511，acc：1.0\n",
      "训练时间：17792.548306703568\n",
      "第300个批次，loss：0.011157232336699963，acc：1.0\n",
      "训练时间：17805.689350366592\n",
      "第400个批次，loss：0.002485111355781555，acc：1.0\n",
      "训练时间：17818.823801994324\n",
      "第500个批次，loss：0.0011279784375801682，acc：1.0\n",
      "训练时间：17831.9723842144\n",
      "第600个批次，loss：0.00014911798643879592，acc：1.0\n",
      "训练时间：17845.10365819931\n",
      "第700个批次，loss：0.019717715680599213，acc：1.0\n",
      "训练时间：17858.24628186226\n",
      "第800个批次，loss：0.001840399345383048，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第153轮训练\n",
      "训练时间：17867.684501886368\n",
      "第0个批次，loss：0.00018998599261976779，acc：1.0\n",
      "训练时间：17880.83299279213\n",
      "第100个批次，loss：0.01979616843163967，acc：1.0\n",
      "训练时间：17893.966374397278\n",
      "第200个批次，loss：0.00026801935746334493，acc：1.0\n",
      "训练时间：17907.124794721603\n",
      "第300个批次，loss：0.0004687933251261711，acc：1.0\n",
      "训练时间：17920.28872013092\n",
      "第400个批次，loss：0.00043852903763763607，acc：1.0\n",
      "训练时间：17933.451330900192\n",
      "第500个批次，loss：0.0019984240643680096，acc：1.0\n",
      "训练时间：17946.601618528366\n",
      "第600个批次，loss：0.00462951697409153，acc：1.0\n",
      "训练时间：17959.73277616501\n",
      "第700个批次，loss：0.00038616207893937826，acc：1.0\n",
      "训练时间：17972.871087551117\n",
      "第800个批次，loss：0.000494933919981122，acc：1.0\n",
      "整体验证集的acc：0.9936538338661194\n",
      "第154轮训练\n",
      "训练时间：17982.29767036438\n",
      "第0个批次，loss：0.0006290831370279193，acc：1.0\n",
      "训练时间：17995.42564511299\n",
      "第100个批次，loss：0.029355982318520546，acc：0.96875\n",
      "训练时间：18008.566611528397\n",
      "第200个批次，loss：0.00012006433826172724，acc：1.0\n",
      "训练时间：18021.712252378464\n",
      "第300个批次，loss：0.031825952231884，acc：0.96875\n",
      "训练时间：18034.83471918106\n",
      "第400个批次，loss：0.003626508405432105，acc：1.0\n",
      "训练时间：18047.987686872482\n",
      "第500个批次，loss：0.00010745525651145726，acc：1.0\n",
      "训练时间：18061.133909463882\n",
      "第600个批次，loss：0.00011080292460974306，acc：1.0\n",
      "训练时间：18074.306905031204\n",
      "第700个批次，loss：0.0004617944359779358，acc：1.0\n",
      "训练时间：18087.45209813118\n",
      "第800个批次，loss：0.0016232139896601439，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第155轮训练\n",
      "训练时间：18096.92725968361\n",
      "第0个批次，loss：0.00019692441856022924，acc：1.0\n",
      "训练时间：18110.06419444084\n",
      "第100个批次，loss：0.0016147157875820994，acc：1.0\n",
      "训练时间：18123.203173160553\n",
      "第200个批次，loss：0.00041212348151020706，acc：1.0\n",
      "训练时间：18136.361951351166\n",
      "第300个批次，loss：0.0006880051805637777，acc：1.0\n",
      "训练时间：18149.504940748215\n",
      "第400个批次，loss：0.0035161306150257587，acc：1.0\n",
      "训练时间：18162.658403396606\n",
      "第500个批次，loss：0.00029027662822045386，acc：1.0\n",
      "训练时间：18175.80136203766\n",
      "第600个批次，loss：0.00025352108059450984，acc：1.0\n",
      "训练时间：18188.964128494263\n",
      "第700个批次，loss：0.015523881651461124，acc：1.0\n",
      "训练时间：18202.119160175323\n",
      "第800个批次，loss：0.0023842696100473404，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第156轮训练\n",
      "训练时间：18211.605211019516\n",
      "第0个批次，loss：0.06621870398521423，acc：0.96875\n",
      "训练时间：18224.74538755417\n",
      "第100个批次，loss：0.00022936654568184167，acc：1.0\n",
      "训练时间：18237.88395190239\n",
      "第200个批次，loss：0.0002027184673352167，acc：1.0\n",
      "训练时间：18251.036854982376\n",
      "第300个批次，loss：0.00010510695574339479，acc：1.0\n",
      "训练时间：18264.165113925934\n",
      "第400个批次，loss：0.0012641182402148843，acc：1.0\n",
      "训练时间：18277.30064892769\n",
      "第500个批次，loss：0.00024111909442581236，acc：1.0\n",
      "训练时间：18290.44884109497\n",
      "第600个批次，loss：0.0009157462045550346，acc：1.0\n",
      "训练时间：18303.632328510284\n",
      "第700个批次，loss：0.04544131085276604，acc：0.96875\n",
      "训练时间：18316.785619974136\n",
      "第800个批次，loss：0.003240992547944188，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第157轮训练\n",
      "训练时间：18326.19675064087\n",
      "第0个批次，loss：0.00016936985775828362，acc：1.0\n",
      "训练时间：18339.341656684875\n",
      "第100个批次，loss：0.0018295488553121686，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：18352.50179886818\n",
      "第200个批次，loss：0.017154833301901817，acc：1.0\n",
      "训练时间：18365.62776017189\n",
      "第300个批次，loss：0.0014187635388225317，acc：1.0\n",
      "训练时间：18378.772749185562\n",
      "第400个批次，loss：0.0005609437357634306，acc：1.0\n",
      "训练时间：18391.91073036194\n",
      "第500个批次，loss：0.03759109601378441，acc：1.0\n",
      "训练时间：18405.05770587921\n",
      "第600个批次，loss：0.0007884141523391008，acc：1.0\n",
      "训练时间：18418.19668507576\n",
      "第700个批次，loss：0.0007893941947259009，acc：1.0\n",
      "训练时间：18431.352437973022\n",
      "第800个批次，loss：0.06900621205568314，acc：0.96875\n",
      "整体验证集的acc：0.992307722568512\n",
      "第158轮训练\n",
      "训练时间：18440.81789803505\n",
      "第0个批次，loss：0.055018939077854156，acc：0.96875\n",
      "训练时间：18453.959799289703\n",
      "第100个批次，loss：0.0003382040886208415，acc：1.0\n",
      "训练时间：18467.116394519806\n",
      "第200个批次，loss：0.0030452487990260124，acc：1.0\n",
      "训练时间：18480.2757062912\n",
      "第300个批次，loss：8.210770465666428e-05，acc：1.0\n",
      "训练时间：18493.405142068863\n",
      "第400个批次，loss：0.026318293064832687，acc：1.0\n",
      "训练时间：18506.545117378235\n",
      "第500个批次，loss：0.0011767102405428886，acc：1.0\n",
      "训练时间：18519.679765939713\n",
      "第600个批次，loss：0.0004187079903203994，acc：1.0\n",
      "训练时间：18532.816739082336\n",
      "第700个批次，loss：0.00028426575590856373，acc：1.0\n",
      "训练时间：18545.973692655563\n",
      "第800个批次，loss：0.012660564854741096，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第159轮训练\n",
      "训练时间：18555.450834989548\n",
      "第0个批次，loss：0.0005825705593451858，acc：1.0\n",
      "训练时间：18568.584814071655\n",
      "第100个批次，loss：4.714345413958654e-05，acc：1.0\n",
      "训练时间：18581.721445322037\n",
      "第200个批次，loss：0.00024943173048086464，acc：1.0\n",
      "训练时间：18594.86852478981\n",
      "第300个批次，loss：0.0011199002619832754，acc：1.0\n",
      "训练时间：18608.006516218185\n",
      "第400个批次，loss：0.0002130859938915819，acc：1.0\n",
      "训练时间：18621.132454395294\n",
      "第500个批次，loss：0.0016556867631152272，acc：1.0\n",
      "训练时间：18634.25842523575\n",
      "第600个批次，loss：4.26588230766356e-05，acc：1.0\n",
      "训练时间：18647.383499622345\n",
      "第700个批次，loss：0.00014210984227247536，acc：1.0\n",
      "训练时间：18660.528465509415\n",
      "第800个批次，loss：0.00023721881734672934，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第160轮训练\n",
      "训练时间：18669.951979637146\n",
      "第0个批次，loss：0.00020475818018894643，acc：1.0\n",
      "训练时间：18683.080213308334\n",
      "第100个批次，loss：0.0014073901111260056，acc：1.0\n",
      "训练时间：18696.21918487549\n",
      "第200个批次，loss：0.0037396166007965803，acc：1.0\n",
      "训练时间：18709.347596406937\n",
      "第300个批次，loss：0.00046750737237744033，acc：1.0\n",
      "训练时间：18722.471554279327\n",
      "第400个批次，loss：0.0005624505574814975，acc：1.0\n",
      "训练时间：18735.601714611053\n",
      "第500个批次，loss：0.0006441707373596728，acc：1.0\n",
      "训练时间：18748.78555750847\n",
      "第600个批次，loss：0.00034867602516897023，acc：1.0\n",
      "训练时间：18761.965249300003\n",
      "第700个批次，loss：0.056862883269786835，acc：0.96875\n",
      "训练时间：18775.117225408554\n",
      "第800个批次，loss：0.001708430703729391，acc：1.0\n",
      "整体验证集的acc：0.9907692074775696\n",
      "第161轮训练\n",
      "训练时间：18784.603653669357\n",
      "第0个批次，loss：0.0011960703413933516，acc：1.0\n",
      "训练时间：18797.767446517944\n",
      "第100个批次，loss：0.002729431027546525，acc：1.0\n",
      "训练时间：18810.90689086914\n",
      "第200个批次，loss：0.0008358756313100457，acc：1.0\n",
      "训练时间：18824.04901075363\n",
      "第300个批次，loss：0.00032786824158392847，acc：1.0\n",
      "训练时间：18837.1769695282\n",
      "第400个批次，loss：0.06418335437774658，acc：0.9375\n",
      "训练时间：18850.30391573906\n",
      "第500个批次，loss：0.03821074217557907，acc：0.96875\n",
      "训练时间：18863.438885450363\n",
      "第600个批次，loss：0.00042751026921905577，acc：1.0\n",
      "训练时间：18876.572413921356\n",
      "第700个批次，loss：2.4909650164772756e-05，acc：1.0\n",
      "训练时间：18889.71475625038\n",
      "第800个批次，loss：0.00020181271247565746，acc：1.0\n",
      "整体验证集的acc：0.9936538338661194\n",
      "第162轮训练\n",
      "训练时间：18899.134880065918\n",
      "第0个批次，loss：1.2173955838079564e-05，acc：1.0\n",
      "训练时间：18913.289774417877\n",
      "第100个批次，loss：0.00019627760048024356，acc：1.0\n",
      "训练时间：18926.97688150406\n",
      "第200个批次，loss：0.003933727741241455，acc：1.0\n",
      "训练时间：18940.24902176857\n",
      "第300个批次，loss：0.0002481180417817086，acc：1.0\n",
      "训练时间：18953.517010211945\n",
      "第400个批次，loss：5.171303928364068e-05，acc：1.0\n",
      "训练时间：18966.770000219345\n",
      "第500个批次，loss：0.003895599627867341，acc：1.0\n",
      "训练时间：18979.95063662529\n",
      "第600个批次，loss：0.042602621018886566，acc：0.96875\n",
      "训练时间：18993.0985994339\n",
      "第700个批次，loss：0.00020877546921838075，acc：1.0\n",
      "训练时间：19006.234621047974\n",
      "第800个批次，loss：0.004005798604339361，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第163轮训练\n",
      "训练时间：19015.6587433815\n",
      "第0个批次，loss：0.00020113826030865312，acc：1.0\n",
      "训练时间：19028.85489463806\n",
      "第100个批次，loss：0.00039060774724930525，acc：1.0\n",
      "训练时间：19041.988787651062\n",
      "第200个批次，loss：0.008503285236656666，acc：1.0\n",
      "训练时间：19055.135754346848\n",
      "第300个批次，loss：0.005702085327357054，acc：1.0\n",
      "训练时间：19068.27666401863\n",
      "第400个批次，loss：0.0020310739055275917，acc：1.0\n",
      "训练时间：19081.41960000992\n",
      "第500个批次，loss：0.0005157062551006675，acc：1.0\n",
      "训练时间：19094.549565792084\n",
      "第600个批次，loss：0.0007748196367174387，acc：1.0\n",
      "训练时间：19107.70754146576\n",
      "第700个批次，loss：0.003832197282463312，acc：1.0\n",
      "训练时间：19120.864516735077\n",
      "第800个批次，loss：2.033119926636573e-05，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第164轮训练\n",
      "训练时间：19130.339661598206\n",
      "第0个批次，loss：0.0011943608988076448，acc：1.0\n",
      "训练时间：19143.483612298965\n",
      "第100个批次，loss：5.271212285151705e-05，acc：1.0\n",
      "训练时间：19156.649040699005\n",
      "第200个批次，loss：7.57128800614737e-05，acc：1.0\n",
      "训练时间：19169.797211170197\n",
      "第300个批次，loss：0.001066451659426093，acc：1.0\n",
      "训练时间：19182.951193332672\n",
      "第400个批次，loss：0.0005094550433568656，acc：1.0\n",
      "训练时间：19196.091171979904\n",
      "第500个批次，loss：0.0016883928328752518，acc：1.0\n",
      "训练时间：19209.233150959015\n",
      "第600个批次，loss：0.00048175183474086225，acc：1.0\n",
      "训练时间：19222.370269060135\n",
      "第700个批次，loss：0.0002106997708324343，acc：1.0\n",
      "训练时间：19235.49928164482\n",
      "第800个批次，loss：0.00632768590003252，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第165轮训练\n",
      "训练时间：19244.911408901215\n",
      "第0个批次，loss：0.0021418447140604258，acc：1.0\n",
      "训练时间：19258.038365840912\n",
      "第100个批次，loss：0.01368018239736557，acc：1.0\n",
      "训练时间：19271.2133538723\n",
      "第200个批次，loss：0.001181434141471982，acc：1.0\n",
      "训练时间：19284.35833311081\n",
      "第300个批次，loss：0.00036858153180219233，acc：1.0\n",
      "训练时间：19297.489920139313\n",
      "第400个批次，loss：0.0002677693555597216，acc：1.0\n",
      "训练时间：19310.64089012146\n",
      "第500个批次，loss：0.026407184079289436，acc：0.96875\n",
      "训练时间：19323.78519630432\n",
      "第600个批次，loss：0.0010614492930471897，acc：1.0\n",
      "训练时间：19336.924163341522\n",
      "第700个批次，loss：4.014070509583689e-05，acc：1.0\n",
      "训练时间：19350.084303617477\n",
      "第800个批次，loss：5.0393562560202554e-05，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第166轮训练\n",
      "训练时间：19359.571448087692\n",
      "第0个批次，loss：0.00022709571931045502，acc：1.0\n",
      "训练时间：19372.70022559166\n",
      "第100个批次，loss：0.0007302967133000493，acc：1.0\n",
      "训练时间：19385.861617565155\n",
      "第200个批次，loss：0.00030153675470501184，acc：1.0\n",
      "训练时间：19399.00105023384\n",
      "第300个批次，loss：0.0007694931700825691，acc：1.0\n",
      "训练时间：19412.127018928528\n",
      "第400个批次，loss：4.5102111471351236e-05，acc：1.0\n",
      "训练时间：19425.334007024765\n",
      "第500个批次，loss：0.0001619418617337942，acc：1.0\n",
      "训练时间：19438.718329906464\n",
      "第600个批次，loss：0.0037467300426214933，acc：1.0\n",
      "训练时间：19451.93474674225\n",
      "第700个批次，loss：0.0002336830657441169，acc：1.0\n",
      "训练时间：19465.05412173271\n",
      "第800个批次，loss：0.0015730391023680568，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第167轮训练\n",
      "训练时间：19474.552576065063\n",
      "第0个批次，loss：0.0022482979111373425，acc：1.0\n",
      "训练时间：19487.7035446167\n",
      "第100个批次，loss：0.000328114430885762，acc：1.0\n",
      "训练时间：19500.838536262512\n",
      "第200个批次，loss：0.004269030410796404，acc：1.0\n",
      "训练时间：19514.00151705742\n",
      "第300个批次，loss：0.0009149524848908186，acc：1.0\n",
      "训练时间：19527.163762807846\n",
      "第400个批次，loss：0.00010844175994861871，acc：1.0\n",
      "训练时间：19540.308777093887\n",
      "第500个批次，loss：0.000667465094011277，acc：1.0\n",
      "训练时间：19553.445733308792\n",
      "第600个批次，loss：0.003053424647077918，acc：1.0\n",
      "训练时间：19566.590702533722\n",
      "第700个批次，loss：0.0012832480715587735，acc：1.0\n",
      "训练时间：19579.76167201996\n",
      "第800个批次，loss：0.004436845891177654，acc：1.0\n",
      "整体验证集的acc：0.994038462638855\n",
      "第168轮训练\n",
      "训练时间：19589.237815380096\n",
      "第0个批次，loss：0.004341606050729752，acc：1.0\n",
      "训练时间：19602.372792243958\n",
      "第100个批次，loss：0.00015846994938328862，acc：1.0\n",
      "训练时间：19615.513018846512\n",
      "第200个批次，loss：0.0006324711139313877，acc：1.0\n",
      "训练时间：19628.679327249527\n",
      "第300个批次，loss：9.591510752215981e-05，acc：1.0\n",
      "训练时间：19641.807299137115\n",
      "第400个批次，loss：0.0018279037903994322，acc：1.0\n",
      "训练时间：19654.953267097473\n",
      "第500个批次，loss：0.02931031584739685，acc：0.96875\n",
      "训练时间：19668.088270664215\n",
      "第600个批次，loss：0.0014090926852077246，acc：1.0\n",
      "训练时间：19681.218240261078\n",
      "第700个批次，loss：0.001471764757297933，acc：1.0\n",
      "训练时间：19694.46823000908\n",
      "第800个批次，loss：0.0022889093961566687，acc：1.0\n",
      "整体验证集的acc：0.9930769205093384\n",
      "第169轮训练\n",
      "训练时间：19704.054398298264\n",
      "第0个批次，loss：0.0004456403257790953，acc：1.0\n",
      "训练时间：19717.306229114532\n",
      "第100个批次，loss：0.0009034986142069101，acc：1.0\n",
      "训练时间：19730.623219013214\n",
      "第200个批次，loss：0.00017260244931094348，acc：1.0\n",
      "训练时间：19743.768182516098\n",
      "第300个批次，loss：0.00036088094930164516，acc：1.0\n",
      "训练时间：19756.908514738083\n",
      "第400个批次，loss：0.016296103596687317，acc：1.0\n",
      "训练时间：19770.05193209648\n",
      "第500个批次，loss：0.007971532642841339，acc：1.0\n",
      "训练时间：19783.196125030518\n",
      "第600个批次，loss：0.0003997105231974274，acc：1.0\n",
      "训练时间：19796.337654352188\n",
      "第700个批次，loss：0.00039101566653698683，acc：1.0\n",
      "训练时间：19809.475125074387\n",
      "第800个批次，loss：0.0009570039692334831，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第170轮训练\n",
      "训练时间：19818.906217336655\n",
      "第0个批次，loss：0.00027946566115133464，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：19832.036425352097\n",
      "第100个批次，loss：9.895254333969206e-05，acc：1.0\n",
      "训练时间：19845.159730672836\n",
      "第200个批次，loss：0.005328567232936621，acc：1.0\n",
      "训练时间：19858.290125131607\n",
      "第300个批次，loss：0.02656685747206211，acc：1.0\n",
      "训练时间：19871.452281475067\n",
      "第400个批次，loss：0.000996389309875667，acc：1.0\n",
      "训练时间：19884.59124827385\n",
      "第500个批次，loss：9.639403288019821e-05，acc：1.0\n",
      "训练时间：19897.72544836998\n",
      "第600个批次，loss：0.00047378632007166743，acc：1.0\n",
      "训练时间：19910.853411912918\n",
      "第700个批次，loss：0.02342183329164982，acc：1.0\n",
      "训练时间：19924.001371622086\n",
      "第800个批次，loss：0.001556125353090465，acc：1.0\n",
      "整体验证集的acc：0.9942307472229004\n",
      "第171轮训练\n",
      "训练时间：19933.479511260986\n",
      "第0个批次，loss：0.015283457934856415，acc：1.0\n",
      "训练时间：19946.621816158295\n",
      "第100个批次，loss：0.00010456156451255083，acc：1.0\n",
      "训练时间：19959.757235765457\n",
      "第200个批次，loss：0.08496637642383575，acc：0.9375\n",
      "训练时间：19973.18875002861\n",
      "第300个批次，loss：0.0026999993715435266，acc：1.0\n",
      "训练时间：19986.361719608307\n",
      "第400个批次，loss：0.0005270112305879593，acc：1.0\n",
      "训练时间：19999.496744394302\n",
      "第500个批次，loss：0.01910848543047905，acc：1.0\n",
      "训练时间：20012.642793655396\n",
      "第600个批次，loss：0.0016628121957182884，acc：1.0\n",
      "训练时间：20025.774755477905\n",
      "第700个批次，loss：0.00025250131147913635，acc：1.0\n",
      "训练时间：20038.911621809006\n",
      "第800个批次，loss：2.861599568859674e-05，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第172轮训练\n",
      "训练时间：20048.31574821472\n",
      "第0个批次，loss：0.00018776115030050278，acc：1.0\n",
      "训练时间：20061.446709394455\n",
      "第100个批次，loss：0.02193659357726574，acc：1.0\n",
      "训练时间：20074.59967160225\n",
      "第200个批次，loss：0.005355396773666143，acc：1.0\n",
      "训练时间：20087.726634979248\n",
      "第300个批次，loss：0.0002999439893756062，acc：1.0\n",
      "训练时间：20100.883603572845\n",
      "第400个批次，loss：0.004457559436559677，acc：1.0\n",
      "训练时间：20114.036584854126\n",
      "第500个批次，loss：0.0011540876002982259，acc：1.0\n",
      "训练时间：20127.17187643051\n",
      "第600个批次，loss：0.0013932075817137957，acc：1.0\n",
      "训练时间：20140.31611275673\n",
      "第700个批次，loss：0.0059576742351055145，acc：1.0\n",
      "训练时间：20153.44607758522\n",
      "第800个批次，loss：0.0003309096209704876，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第173轮训练\n",
      "训练时间：20162.879272699356\n",
      "第0个批次，loss：0.00020574349036905915，acc：1.0\n",
      "训练时间：20176.032850265503\n",
      "第100个批次，loss：0.0068132211454212666，acc：1.0\n",
      "训练时间：20189.17581677437\n",
      "第200个批次，loss：0.0022776718251407146，acc：1.0\n",
      "训练时间：20202.412063598633\n",
      "第300个批次，loss：0.0017531091580167413，acc：1.0\n",
      "训练时间：20215.60904288292\n",
      "第400个批次，loss：0.00051590969087556，acc：1.0\n",
      "训练时间：20228.764013051987\n",
      "第500个批次，loss：0.00012520178279373795，acc：1.0\n",
      "训练时间：20242.077028036118\n",
      "第600个批次，loss：0.00211042957380414，acc：1.0\n",
      "训练时间：20255.294795274734\n",
      "第700个批次，loss：0.0017199587309733033，acc：1.0\n",
      "训练时间：20268.87098646164\n",
      "第800个批次，loss：0.00010384383494965732，acc：1.0\n",
      "整体验证集的acc：0.992307722568512\n",
      "第174轮训练\n",
      "训练时间：20278.368540525436\n",
      "第0个批次，loss：0.07223043590784073，acc：0.96875\n",
      "训练时间：20291.588529109955\n",
      "第100个批次，loss：8.189566869987175e-05，acc：1.0\n",
      "训练时间：20304.78767681122\n",
      "第200个批次，loss：0.00044334764243103564，acc：1.0\n",
      "训练时间：20317.98566222191\n",
      "第300个批次，loss：0.00011644157348200679，acc：1.0\n",
      "训练时间：20331.173636198044\n",
      "第400个批次，loss：0.005625398363918066，acc：1.0\n",
      "训练时间：20344.381618499756\n",
      "第500个批次，loss：0.0001930442958837375，acc：1.0\n",
      "训练时间：20357.60159921646\n",
      "第600个批次，loss：0.0007877874886617064，acc：1.0\n",
      "训练时间：20370.811589717865\n",
      "第700个批次，loss：0.001479764119721949，acc：1.0\n",
      "训练时间：20384.016576051712\n",
      "第800个批次，loss：0.0013949382118880749，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第175轮训练\n",
      "训练时间：20393.500713825226\n",
      "第0个批次，loss：0.0006822560681030154，acc：1.0\n",
      "训练时间：20406.762710094452\n",
      "第100个批次，loss：0.00023101616534404457，acc：1.0\n",
      "训练时间：20419.977701425552\n",
      "第200个批次，loss：0.00010929034760920331，acc：1.0\n",
      "训练时间：20433.177712917328\n",
      "第300个批次，loss：0.00020800076890736818，acc：1.0\n",
      "训练时间：20446.3769197464\n",
      "第400个批次，loss：0.0009313452173955739，acc：1.0\n",
      "训练时间：20459.595908164978\n",
      "第500个批次，loss：0.07389390468597412，acc：0.96875\n",
      "训练时间：20472.824916362762\n",
      "第600个批次，loss：0.00010658654355211183，acc：1.0\n",
      "训练时间：20486.02389907837\n",
      "第700个批次，loss：0.006302425637841225，acc：1.0\n",
      "训练时间：20499.22937655449\n",
      "第800个批次，loss：0.0031161659862846136，acc：1.0\n",
      "整体验证集的acc：0.9921153783798218\n",
      "第176轮训练\n",
      "训练时间：20508.71851658821\n",
      "第0个批次，loss：0.00017761456547304988，acc：1.0\n",
      "训练时间：20521.931504249573\n",
      "第100个批次，loss：0.00057936308439821，acc：1.0\n",
      "训练时间：20535.13248872757\n",
      "第200个批次，loss：3.24733518937137e-05，acc：1.0\n",
      "训练时间：20548.34046936035\n",
      "第300个批次，loss：0.0013642188860103488，acc：1.0\n",
      "训练时间：20561.5592648983\n",
      "第400个批次，loss：0.0007308979402296245，acc：1.0\n",
      "训练时间：20574.76124715805\n",
      "第500个批次，loss：0.015439924784004688，acc：1.0\n",
      "训练时间：20587.9916908741\n",
      "第600个批次，loss：5.419564695330337e-05，acc：1.0\n",
      "训练时间：20601.20868396759\n",
      "第700个批次，loss：0.0011860072845593095，acc：1.0\n",
      "训练时间：20614.424667596817\n",
      "第800个批次，loss：0.00013309145288076252，acc：1.0\n",
      "整体验证集的acc：0.9907692074775696\n",
      "第177轮训练\n",
      "训练时间：20623.87880039215\n",
      "第0个批次，loss：0.0015581261832267046，acc：1.0\n",
      "训练时间：20637.065250635147\n",
      "第100个批次，loss：0.002172052161768079，acc：1.0\n",
      "训练时间：20650.27823114395\n",
      "第200个批次，loss：0.00029098839149810374，acc：1.0\n",
      "训练时间：20663.4721429348\n",
      "第300个批次，loss：0.003932643681764603，acc：1.0\n",
      "训练时间：20676.667136907578\n",
      "第400个批次，loss：0.020097296684980392，acc：1.0\n",
      "训练时间：20689.86411857605\n",
      "第500个批次，loss：0.00024180379114113748，acc：1.0\n",
      "训练时间：20703.08222913742\n",
      "第600个批次，loss：0.0001955421466846019，acc：1.0\n",
      "训练时间：20716.2922976017\n",
      "第700个批次，loss：0.0002225144999101758，acc：1.0\n",
      "训练时间：20729.49466943741\n",
      "第800个批次，loss：6.825818854849786e-05，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第178轮训练\n",
      "训练时间：20738.984822511673\n",
      "第0个批次，loss：0.00029797101160511374，acc：1.0\n",
      "训练时间：20752.16580271721\n",
      "第100个批次，loss：0.0010801447788253427，acc：1.0\n",
      "训练时间：20765.357794761658\n",
      "第200个批次，loss：5.649991726386361e-05，acc：1.0\n",
      "训练时间：20778.561777591705\n",
      "第300个批次，loss：0.00019503990188241005，acc：1.0\n",
      "训练时间：20791.745744228363\n",
      "第400个批次，loss：0.0003359890542924404，acc：1.0\n",
      "训练时间：20804.937730312347\n",
      "第500个批次，loss：0.0003065768105443567，acc：1.0\n",
      "训练时间：20818.13670516014\n",
      "第600个批次，loss：0.0016637451481074095，acc：1.0\n",
      "训练时间：20831.358847379684\n",
      "第700个批次，loss：0.00024057454720605165，acc：1.0\n",
      "训练时间：20844.559828042984\n",
      "第800个批次，loss：0.0004172675544396043，acc：1.0\n",
      "整体验证集的acc：0.9930769205093384\n",
      "第179轮训练\n",
      "训练时间：20854.079491853714\n",
      "第0个批次，loss：0.0012264869874343276，acc：1.0\n",
      "训练时间：20867.29791045189\n",
      "第100个批次，loss：0.0030040848068892956，acc：1.0\n",
      "训练时间：20880.476895809174\n",
      "第200个批次，loss：0.008741124533116817，acc：1.0\n",
      "训练时间：20893.673874378204\n",
      "第300个批次，loss：0.00013846922956872731，acc：1.0\n",
      "训练时间：20906.859848499298\n",
      "第400个批次，loss：0.17537438869476318，acc：0.96875\n",
      "训练时间：20920.051276683807\n",
      "第500个批次，loss：0.0003083570336457342，acc：1.0\n",
      "训练时间：20933.24026989937\n",
      "第600个批次，loss：0.0008240613387897611，acc：1.0\n",
      "训练时间：20946.434243440628\n",
      "第700个批次，loss：0.0010872881393879652，acc：1.0\n",
      "训练时间：20959.62434911728\n",
      "第800个批次，loss：0.00019779395370278507，acc：1.0\n",
      "整体验证集的acc：0.9932692050933838\n",
      "第180轮训练\n",
      "训练时间：20969.10348701477\n",
      "第0个批次，loss：0.0002100776182487607，acc：1.0\n",
      "训练时间：20982.29447364807\n",
      "第100个批次，loss：0.00016738598060328513，acc：1.0\n",
      "训练时间：20995.483449697495\n",
      "第200个批次，loss：0.0021487337071448565，acc：1.0\n",
      "训练时间：21008.70542883873\n",
      "第300个批次，loss：0.00016001089534256607，acc：1.0\n",
      "训练时间：21021.88951730728\n",
      "第400个批次，loss：0.0009968652157112956，acc：1.0\n",
      "训练时间：21035.092496156693\n",
      "第500个批次，loss：3.437383202253841e-05，acc：1.0\n",
      "训练时间：21048.28248000145\n",
      "第600个批次，loss：0.0011451783357188106，acc：1.0\n",
      "训练时间：21061.49390935898\n",
      "第700个批次，loss：0.0006748169544152915，acc：1.0\n",
      "训练时间：21074.6960773468\n",
      "第800个批次，loss：0.00036776572233065963，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第181轮训练\n",
      "训练时间：21084.20822739601\n",
      "第0个批次，loss：0.0002391764137428254，acc：1.0\n",
      "训练时间：21097.411234140396\n",
      "第100个批次，loss：0.003814168507233262，acc：1.0\n",
      "训练时间：21110.61416053772\n",
      "第200个批次，loss：0.0010203601559624076，acc：1.0\n",
      "训练时间：21123.81330728531\n",
      "第300个批次，loss：0.00024778436636552215，acc：1.0\n",
      "训练时间：21137.009278297424\n",
      "第400个批次，loss：0.00014870561426505446，acc：1.0\n",
      "训练时间：21150.199382781982\n",
      "第500个批次，loss：0.003328148275613785，acc：1.0\n",
      "训练时间：21163.397636413574\n",
      "第600个批次，loss：0.0008693890413269401，acc：1.0\n",
      "训练时间：21176.60560774803\n",
      "第700个批次，loss：0.0035155199002474546，acc：1.0\n",
      "训练时间：21189.80559515953\n",
      "第800个批次，loss：4.2821557144634426e-05，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第182轮训练\n",
      "训练时间：21199.27073073387\n",
      "第0个批次，loss：0.00300052622333169，acc：1.0\n",
      "训练时间：21212.47857761383\n",
      "第100个批次，loss：0.0010250259656459093，acc：1.0\n",
      "训练时间：21225.68785881996\n",
      "第200个批次，loss：0.0009522978216409683，acc：1.0\n",
      "训练时间：21238.88785624504\n",
      "第300个批次，loss：6.018899875925854e-05，acc：1.0\n",
      "训练时间：21252.07483291626\n",
      "第400个批次，loss：0.001496348064392805，acc：1.0\n",
      "训练时间：21265.27472281456\n",
      "第500个批次，loss：0.004699822049587965，acc：1.0\n",
      "训练时间：21278.48571395874\n",
      "第600个批次，loss：0.005143676418811083，acc：1.0\n",
      "训练时间：21291.698704957962\n",
      "第700个批次，loss：0.00032448835554532707，acc：1.0\n",
      "训练时间：21304.92909526825\n",
      "第800个批次，loss：0.0003934752894565463，acc：1.0\n",
      "整体验证集的acc：0.9942307472229004\n",
      "第183轮训练\n",
      "训练时间：21314.39023399353\n",
      "第0个批次，loss：0.0029314651619642973，acc：1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：21327.593539714813\n",
      "第100个批次，loss：9.860376303549856e-05，acc：1.0\n",
      "训练时间：21340.863539218903\n",
      "第200个批次，loss：0.011435598134994507，acc：1.0\n",
      "训练时间：21354.191805124283\n",
      "第300个批次，loss：0.0014592281077057123，acc：1.0\n",
      "训练时间：21367.354773283005\n",
      "第400个批次，loss：0.00021565727365668863，acc：1.0\n",
      "训练时间：21380.510548830032\n",
      "第500个批次，loss：0.00510879373177886，acc：1.0\n",
      "训练时间：21393.68653154373\n",
      "第600个批次，loss：0.0013842424377799034，acc：1.0\n",
      "训练时间：21406.833424568176\n",
      "第700个批次，loss：0.001956529449671507，acc：1.0\n",
      "训练时间：21419.989394187927\n",
      "第800个批次，loss：0.00012516812421381474，acc：1.0\n",
      "整体验证集的acc：0.993461549282074\n",
      "第184轮训练\n",
      "训练时间：21429.426526784897\n",
      "第0个批次，loss：0.00482798321172595，acc：1.0\n",
      "训练时间：21442.574507713318\n",
      "第100个批次，loss：0.0005316248279996216，acc：1.0\n",
      "训练时间：21455.80149126053\n",
      "第200个批次，loss：0.0026968338061124086，acc：1.0\n",
      "训练时间：21469.210525989532\n",
      "第300个批次，loss：0.007643722463399172，acc：1.0\n",
      "训练时间：21482.419506072998\n",
      "第400个批次，loss：0.00015583554340992123，acc：1.0\n",
      "训练时间：21495.624722003937\n",
      "第500个批次，loss：0.00015220521891023964，acc：1.0\n",
      "训练时间：21508.827107667923\n",
      "第600个批次，loss：0.00119002815335989，acc：1.0\n",
      "训练时间：21522.02355837822\n",
      "第700个批次，loss：0.000358130841050297，acc：1.0\n",
      "训练时间：21535.225179195404\n",
      "第800个批次，loss：0.0001554290356580168，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第185轮训练\n",
      "训练时间：21544.733328342438\n",
      "第0个批次，loss：0.03516291454434395，acc：0.96875\n",
      "训练时间：21557.92330813408\n",
      "第100个批次，loss：0.0030929972417652607，acc：1.0\n",
      "训练时间：21571.12539935112\n",
      "第200个批次，loss：0.0009732640464790165，acc：1.0\n",
      "训练时间：21584.326597452164\n",
      "第300个批次，loss：0.00021420848497655243，acc：1.0\n",
      "训练时间：21597.518571853638\n",
      "第400个批次，loss：0.00017843188834376633，acc：1.0\n",
      "训练时间：21610.713670253754\n",
      "第500个批次，loss：0.0001818635209929198，acc：1.0\n",
      "训练时间：21623.900914669037\n",
      "第600个批次，loss：0.0010233642533421516，acc：1.0\n",
      "训练时间：21637.09489250183\n",
      "第700个批次，loss：0.028139153495430946，acc：1.0\n",
      "训练时间：21650.281876564026\n",
      "第800个批次，loss：0.001303885132074356，acc：1.0\n",
      "整体验证集的acc：0.9926922917366028\n",
      "第186轮训练\n",
      "训练时间：21659.73500776291\n",
      "第0个批次，loss：0.00015908479690551758，acc：1.0\n",
      "训练时间：21672.942982196808\n",
      "第100个批次，loss：7.059002382447943e-05，acc：1.0\n",
      "训练时间：21686.129955291748\n",
      "第200个批次，loss：0.0027369866147637367，acc：1.0\n",
      "训练时间：21699.31337618828\n",
      "第300个批次，loss：0.0126767223700881，acc：1.0\n",
      "训练时间：21712.502360105515\n",
      "第400个批次，loss：0.0005278387106955051，acc：1.0\n",
      "训练时间：21725.68773150444\n",
      "第500个批次，loss：0.0009979123715311289，acc：1.0\n",
      "训练时间：21738.869704008102\n",
      "第600个批次，loss：6.0352707805577666e-05，acc：1.0\n",
      "训练时间：21752.055683612823\n",
      "第700个批次，loss：0.038311731070280075，acc：0.96875\n",
      "训练时间：21765.240662574768\n",
      "第800个批次，loss：0.0006922194734215736，acc：1.0\n",
      "整体验证集的acc：0.9913461804389954\n",
      "第187轮训练\n",
      "训练时间：21774.710798978806\n",
      "第0个批次，loss：0.001773645170032978，acc：1.0\n",
      "训练时间：21787.919788599014\n",
      "第100个批次，loss：0.0003825573658104986，acc：1.0\n",
      "训练时间：21801.10276579857\n",
      "第200个批次，loss：0.0003611080173868686，acc：1.0\n",
      "训练时间：21814.27904176712\n",
      "第300个批次，loss：0.00013846297224517912，acc：1.0\n",
      "训练时间：21827.466027736664\n",
      "第400个批次，loss：0.00010766705236164853，acc：1.0\n",
      "训练时间：21840.648995876312\n",
      "第500个批次，loss：0.00041838682955130935，acc：1.0\n",
      "训练时间：21853.840237379074\n",
      "第600个批次，loss：0.00043407196062617004，acc：1.0\n",
      "训练时间：21867.03222322464\n",
      "第700个批次，loss：0.0006913468241691589，acc：1.0\n",
      "训练时间：21880.22012114525\n",
      "第800个批次，loss：0.0004755115369334817，acc：1.0\n",
      "整体验证集的acc：0.9925000071525574\n",
      "第188轮训练\n",
      "训练时间：21889.6732506752\n",
      "第0个批次，loss：7.011035631876439e-05，acc：1.0\n",
      "训练时间：21902.883235931396\n",
      "第100个批次，loss：0.009725354611873627，acc：1.0\n",
      "训练时间：21916.093218803406\n",
      "第200个批次，loss：0.0018848406616598368，acc：1.0\n",
      "训练时间：21929.28559422493\n",
      "第300个批次，loss：0.0022133756428956985，acc：1.0\n",
      "训练时间：21942.472590446472\n",
      "第400个批次，loss：0.003984866198152304，acc：1.0\n",
      "训练时间：21955.653571605682\n",
      "第500个批次，loss：0.0004994663177058101，acc：1.0\n",
      "训练时间：21968.836708545685\n",
      "第600个批次，loss：0.00021132615802343935，acc：1.0\n",
      "训练时间：21982.01806664467\n",
      "第700个批次，loss：0.04839269071817398，acc：0.96875\n",
      "训练时间：21995.19704079628\n",
      "第800个批次，loss：0.07416123896837234，acc：0.96875\n",
      "整体验证集的acc：0.992307722568512\n",
      "第189轮训练\n",
      "训练时间：22004.64017534256\n",
      "第0个批次，loss：0.00018424383597448468，acc：1.0\n",
      "训练时间：22017.8202149868\n",
      "第100个批次，loss：7.800854655215517e-05，acc：1.0\n",
      "训练时间：22031.02119421959\n",
      "第200个批次，loss：0.00015979215095285326，acc：1.0\n",
      "训练时间：22044.213171720505\n",
      "第300个批次，loss：0.04288843274116516，acc：0.96875\n",
      "训练时间：22057.398743867874\n",
      "第400个批次，loss：0.00024971377570182085，acc：1.0\n",
      "训练时间：22070.589718818665\n",
      "第500个批次，loss：0.0006114270072430372，acc：1.0\n",
      "训练时间：22083.789932012558\n",
      "第600个批次，loss：0.003206606488674879，acc：1.0\n",
      "训练时间：22096.991911649704\n",
      "第700个批次，loss：0.0017816420877352357，acc：1.0\n",
      "训练时间：22110.179383039474\n",
      "第800个批次，loss：0.00017700187163427472，acc：1.0\n",
      "整体验证集的acc：0.993461549282074\n",
      "第190轮训练\n",
      "训练时间：22119.65452504158\n",
      "第0个批次，loss：0.001742344698868692，acc：1.0\n",
      "训练时间：22132.850457429886\n",
      "第100个批次，loss：0.008877061307430267，acc：1.0\n",
      "训练时间：22146.047435998917\n",
      "第200个批次，loss：0.011666318401694298，acc：1.0\n",
      "训练时间：22159.253581047058\n",
      "第300个批次，loss：0.0510920025408268，acc：0.96875\n",
      "训练时间：22172.44752597809\n",
      "第400个批次，loss：0.00029749752138741314，acc：1.0\n",
      "训练时间：22185.651600837708\n",
      "第500个批次，loss：0.0001760954619385302，acc：1.0\n",
      "训练时间：22198.845984220505\n",
      "第600个批次，loss：0.00029049807926639915，acc：1.0\n",
      "训练时间：22212.031088352203\n",
      "第700个批次，loss：0.00039688177639618516，acc：1.0\n",
      "训练时间：22225.233078718185\n",
      "第800个批次，loss：0.0013324290048331022，acc：1.0\n",
      "整体验证集的acc：0.9938461780548096\n",
      "第191轮训练\n",
      "训练时间：22234.768242836\n",
      "第0个批次，loss：0.002997985342517495，acc：1.0\n",
      "训练时间：22247.950543165207\n",
      "第100个批次，loss：0.000569189025554806，acc：1.0\n",
      "训练时间：22261.151870012283\n",
      "第200个批次，loss：0.00012052516831317917，acc：1.0\n",
      "训练时间：22274.3868598938\n",
      "第300个批次，loss：0.0010750009678304195，acc：1.0\n",
      "训练时间：22287.568840026855\n",
      "第400个批次，loss：0.0005896177608519793，acc：1.0\n",
      "训练时间：22300.762812137604\n",
      "第500个批次，loss：0.00041380926268175244，acc：1.0\n",
      "训练时间：22313.953786611557\n",
      "第600个批次，loss：0.0008322993526235223，acc：1.0\n",
      "训练时间：22327.155767917633\n",
      "第700个批次，loss：0.0001337478606728837，acc：1.0\n",
      "训练时间：22340.383149385452\n",
      "第800个批次，loss：0.0004229142505209893，acc：1.0\n",
      "整体验证集的acc：0.9921153783798218\n",
      "第192轮训练\n",
      "训练时间：22349.901293039322\n",
      "第0个批次，loss：0.007126428186893463，acc：1.0\n",
      "训练时间：22363.101277828217\n",
      "第100个批次，loss：0.0372343584895134，acc：0.96875\n",
      "训练时间：22376.294263362885\n",
      "第200个批次，loss：0.0012451962102204561，acc：1.0\n",
      "训练时间：22389.506230592728\n",
      "第300个批次，loss：0.00011343895312165841，acc：1.0\n",
      "训练时间：22402.72313761711\n",
      "第400个批次，loss：0.00018251559231430292，acc：1.0\n",
      "训练时间：22415.914136648178\n",
      "第500个批次，loss：0.019221631810069084，acc：1.0\n",
      "训练时间：22429.118123054504\n",
      "第600个批次，loss：0.011138321831822395，acc：1.0\n",
      "训练时间：22442.323160886765\n",
      "第700个批次，loss：0.001230671419762075，acc：1.0\n",
      "训练时间：22455.524146795273\n",
      "第800个批次，loss：0.0003231349401175976，acc：1.0\n",
      "整体验证集的acc：0.9930769205093384\n",
      "第193轮训练\n",
      "训练时间：22465.008288621902\n",
      "第0个批次，loss：0.000545886461623013，acc：1.0\n",
      "训练时间：22478.229279756546\n",
      "第100个批次，loss：0.0009447140619158745，acc：1.0\n",
      "训练时间：22491.4404797554\n",
      "第200个批次，loss：0.019772300496697426，acc：1.0\n",
      "训练时间：22504.65069079399\n",
      "第300个批次，loss：0.00010867853416129947，acc：1.0\n",
      "训练时间：22517.865225553513\n",
      "第400个批次，loss：0.00012837279064115137，acc：1.0\n",
      "训练时间：22531.13179039955\n",
      "第500个批次，loss：0.012728850357234478，acc：1.0\n",
      "训练时间：22544.355142116547\n",
      "第600个批次，loss：0.003453404875472188，acc：1.0\n",
      "训练时间：22557.558121442795\n",
      "第700个批次，loss：0.00016565022815484554，acc：1.0\n",
      "训练时间：22570.76611018181\n",
      "第800个批次，loss：0.0003506717912387103，acc：1.0\n",
      "整体验证集的acc：0.993461549282074\n",
      "第194轮训练\n",
      "训练时间：22580.25325846672\n",
      "第0个批次，loss：0.01597597263753414，acc：1.0\n",
      "训练时间：22593.4282476902\n",
      "第100个批次，loss：0.0002265099756186828，acc：1.0\n",
      "训练时间：22606.627444028854\n",
      "第200个批次，loss：0.0005887642037123442，acc：1.0\n",
      "训练时间：22619.817425251007\n",
      "第300个批次，loss：0.00096983986441046，acc：1.0\n",
      "训练时间：22633.036418914795\n",
      "第400个批次，loss：0.00018785803695209324，acc：1.0\n",
      "训练时间：22646.234359264374\n",
      "第500个批次，loss：0.00038287442293949425，acc：1.0\n",
      "训练时间：22659.42131614685\n",
      "第600个批次，loss：0.0025744072627276182，acc：1.0\n",
      "训练时间：22672.606298923492\n",
      "第700个批次，loss：0.0016583489486947656，acc：1.0\n",
      "训练时间：22685.803312778473\n",
      "第800个批次，loss：0.0005006970022805035，acc：1.0\n",
      "整体验证集的acc：0.9913461804389954\n",
      "第195轮训练\n",
      "训练时间：22695.278827905655\n",
      "第0个批次，loss：0.00026150321355089545，acc：1.0\n",
      "训练时间：22708.615312576294\n",
      "第100个批次，loss：0.003055314999073744，acc：1.0\n",
      "训练时间：22722.012360334396\n",
      "第200个批次，loss：0.00026229838840663433，acc：1.0\n",
      "训练时间：22735.338366031647\n",
      "第300个批次，loss：0.00039178243605419993，acc：1.0\n",
      "训练时间：22748.618362665176\n",
      "第400个批次，loss：0.00059683428844437，acc：1.0\n",
      "训练时间：22761.803634166718\n",
      "第500个批次，loss：0.0022420294117182493，acc：1.0\n",
      "训练时间：22774.9726126194\n",
      "第600个批次，loss：0.0001391043042531237，acc：1.0\n",
      "训练时间：22788.1595993042\n",
      "第700个批次，loss：0.00011596090189414099，acc：1.0\n",
      "训练时间：22801.35054254532\n",
      "第800个批次，loss：0.010756364092230797，acc：1.0\n",
      "整体验证集的acc：0.9930769205093384\n",
      "第196轮训练\n",
      "训练时间：22810.85368657112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个批次，loss：0.00041266149492003024，acc：1.0\n",
      "训练时间：22824.038870573044\n",
      "第100个批次，loss：0.00940394401550293，acc：1.0\n",
      "训练时间：22837.223345518112\n",
      "第200个批次，loss：0.04245109111070633，acc：0.96875\n",
      "训练时间：22850.405335187912\n",
      "第300个批次，loss：0.13715897500514984，acc：0.96875\n",
      "训练时间：22863.592308998108\n",
      "第400个批次，loss：7.667791214771569e-05，acc：1.0\n",
      "训练时间：22876.790300369263\n",
      "第500个批次，loss：6.856684194644913e-05，acc：1.0\n",
      "训练时间：22889.967304229736\n",
      "第600个批次，loss：7.092210580594838e-05，acc：1.0\n",
      "训练时间：22903.148280382156\n",
      "第700个批次，loss：0.00012423653970472515，acc：1.0\n",
      "训练时间：22916.352523088455\n",
      "第800个批次，loss：0.0002326188114238903，acc：1.0\n",
      "整体验证集的acc：0.992884635925293\n",
      "第197轮训练\n",
      "训练时间：22925.81264925003\n",
      "第0个批次，loss：0.0011425166158005595，acc：1.0\n",
      "训练时间：22938.993630170822\n",
      "第100个批次，loss：0.00039514951640740037，acc：1.0\n",
      "训练时间：22952.203615665436\n",
      "第200个批次，loss：0.0004408158711157739，acc：1.0\n",
      "训练时间：22965.5679769516\n",
      "第300个批次，loss：0.0003268510045018047，acc：1.0\n",
      "训练时间：22978.785469532013\n",
      "第400个批次，loss：0.0002593734534457326，acc：1.0\n",
      "训练时间：22992.000494480133\n",
      "第500个批次，loss：0.0005600185832008719，acc：1.0\n",
      "训练时间：23005.207434415817\n",
      "第600个批次，loss：0.0004620600666385144，acc：1.0\n",
      "训练时间：23018.393409013748\n",
      "第700个批次，loss：0.006267586722970009，acc：1.0\n",
      "训练时间：23031.588653326035\n",
      "第800个批次，loss：0.05023643746972084，acc：0.96875\n",
      "整体验证集的acc：0.9938461780548096\n",
      "第198轮训练\n",
      "训练时间：23041.07579755783\n",
      "第0个批次，loss：0.0027688019908964634，acc：1.0\n",
      "训练时间：23054.265773773193\n",
      "第100个批次，loss：0.0003904233162757009，acc：1.0\n",
      "训练时间：23067.467716693878\n",
      "第200个批次，loss：0.0008466691942885518，acc：1.0\n",
      "训练时间：23080.6506857872\n",
      "第300个批次，loss：0.00011265699868090451，acc：1.0\n",
      "训练时间：23093.83371567726\n",
      "第400个批次，loss：0.028225330635905266，acc：0.96875\n",
      "训练时间：23107.041699647903\n",
      "第500个批次，loss：8.028457523323596e-05，acc：1.0\n",
      "训练时间：23120.23967909813\n",
      "第600个批次，loss：0.0002706614322960377，acc：1.0\n",
      "训练时间：23133.423691034317\n",
      "第700个批次，loss：0.0005905912257730961，acc：1.0\n",
      "训练时间：23146.79171895981\n",
      "第800个批次，loss：0.0006488357321359217，acc：1.0\n",
      "整体验证集的acc：0.9917307496070862\n",
      "第199轮训练\n",
      "训练时间：23156.321862220764\n",
      "第0个批次，loss：0.0038689749781042337，acc：1.0\n",
      "训练时间：23169.5488448143\n",
      "第100个批次，loss：0.00015994963177945465，acc：1.0\n",
      "训练时间：23182.722999095917\n",
      "第200个批次，loss：0.0005784441018477082，acc：1.0\n",
      "训练时间：23195.88597512245\n",
      "第300个批次，loss：0.05291210114955902，acc：0.96875\n",
      "训练时间：23209.14516878128\n",
      "第400个批次，loss：0.0011738967150449753，acc：1.0\n",
      "训练时间：23222.28951191902\n",
      "第500个批次，loss：0.003685609670355916，acc：1.0\n",
      "训练时间：23235.453889608383\n",
      "第600个批次，loss：0.0010437509045004845，acc：1.0\n",
      "训练时间：23248.59484744072\n",
      "第700个批次，loss：0.0006165325175970793，acc：1.0\n",
      "训练时间：23261.739322423935\n",
      "第800个批次，loss：0.0059509314596652985，acc：1.0\n",
      "整体验证集的acc：0.9932692050933838\n",
      "第200轮训练\n",
      "训练时间：23271.212460041046\n",
      "第0个批次，loss：0.004564047325402498，acc：1.0\n",
      "训练时间：23284.352430343628\n",
      "第100个批次，loss：0.08896655589342117，acc：0.96875\n",
      "训练时间：23297.514360427856\n",
      "第200个批次，loss：0.0027843310963362455，acc：1.0\n",
      "训练时间：23310.67633509636\n",
      "第300个批次，loss：0.0005670866230502725，acc：1.0\n",
      "训练时间：23323.849808692932\n",
      "第400个批次，loss：8.85005429154262e-05，acc：1.0\n",
      "训练时间：23337.151132822037\n",
      "第500个批次，loss：0.0002985814353451133，acc：1.0\n",
      "训练时间：23350.523149967194\n",
      "第600个批次，loss：0.00015016255201771855，acc：1.0\n",
      "训练时间：23363.712131738663\n",
      "第700个批次，loss：0.0012523786863312125，acc：1.0\n",
      "训练时间：23376.89710521698\n",
      "第800个批次，loss：0.0015640918863937259，acc：1.0\n",
      "整体验证集的acc：0.9919230937957764\n",
      "第201轮训练\n",
      "训练时间：23386.428249120712\n",
      "第0个批次，loss：8.404606342082843e-05，acc：1.0\n",
      "训练时间：23399.702263355255\n",
      "第100个批次，loss：0.00213628844358027，acc：1.0\n",
      "训练时间：23412.919756174088\n",
      "第200个批次，loss：0.008599855937063694，acc：1.0\n",
      "训练时间：23426.454918146133\n",
      "第300个批次，loss：0.0003542477497830987，acc：1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8132\\2403220929.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"第{i+1}轮训练\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\LiMu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\LiMu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\LiMu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\LiMu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\LiMu\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\LiMu\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\LiMu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\LiMu\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         )\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfn_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1248\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbrightness_factor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjust_brightness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrightness_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# 开始训练\n",
    "for i in range(epoch):\n",
    "    print(f\"第{i+1}轮训练\")\n",
    "    net.train()\n",
    "    for j,(X,y) in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat,y)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        train_acc = (y_hat.argmax(1)==y).sum()\n",
    "        if j%100==0:\n",
    "            print(f\"训练时间：{time.time()-start_time}\")\n",
    "            print(f\"第{j}个批次，loss：{l}，acc：{train_acc/batch_size}\")\n",
    "    \n",
    "    # 在验证集上进行测试\n",
    "    total_acc = 0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for X,y in valid_data_loader:\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            y_hat = net(X)\n",
    "            acc = (y_hat.argmax(1)==y).sum()\n",
    "            total_acc+=acc\n",
    "    if (i+1)%10 == 0:\n",
    "        torch.save(net, f'C:/Users/47925/Desktop/Data_sign_language/logs/full_model{i}.pth')\n",
    "    \n",
    "    print(f\"整体验证集的acc：{total_acc/len(valid_data_loader.dataset)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61420162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
